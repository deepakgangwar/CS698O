{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: The Winter is here\n",
    "##### This works best with epic battle music. No spoilers present.\n",
    "<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tywin Lannister was right when he said: \"The great war is between death and life, ice and fire. If we loose, the night will never end\"<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It has been six months since the white walkers' army marched into the north, led by the night king himself on a dead dragon. It has been a battle like never before: never before have men faced such an enemy in battle, never before have men fought so bravely against a united threat, and never before have they been so gravely defeated.<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; While Cersei is in King's landing, brave men have died fighting the great war. Among others, Tyrion is dead, Arya is dead and Jon Snow is dead, again. In a desperate battle, Daenerys leads all her forces in a final stand-off with the dead just south of Winterfell. <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Her army defeated, she is now on the run on her dragon in an air battle, being chased by two of her own dragons, the Night king and a dead Jon Snow. Suddenly, the Night king's spear hits Danny's dragon, who, raining blood and fire, falls into ice, taking the lost queen, with him. <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Daenerys opens her eyes in a strange place, a place which does not follow the rules of space and time, where the dead souls killed by the dead men are trapped, forever. But who woke her up? There stands near her, Tyrion, with Jorah, Davos, Jon Snow, and everybody else. They all indulge in a heartfelt reunion when someone yells- \"But how do we get out?<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Varys sees a talking crystal close by, who asks them of completing a task, which on completion would allow them to go back to the land of the living, with the ultimate tool to defeat the white-walkers and kills the night king, the Dragon-axe. They have summoned you for help, as the task is out of their expertise, to apply a modified CNN to solve the object detection problem on the PASCAL VOC dataset. Varys, the master of whisperers, has used his talents to import the following for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "# You can ask Varys to get you more if you desire\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import PIL.Image\n",
    "import PIL.ImageChops\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "from random import randint\n",
    "\n",
    "resnet_input = 224#size of resnet18 input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cersei chose violence, you choose your hyper-parameters wisely using validation data!\n",
    "batch_size = 2\n",
    "num_epochs = 5\n",
    "learning_rate =  0.001\n",
    "hyp_momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build the data\n",
    "The hound who was in charge for getting the data, brought you the following links:\n",
    "<br/>Training and validation:\n",
    "<br/>http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "<br/>Testing data:\n",
    "<br/>http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "<br/>He also told you that the dataset(datascrolls :P) consists of images from of 20 classes, with detection annotations included. The JPEGImages folder houses the images, and the Annotations folder has the object-wise labels for the objects in one xml file per image. You have to extract the object information, ie. the [xmin, ymin] (the top left x,y co-ordinates) and the [xmax, ymax] (the bottom right x,y co-ordinates) of only the objects belonging to the given 20 classes(aeroplane, bicycle, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, train, TV). For parsing the xml file, you can ask Varys to import xml.etree.ElementTree for you. <br/>\n",
    "<br/> You can then ask Bronn and Jamie to organize the data as follows:\n",
    "<br/> For every image in the dataset, extract/crop the object patch from the image one by one using their respective co-ordinates:[xmin, ymin, xmax, ymax], resize the image to resnet_input, and store it with its class label information. Do the same for training/validation and test datasets. <br/>\n",
    "##### Important\n",
    "You also have to collect data for an extra background class which stands for the class of an object which is not a part of any of the 20 classes. For this, you can crop and resize any random patches from an image. A good idea is to extract patches that have low \"intersection over union\" with any object present in the image frame from the 20 Pascal VOC classes. The number of background images should be roughly around those of other class objects' images. Hence the total classes turn out to be 21. This is important for applying the sliding window method later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ('__background__',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "           'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken form pyimagesearch for calculating intersection over union\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = (xB - xA + 1) * (yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea + np.finfo(float).eps)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from stackoverflow for drawing random bounding boxes\n",
    "def random_bbox(bbox):\n",
    "    v = [randint(0, v) for v in bbox]\n",
    "    left = min(v[0], v[2])\n",
    "    upper = min(v[1], v[3])\n",
    "    right = max(v[0], v[2])\n",
    "    lower = max(v[1], v[3])\n",
    "    return [left, upper, right, lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jamie_bronn_build_dataset(dir,img_path):            \n",
    "    image = PIL.Image.open(img_path)\n",
    "    img_name = img_path.split(\"/\")[-1].split(\".\")[-2]\n",
    "    print(img_name)\n",
    "    xml_path = dir+'/Annotations/'+img_name+'.xml'\n",
    "    xml_tree = ET.parse(xml_path)\n",
    "    xml_root = xml_tree.getroot()\n",
    "\n",
    "    temp_img = PIL.Image.new('RGB',image.size,0)\n",
    "#     image.show()\n",
    "    \n",
    "    location = []\n",
    "    labels = []\n",
    "    object_img = []\n",
    "    for object in xml_root.findall('object'):\n",
    "        name = object.find('name').text\n",
    "        position = [int(object.find('bndbox').find('xmin').text), int(object.find('bndbox').find('ymin').text),\n",
    "                    int(object.find('bndbox').find('xmax').text), int(object.find('bndbox').find('ymax').text)]\n",
    "        location.append(position)\n",
    "        crop_img = image.crop(position).convert('RGB')\n",
    "        object_img.append(crop_img)\n",
    "        labels.append(classes.index(name))\n",
    "        \n",
    "#         temp_img.paste(crop_img,position)\n",
    "\n",
    "#     temp_img = PIL.ImageChops.subtract(image,temp_img)\n",
    "#     l = skimage.morphology.label(np.array(image.convert('L')))\n",
    "#     regions = skimage.measure.regionprops(l)\n",
    "#     max_area = 0\n",
    "#     for region in regions:\n",
    "#         if region.area >= max_area:\n",
    "#             position = region.bbox\n",
    "#             max_area = region.area\n",
    "            \n",
    "#     location.append(position)        \n",
    "#     crop_img = image.crop(position).convert('RGB')\n",
    "# #     crop_img.show()\n",
    "#     object_img.append(crop_img)\n",
    "#     labels.append(classes.index('__background__'))\n",
    "\n",
    "    iou_threshold = 0.3\n",
    "    num = 0\n",
    "    while(num < 1):\n",
    "        bbox = image.getbbox()\n",
    "        boxA = random_bbox(bbox)\n",
    "        mscore = 0\n",
    "        for boxB in location:\n",
    "              score = (bb_intersection_over_union(boxA, boxB))\n",
    "              if (score > mscore):\n",
    "                  mscore = score\n",
    "        if (mscore < iou_threshold):\n",
    "            object_img.append(image.crop(boxA).convert('RGB'))\n",
    "            labels.append(classes.index('__background__'))\n",
    "            num = num + 1\n",
    "        \n",
    "    return object_img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hound_dataset(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # Begin\n",
    "        print(train)\n",
    "        if(train):\n",
    "            dir = root_dir + '/train/VOCdevkit/VOC2007'\n",
    "        else :\n",
    "            dir = root_dir + '/test/VOCdevkit/VOC2007'\n",
    "        self.transform = transform\n",
    "        self.img = [];\n",
    "        self.label = [];\n",
    "        i = 0\n",
    "        for img_path in glob.glob(dir+'/JPEGImages/*.jpg'):\n",
    "            object_img, name = jamie_bronn_build_dataset(dir,img_path)\n",
    "            self.img.extend(object_img)\n",
    "            self.label.extend(name)\n",
    "#             i = i+1\n",
    "#             if i == 7:\n",
    "#                 break\n",
    "                       \n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform is None:\n",
    "            return (self.img[idx],self.label[idx])\n",
    "        else:\n",
    "            img_transformed = self.transform(self.img[idx])\n",
    "            return (img_transformed,self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_dataset = hound_dataset(root_dir='.', train=False, transform=None) # Supply proper root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the netwok\n",
    "<br/>You can ask Arya to train the network on the created dataset. This will yield a classification network on the 21 classes of the VOC dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "008310\n",
      "001492\n",
      "004514\n",
      "004611\n",
      "003239\n",
      "004685\n",
      "000806\n",
      "008390\n",
      "002933\n",
      "003699\n",
      "001137\n",
      "002520\n",
      "007803\n",
      "007330\n",
      "002056\n",
      "005173\n",
      "004512\n",
      "006346\n",
      "008100\n",
      "007311\n",
      "002036\n",
      "003382\n",
      "007997\n",
      "005058\n",
      "009764\n",
      "006209\n",
      "003790\n",
      "003280\n",
      "001486\n",
      "003618\n",
      "003646\n",
      "002253\n",
      "008213\n",
      "006357\n",
      "007141\n",
      "008771\n",
      "000977\n",
      "007970\n",
      "008076\n",
      "009745\n",
      "009905\n",
      "004111\n",
      "002272\n",
      "004186\n",
      "000524\n",
      "006398\n",
      "000352\n",
      "006424\n",
      "002180\n",
      "004228\n",
      "003783\n",
      "005217\n",
      "000164\n",
      "006468\n",
      "008360\n",
      "004019\n",
      "003337\n",
      "008982\n",
      "008529\n",
      "007897\n",
      "005845\n",
      "009532\n",
      "003299\n",
      "007292\n",
      "001755\n",
      "000270\n",
      "002899\n",
      "005851\n",
      "004140\n",
      "004607\n",
      "004926\n",
      "003135\n",
      "009299\n",
      "004423\n",
      "006725\n",
      "006852\n",
      "007544\n",
      "001442\n",
      "001504\n",
      "000477\n",
      "006687\n",
      "005186\n",
      "003039\n",
      "003824\n",
      "009834\n",
      "007208\n",
      "007132\n",
      "001522\n",
      "002345\n",
      "005487\n",
      "000435\n",
      "005086\n",
      "006355\n",
      "006179\n",
      "002140\n",
      "002858\n",
      "005930\n",
      "008426\n",
      "007138\n",
      "004033\n",
      "003821\n",
      "008318\n",
      "005358\n",
      "000867\n",
      "008069\n",
      "000215\n",
      "000608\n",
      "003654\n",
      "005094\n",
      "001677\n",
      "002969\n",
      "007745\n",
      "007370\n",
      "001523\n",
      "004649\n",
      "006035\n",
      "003094\n",
      "006133\n",
      "006304\n",
      "005517\n",
      "002405\n",
      "000308\n",
      "007474\n",
      "006275\n",
      "007398\n",
      "000726\n",
      "000851\n",
      "001068\n",
      "003017\n",
      "001012\n",
      "006919\n",
      "009285\n",
      "009945\n",
      "008253\n",
      "003260\n",
      "008268\n",
      "005897\n",
      "006314\n",
      "005169\n",
      "001239\n",
      "004999\n",
      "001290\n",
      "005668\n",
      "002699\n",
      "005343\n",
      "001164\n",
      "000949\n",
      "002803\n",
      "006269\n",
      "003554\n",
      "008926\n",
      "004814\n",
      "004815\n",
      "000305\n",
      "003042\n",
      "002129\n",
      "006375\n",
      "000156\n",
      "005790\n",
      "001453\n",
      "003284\n",
      "006699\n",
      "001554\n",
      "006588\n",
      "005838\n",
      "007768\n",
      "005028\n",
      "008026\n",
      "003349\n",
      "002916\n",
      "001475\n",
      "007200\n",
      "004023\n",
      "007971\n",
      "009411\n",
      "007503\n",
      "001950\n",
      "001102\n",
      "000224\n",
      "001614\n",
      "002343\n",
      "002112\n",
      "006291\n",
      "009676\n",
      "002257\n",
      "002589\n",
      "005318\n",
      "005803\n",
      "002896\n",
      "006474\n",
      "005210\n",
      "007258\n",
      "009703\n",
      "001717\n",
      "003376\n",
      "004152\n",
      "002135\n",
      "001860\n",
      "002459\n",
      "003214\n",
      "002287\n",
      "000699\n",
      "003961\n",
      "000849\n",
      "009205\n",
      "000219\n",
      "004974\n",
      "006866\n",
      "009144\n",
      "005457\n",
      "002410\n",
      "000518\n",
      "008342\n",
      "007767\n",
      "006260\n",
      "001617\n",
      "003002\n",
      "005029\n",
      "002460\n",
      "008960\n",
      "009194\n",
      "001858\n",
      "002722\n",
      "002006\n",
      "005220\n",
      "008364\n",
      "008951\n",
      "001203\n",
      "005145\n",
      "004885\n",
      "009018\n",
      "003262\n",
      "005741\n",
      "001185\n",
      "006038\n",
      "008607\n",
      "005828\n",
      "007275\n",
      "004135\n",
      "004984\n",
      "003991\n",
      "006803\n",
      "005483\n",
      "007919\n",
      "003356\n",
      "004950\n",
      "005719\n",
      "005027\n",
      "000312\n",
      "006702\n",
      "009617\n",
      "009155\n",
      "009312\n",
      "009686\n",
      "008985\n",
      "007721\n",
      "000958\n",
      "008012\n",
      "003885\n",
      "001119\n",
      "009496\n",
      "008191\n",
      "000823\n",
      "003912\n",
      "000454\n",
      "004956\n",
      "001166\n",
      "008061\n",
      "002276\n",
      "001082\n",
      "005368\n",
      "008831\n",
      "007519\n",
      "004391\n",
      "005085\n",
      "007877\n",
      "006243\n",
      "005885\n",
      "004632\n",
      "003638\n",
      "007038\n",
      "007381\n",
      "007084\n",
      "000374\n",
      "009860\n",
      "002563\n",
      "005878\n",
      "001933\n",
      "002116\n",
      "006309\n",
      "004566\n",
      "000245\n",
      "002493\n",
      "007884\n",
      "007046\n",
      "008810\n",
      "003300\n",
      "007683\n",
      "001559\n",
      "007663\n",
      "004271\n",
      "004705\n",
      "007048\n",
      "006023\n",
      "007236\n",
      "007883\n",
      "003923\n",
      "009215\n",
      "003147\n",
      "000519\n",
      "001607\n",
      "006587\n",
      "004364\n",
      "007389\n",
      "001902\n",
      "008756\n",
      "004562\n",
      "005185\n",
      "000282\n",
      "001444\n",
      "003754\n",
      "001260\n",
      "003090\n",
      "000680\n",
      "000967\n",
      "006289\n",
      "000929\n",
      "001472\n",
      "001151\n",
      "009289\n",
      "007900\n",
      "000859\n",
      "003732\n",
      "006550\n",
      "008859\n",
      "004671\n",
      "004722\n",
      "009512\n",
      "007482\n",
      "008720\n",
      "000482\n",
      "006674\n",
      "004189\n",
      "003311\n",
      "003150\n",
      "007172\n",
      "005061\n",
      "005360\n",
      "003803\n",
      "005023\n",
      "006466\n",
      "007772\n",
      "000469\n",
      "004093\n",
      "002826\n",
      "002192\n",
      "005985\n",
      "002300\n",
      "003461\n",
      "003497\n",
      "002372\n",
      "007974\n",
      "003054\n",
      "009958\n",
      "003110\n",
      "008958\n",
      "006262\n",
      "000888\n",
      "007535\n",
      "007928\n",
      "003072\n",
      "006026\n",
      "005179\n",
      "009523\n",
      "004991\n",
      "005789\n",
      "009085\n",
      "001160\n",
      "009368\n",
      "006159\n",
      "009859\n",
      "005908\n",
      "009531\n",
      "005471\n",
      "007425\n",
      "006534\n",
      "000829\n",
      "009528\n",
      "004457\n",
      "003868\n",
      "004495\n",
      "008236\n",
      "003407\n",
      "004459\n",
      "003667\n",
      "007421\n",
      "004209\n",
      "006153\n",
      "009698\n",
      "005884\n",
      "006536\n",
      "005812\n",
      "008316\n",
      "007351\n",
      "003781\n",
      "000760\n",
      "007847\n",
      "008760\n",
      "007068\n",
      "008766\n",
      "005424\n",
      "008275\n",
      "004841\n",
      "008883\n",
      "001582\n",
      "008036\n",
      "003511\n",
      "005685\n",
      "007093\n",
      "003675\n",
      "006858\n",
      "003395\n",
      "007263\n",
      "008168\n",
      "005586\n",
      "004274\n",
      "001995\n",
      "007795\n",
      "009197\n",
      "003688\n",
      "006261\n",
      "008876\n",
      "001777\n",
      "002034\n",
      "008482\n",
      "008209\n",
      "007586\n",
      "009614\n",
      "009255\n",
      "002420\n",
      "002366\n",
      "009481\n",
      "000494\n",
      "005956\n",
      "008553\n",
      "005702\n",
      "004876\n",
      "008049\n",
      "000552\n",
      "004539\n",
      "007840\n",
      "007285\n",
      "009007\n",
      "000545\n",
      "009959\n",
      "009587\n",
      "008307\n",
      "006350\n",
      "004117\n",
      "009250\n",
      "002645\n",
      "009600\n",
      "002704\n",
      "000816\n",
      "009778\n",
      "001186\n",
      "008122\n",
      "008186\n",
      "000225\n",
      "005177\n",
      "000908\n",
      "004535\n",
      "004857\n",
      "006124\n",
      "000707\n",
      "007427\n",
      "005430\n",
      "001036\n",
      "008442\n",
      "006878\n",
      "003213\n",
      "007668\n",
      "002807\n",
      "002508\n",
      "003011\n",
      "005566\n",
      "004295\n",
      "000033\n",
      "009537\n",
      "003694\n",
      "008968\n",
      "008422\n",
      "002847\n",
      "002153\n",
      "002367\n",
      "006396\n",
      "000802\n",
      "003714\n",
      "004339\n",
      "006381\n",
      "008032\n",
      "002404\n",
      "001298\n",
      "000555\n",
      "008410\n",
      "002867\n",
      "009721\n",
      "002194\n",
      "001498\n",
      "005736\n",
      "003510\n",
      "008048\n",
      "001501\n",
      "002594\n",
      "005146\n",
      "003259\n",
      "004185\n",
      "001420\n",
      "006065\n",
      "004346\n",
      "009618\n",
      "002096\n",
      "002480\n",
      "001612\n",
      "006666\n",
      "000129\n",
      "006229\n",
      "000198\n",
      "008920\n",
      "008503\n",
      "006753\n",
      "008416\n",
      "001590\n",
      "005478\n",
      "000017\n",
      "002767\n",
      "006067\n",
      "006909\n",
      "000036\n",
      "002472\n",
      "002995\n",
      "009865\n",
      "004370\n",
      "005541\n",
      "002174\n",
      "007072\n",
      "005363\n",
      "002512\n",
      "009303\n",
      "008595\n",
      "004496\n",
      "006777\n",
      "001215\n",
      "008718\n",
      "002693\n",
      "002947\n",
      "002667\n",
      "003320\n",
      "000332\n",
      "002749\n",
      "004963\n",
      "006456\n",
      "004776\n",
      "005764\n",
      "000686\n",
      "003421\n",
      "004968\n",
      "002855\n",
      "004108\n",
      "006175\n",
      "002263\n",
      "007073\n",
      "000879\n",
      "000831\n",
      "001011\n",
      "008293\n",
      "007731\n",
      "001936\n",
      "002658\n",
      "002845\n",
      "008225\n",
      "005875\n",
      "007729\n",
      "006794\n",
      "009641\n",
      "001875\n",
      "008635\n",
      "005229\n",
      "002348\n",
      "002795\n",
      "002766\n",
      "003827\n",
      "009180\n",
      "009151\n",
      "000486\n",
      "007601\n",
      "008060\n",
      "003551\n",
      "005258\n",
      "001765\n",
      "001002\n",
      "009961\n",
      "004834\n",
      "007953\n",
      "009749\n",
      "005732\n",
      "009634\n",
      "003589\n",
      "003926\n",
      "007959\n",
      "001680\n",
      "000896\n",
      "004565\n",
      "004015\n",
      "005370\n",
      "000654\n",
      "002864\n",
      "001901\n",
      "007565\n",
      "000165\n",
      "003359\n",
      "000132\n",
      "003137\n",
      "002690\n",
      "005417\n",
      "007809\n",
      "000431\n",
      "005305\n",
      "009371\n",
      "007222\n",
      "004174\n",
      "005906\n",
      "004517\n",
      "002288\n",
      "004105\n",
      "007064\n",
      "009650\n",
      "000528\n",
      "006947\n",
      "001043\n",
      "002869\n",
      "008884\n",
      "000450\n",
      "008180\n",
      "004910\n",
      "009681\n",
      "006671\n",
      "008987\n",
      "006497\n",
      "000142\n",
      "008336\n",
      "008592\n",
      "003129\n",
      "008723\n",
      "005743\n",
      "005079\n",
      "000154\n",
      "005274\n",
      "005600\n",
      "005761\n",
      "000648\n",
      "008085\n",
      "005369\n",
      "000349\n",
      "006631\n",
      "003294\n",
      "007414\n",
      "002213\n",
      "007095\n",
      "001952\n",
      "005606\n",
      "007009\n",
      "008980\n",
      "003743\n",
      "005467\n",
      "003763\n",
      "007980\n",
      "002091\n",
      "003008\n",
      "004777\n",
      "001174\n",
      "000880\n",
      "006363\n",
      "006270\n",
      "006233\n",
      "003390\n",
      "007130\n",
      "003671\n",
      "006632\n",
      "009491\n",
      "000906\n",
      "004997\n",
      "001468\n",
      "007915\n",
      "003983\n",
      "008483\n",
      "002094\n",
      "007261\n",
      "009053\n",
      "008272\n",
      "001649\n",
      "001594\n",
      "006529\n",
      "009020\n",
      "006259\n",
      "009227\n",
      "007692\n",
      "006404\n",
      "004528\n",
      "007517\n",
      "002786\n",
      "000476\n",
      "009926\n",
      "000805\n",
      "005585\n",
      "007533\n",
      "009136\n",
      "004789\n",
      "009323\n",
      "002374\n",
      "004392\n",
      "001311\n",
      "002812\n",
      "005407\n",
      "002559\n",
      "008468\n",
      "002879\n",
      "006459\n",
      "006827\n",
      "007029\n",
      "008854\n",
      "003374\n",
      "003308\n",
      "000989\n",
      "002958\n",
      "008874\n",
      "006735\n",
      "009878\n",
      "001499\n",
      "009315\n",
      "005413\n",
      "007078\n",
      "008914\n",
      "002976\n",
      "007605\n",
      "003416\n",
      "009776\n",
      "000218\n",
      "005373\n",
      "001676\n",
      "006903\n",
      "000146\n",
      "004325\n",
      "002931\n",
      "008582\n",
      "002369\n",
      "008886\n",
      "009126\n",
      "005841\n",
      "002741\n",
      "001981\n",
      "009605\n",
      "009159\n",
      "008731\n",
      "005273\n",
      "007484\n",
      "000073\n",
      "008871\n",
      "007649\n",
      "005960\n",
      "006111\n",
      "003103\n",
      "008610\n",
      "000755\n",
      "002546\n",
      "009295\n",
      "005620\n",
      "006883\n",
      "009497\n",
      "003433\n",
      "004201\n",
      "008796\n",
      "006860\n",
      "007624\n",
      "007300\n",
      "009867\n",
      "000637\n",
      "001741\n",
      "000520\n",
      "000256\n",
      "007079\n",
      "008692\n",
      "004675\n",
      "005979\n",
      "003430\n",
      "003093\n",
      "008449\n",
      "006509\n",
      "007656\n",
      "004279\n",
      "002166\n",
      "008840\n",
      "002268\n",
      "005269\n",
      "006628\n",
      "000249\n",
      "006530\n",
      "007318\n",
      "006924\n",
      "001233\n",
      "000931\n",
      "003546\n",
      "001778\n",
      "001627\n",
      "005064\n",
      "007022\n",
      "004869\n",
      "002566\n",
      "000408\n",
      "002584\n",
      "002988\n",
      "008391\n",
      "000684\n",
      "009938\n",
      "002193\n",
      "001107\n",
      "003798\n",
      "004244\n",
      "008940\n",
      "002267\n",
      "002593\n",
      "001739\n",
      "004120\n",
      "003398\n",
      "003229\n",
      "008199\n",
      "006216\n",
      "005756\n",
      "005020\n",
      "008445\n",
      "004673\n",
      "006617\n",
      "000298\n",
      "003133\n",
      "009286\n",
      "002423\n",
      "002668\n",
      "005591\n",
      "002844\n",
      "001771\n",
      "007762\n",
      "001464\n",
      "005877\n",
      "000325\n",
      "008280\n",
      "004938\n",
      "003403\n",
      "009809\n",
      "008817\n",
      "006018\n",
      "009691\n",
      "003706\n",
      "003614\n",
      "001008\n",
      "008042\n",
      "002834\n",
      "000605\n",
      "005130\n",
      "003698\n",
      "006718\n",
      "003496\n",
      "001548\n",
      "009684\n",
      "009089\n",
      "009398\n",
      "005419\n",
      "004676\n",
      "002595\n",
      "006611\n",
      "004409\n",
      "002215\n",
      "004636\n",
      "002759\n",
      "002518\n",
      "005550\n",
      "002172\n",
      "008927\n",
      "006939\n",
      "003450\n",
      "003155\n",
      "008132\n",
      "006395\n",
      "006146\n",
      "005697\n",
      "001689\n",
      "006224\n",
      "005469\n",
      "009066\n",
      "003524\n",
      "008900\n",
      "006329\n",
      "008169\n",
      "009049\n",
      "005351\n",
      "004405\n",
      "005441\n",
      "003806\n",
      "006836\n",
      "005984\n",
      "003722\n",
      "007445\n",
      "006264\n",
      "009325\n",
      "008973\n",
      "008235\n",
      "002901\n",
      "005429\n",
      "006727\n",
      "008967\n",
      "006353\n",
      "009667\n",
      "009034\n",
      "008345\n",
      "002184\n",
      "002684\n",
      "005614\n",
      "005899\n",
      "001360\n",
      "005873\n",
      "005510\n",
      "009350\n",
      "000438\n",
      "004850\n",
      "009424\n",
      "003847\n",
      "006625\n",
      "002734\n",
      "002942\n",
      "009939\n",
      "000021\n",
      "009796\n",
      "006300\n",
      "003642\n",
      "004379\n",
      "009611\n",
      "007376\n",
      "008398\n",
      "004727\n",
      "004656\n",
      "008248\n",
      "005755\n",
      "009359\n",
      "004710\n",
      "003100\n",
      "001806\n",
      "007162\n",
      "004256\n",
      "000834\n",
      "006421\n",
      "006761\n",
      "004300\n",
      "008005\n",
      "003704\n",
      "006225\n",
      "008302\n",
      "000591\n",
      "008456\n",
      "002723\n",
      "007390\n",
      "006867\n",
      "009596\n",
      "009283\n",
      "001248\n",
      "007194\n",
      "009064\n",
      "003860\n",
      "007479\n",
      "005006\n",
      "007086\n",
      "000104\n",
      "002099\n",
      "000459\n",
      "004581\n",
      "009746\n",
      "004537\n",
      "001932\n",
      "007798\n",
      "002171\n",
      "008008\n",
      "008738\n",
      "007491\n",
      "002291\n",
      "005951\n",
      "003935\n",
      "003887\n",
      "000685\n",
      "008655\n",
      "004746\n",
      "009273\n",
      "003396\n",
      "007606\n",
      "000347\n",
      "005111\n",
      "002848\n",
      "001490\n",
      "003820\n",
      "009477\n",
      "008430\n",
      "000515\n",
      "004935\n",
      "009882\n",
      "008299\n",
      "006251\n",
      "004494\n",
      "000814\n",
      "005374\n",
      "002468\n",
      "008443\n",
      "008174\n",
      "001934\n",
      "007976\n",
      "005549\n",
      "006704\n",
      "008409\n",
      "004463\n",
      "006864\n",
      "001734\n",
      "002445\n",
      "006922\n",
      "003244\n",
      "003760\n",
      "004404\n",
      "002197\n",
      "007276\n",
      "008075\n",
      "003604\n",
      "000034\n",
      "004438\n",
      "000439\n",
      "008320\n",
      "002134\n",
      "000777\n",
      "005134\n",
      "006697\n",
      "005055\n",
      "008216\n",
      "004647\n",
      "009884\n",
      "008814\n",
      "001515\n",
      "001918\n",
      "003877\n",
      "003674\n",
      "000919\n",
      "005393\n",
      "007023\n",
      "009036\n",
      "000012\n",
      "002689\n",
      "009902\n",
      "003362\n",
      "000885\n",
      "005923\n",
      "004719\n",
      "002247\n",
      "002342\n",
      "003588\n",
      "006800\n",
      "007410\n",
      "005981\n",
      "003066\n",
      "002413\n",
      "004773\n",
      "006855\n",
      "009576\n",
      "001334\n",
      "009743\n",
      "002732\n",
      "008514\n",
      "009609\n",
      "002695\n",
      "009419\n",
      "006475\n",
      "007631\n",
      "000531\n",
      "003161\n",
      "006661\n",
      "001579\n",
      "001144\n",
      "000130\n",
      "006437\n",
      "002579\n",
      "009461\n",
      "001509\n",
      "009247\n",
      "001904\n",
      "000395\n",
      "002385\n",
      "005669\n",
      "005181\n",
      "005116\n",
      "003898\n",
      "005526\n",
      "007763\n",
      "001726\n",
      "000192\n",
      "008478\n",
      "006859\n",
      "001154\n",
      "003487\n",
      "004479\n",
      "000754\n",
      "007004\n",
      "006238\n",
      "006025\n",
      "007059\n",
      "009872\n",
      "001718\n",
      "003947\n",
      "000266\n",
      "002170\n",
      "001350\n",
      "000770\n",
      "005799\n",
      "003869\n",
      "003913\n",
      "008279\n",
      "005605\n",
      "006679\n",
      "004122\n",
      "006499\n",
      "002501\n",
      "009117\n",
      "005928\n",
      "005531\n",
      "006484\n",
      "009458\n",
      "000318\n",
      "009508\n",
      "008654\n",
      "001750\n",
      "004692\n",
      "005416\n",
      "006654\n",
      "007139\n",
      "008847\n",
      "000972\n",
      "004069\n",
      "000461\n",
      "000320\n",
      "002504\n",
      "002561\n",
      "001050\n",
      "004257\n",
      "005236\n",
      "003061\n",
      "002470\n",
      "004500\n",
      "007100\n",
      "000381\n",
      "007619\n",
      "001845\n",
      "005486\n",
      "004433\n",
      "001254\n",
      "001042\n",
      "002307\n",
      "000982\n",
      "003441\n",
      "001643\n",
      "003124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001441\n",
      "006208\n",
      "000892\n",
      "003767\n",
      "004145\n",
      "006128\n",
      "001014\n",
      "001259\n",
      "006802\n",
      "004195\n",
      "006949\n",
      "002145\n",
      "000464\n",
      "002218\n",
      "008093\n",
      "009836\n",
      "007052\n",
      "003857\n",
      "004307\n",
      "000275\n",
      "002437\n",
      "003159\n",
      "007097\n",
      "009108\n",
      "001555\n",
      "009209\n",
      "007890\n",
      "000516\n",
      "004644\n",
      "009131\n",
      "000794\n",
      "004396\n",
      "000748\n",
      "009039\n",
      "003466\n",
      "002477\n",
      "001877\n",
      "004169\n",
      "004576\n",
      "000592\n",
      "000081\n",
      "009271\n",
      "007621\n",
      "007446\n",
      "005352\n",
      "005856\n",
      "005144\n",
      "007470\n",
      "002954\n",
      "008843\n",
      "005278\n",
      "005796\n",
      "002944\n",
      "001121\n",
      "005404\n",
      "002324\n",
      "006417\n",
      "001024\n",
      "000946\n",
      "004121\n",
      "005542\n",
      "006098\n",
      "001205\n",
      "001978\n",
      "008542\n",
      "000480\n",
      "008425\n",
      "007080\n",
      "007077\n",
      "007727\n",
      "007350\n",
      "003425\n",
      "000934\n",
      "005652\n",
      "000782\n",
      "002967\n",
      "003462\n",
      "006610\n",
      "000047\n",
      "008346\n",
      "000973\n",
      "007753\n",
      "009189\n",
      "009463\n",
      "004911\n",
      "006874\n",
      "004468\n",
      "007667\n",
      "007831\n",
      "006706\n",
      "008653\n",
      "004674\n",
      "001409\n",
      "003021\n",
      "006538\n",
      "008190\n",
      "003218\n",
      "000964\n",
      "004077\n",
      "004253\n",
      "006335\n",
      "003023\n",
      "005786\n",
      "004552\n",
      "004687\n",
      "006840\n",
      "003895\n",
      "002912\n",
      "008106\n",
      "006011\n",
      "009586\n",
      "003997\n",
      "003117\n",
      "003567\n",
      "009908\n",
      "008663\n",
      "008801\n",
      "008115\n",
      "001084\n",
      "009807\n",
      "008068\n",
      "004708\n",
      "007876\n",
      "004524\n",
      "005388\n",
      "007475\n",
      "006965\n",
      "000259\n",
      "008125\n",
      "005700\n",
      "000965\n",
      "009585\n",
      "000899\n",
      "006681\n",
      "007125\n",
      "006562\n",
      "002891\n",
      "009278\n",
      "000276\n",
      "006055\n",
      "000514\n",
      "007558\n",
      "003828\n",
      "003636\n",
      "005191\n",
      "000403\n",
      "002401\n",
      "000372\n",
      "004341\n",
      "006677\n",
      "000996\n",
      "007506\n",
      "000810\n",
      "004788\n",
      "009141\n",
      "005903\n",
      "001413\n",
      "004321\n",
      "008037\n",
      "009543\n",
      "006108\n",
      "008454\n",
      "005328\n",
      "007987\n",
      "001556\n",
      "003127\n",
      "000122\n",
      "002987\n",
      "003628\n",
      "009500\n",
      "007885\n",
      "006427\n",
      "002572\n",
      "006482\n",
      "008688\n",
      "001200\n",
      "009735\n",
      "004502\n",
      "001470\n",
      "005203\n",
      "006198\n",
      "000682\n",
      "006658\n",
      "002881\n",
      "002279\n",
      "003576\n",
      "002452\n",
      "005662\n",
      "008644\n",
      "008523\n",
      "000257\n",
      "001182\n",
      "004073\n",
      "000125\n",
      "001693\n",
      "001314\n",
      "004672\n",
      "004437\n",
      "005636\n",
      "002917\n",
      "000971\n",
      "000993\n",
      "004082\n",
      "008757\n",
      "002880\n",
      "003965\n",
      "006323\n",
      "003140\n",
      "008306\n",
      "005788\n",
      "002913\n",
      "005489\n",
      "008063\n",
      "009502\n",
      "009407\n",
      "002815\n",
      "008727\n",
      "007956\n",
      "001493\n",
      "005970\n",
      "007359\n",
      "008138\n",
      "000728\n",
      "002873\n",
      "001104\n",
      "007551\n",
      "007468\n",
      "007280\n",
      "004411\n",
      "000943\n",
      "002678\n",
      "006400\n",
      "008526\n",
      "003621\n",
      "002281\n",
      "000815\n",
      "000921\n",
      "001628\n",
      "000500\n",
      "007372\n",
      "003963\n",
      "005378\n",
      "002156\n",
      "001524\n",
      "009954\n",
      "004034\n",
      "008300\n",
      "001229\n",
      "003379\n",
      "006932\n",
      "004470\n",
      "008031\n",
      "002054\n",
      "002284\n",
      "006618\n",
      "001268\n",
      "000808\n",
      "007219\n",
      "008177\n",
      "004542\n",
      "009213\n",
      "009196\n",
      "006203\n",
      "002190\n",
      "001231\n",
      "006320\n",
      "001842\n",
      "003837\n",
      "007260\n",
      "002064\n",
      "006409\n",
      "005716\n",
      "002109\n",
      "004191\n",
      "004017\n",
      "001483\n",
      "002234\n",
      "003468\n",
      "003247\n",
      "001989\n",
      "001266\n",
      "006162\n",
      "001841\n",
      "009389\n",
      "005414\n",
      "008518\n",
      "007950\n",
      "003586\n",
      "004430\n",
      "004897\n",
      "003932\n",
      "001861\n",
      "009015\n",
      "005253\n",
      "001828\n",
      "008822\n",
      "001110\n",
      "003793\n",
      "004133\n",
      "002260\n",
      "003121\n",
      "005161\n",
      "003369\n",
      "001531\n",
      "001393\n",
      "008494\n",
      "003145\n",
      "006772\n",
      "006337\n",
      "007109\n",
      "007575\n",
      "008269\n",
      "002859\n",
      "007432\n",
      "001352\n",
      "002641\n",
      "007559\n",
      "009738\n",
      "004131\n",
      "000169\n",
      "009712\n",
      "005905\n",
      "008965\n",
      "008905\n",
      "003419\n",
      "006814\n",
      "000826\n",
      "006595\n",
      "006215\n",
      "009565\n",
      "004859\n",
      "000311\n",
      "008647\n",
      "001250\n",
      "007901\n",
      "003525\n",
      "004882\n",
      "000903\n",
      "006089\n",
      "004571\n",
      "006828\n",
      "007815\n",
      "003051\n",
      "006189\n",
      "002514\n",
      "001247\n",
      "005590\n",
      "002120\n",
      "004585\n",
      "001341\n",
      "008645\n",
      "003360\n",
      "002256\n",
      "007150\n",
      "009306\n",
      "002854\n",
      "006258\n",
      "007279\n",
      "008728\n",
      "004527\n",
      "001938\n",
      "007327\n",
      "000862\n",
      "002063\n",
      "002337\n",
      "009659\n",
      "008558\n",
      "000904\n",
      "007908\n",
      "005434\n",
      "005202\n",
      "001387\n",
      "009037\n",
      "008872\n",
      "004701\n",
      "004986\n",
      "005138\n",
      "002727\n",
      "000845\n",
      "006352\n",
      "001494\n",
      "006043\n",
      "003112\n",
      "003655\n",
      "006622\n",
      "006593\n",
      "003537\n",
      "008470\n",
      "005350\n",
      "004361\n",
      "006130\n",
      "002333\n",
      "007274\n",
      "006281\n",
      "005701\n",
      "004258\n",
      "007223\n",
      "002226\n",
      "004953\n",
      "002633\n",
      "005077\n",
      "000589\n",
      "000269\n",
      "003986\n",
      "002744\n",
      "006916\n",
      "002657\n",
      "009291\n",
      "003408\n",
      "009896\n",
      "005379\n",
      "003509\n",
      "008108\n",
      "007117\n",
      "007212\n",
      "004356\n",
      "006387\n",
      "005839\n",
      "000954\n",
      "005420\n",
      "004368\n",
      "001332\n",
      "003316\n",
      "000026\n",
      "009655\n",
      "003971\n",
      "007451\n",
      "003274\n",
      "009468\n",
      "003727\n",
      "001651\n",
      "000379\n",
      "000705\n",
      "003834\n",
      "004597\n",
      "003874\n",
      "002042\n",
      "000793\n",
      "001638\n",
      "005475\n",
      "004946\n",
      "003969\n",
      "006285\n",
      "007146\n",
      "008638\n",
      "009420\n",
      "005779\n",
      "009094\n",
      "001299\n",
      "001143\n",
      "009365\n",
      "002915\n",
      "003350\n",
      "002340\n",
      "006824\n",
      "008995\n",
      "008742\n",
      "005686\n",
      "005292\n",
      "000554\n",
      "005307\n",
      "004011\n",
      "007751\n",
      "007843\n",
      "009437\n",
      "007932\n",
      "003013\n",
      "005980\n",
      "001170\n",
      "008911\n",
      "000433\n",
      "009935\n",
      "004421\n",
      "000950\n",
      "003907\n",
      "003866\n",
      "004905\n",
      "000304\n",
      "009244\n",
      "005840\n",
      "003470\n",
      "007259\n",
      "009869\n",
      "002966\n",
      "004973\n",
      "001633\n",
      "004992\n",
      "003844\n",
      "007016\n",
      "008312\n",
      "002906\n",
      "001273\n",
      "001708\n",
      "008823\n",
      "001837\n",
      "003105\n",
      "009913\n",
      "001125\n",
      "008710\n",
      "008202\n",
      "001892\n",
      "003634\n",
      "004548\n",
      "002680\n",
      "003518\n",
      "006935\n",
      "003204\n",
      "008909\n",
      "005244\n",
      "000203\n",
      "009479\n",
      "007864\n",
      "009567\n",
      "008856\n",
      "008975\n",
      "001281\n",
      "001688\n",
      "005625\n",
      "000370\n",
      "009434\n",
      "003774\n",
      "004376\n",
      "003960\n",
      "007718\n",
      "000134\n",
      "009794\n",
      "008667\n",
      "002529\n",
      "007325\n",
      "006463\n",
      "008043\n",
      "002321\n",
      "001287\n",
      "004742\n",
      "000463\n",
      "008220\n",
      "000296\n",
      "006841\n",
      "005346\n",
      "003994\n",
      "001272\n",
      "008628\n",
      "006657\n",
      "009343\n",
      "004102\n",
      "008879\n",
      "009432\n",
      "002465\n",
      "001727\n",
      "000131\n",
      "009177\n",
      "004630\n",
      "009647\n",
      "006963\n",
      "005653\n",
      "005397\n",
      "008241\n",
      "001526\n",
      "005735\n",
      "004389\n",
      "008833\n",
      "008722\n",
      "009636\n",
      "009123\n",
      "000690\n",
      "002794\n",
      "001418\n",
      "007859\n",
      "004269\n",
      "008067\n",
      "004612\n",
      "001768\n",
      "009710\n",
      "000141\n",
      "006765\n",
      "005639\n",
      "005440\n",
      "005867\n",
      "001018\n",
      "001899\n",
      "008294\n",
      "003177\n",
      "004587\n",
      "006339\n",
      "007191\n",
      "006575\n",
      "009413\n",
      "001485\n",
      "001878\n",
      "005576\n",
      "007424\n",
      "008633\n",
      "006321\n",
      "002603\n",
      "005544\n",
      "004682\n",
      "001289\n",
      "005176\n",
      "001787\n",
      "007579\n",
      "006027\n",
      "008465\n",
      "008978\n",
      "000448\n",
      "000742\n",
      "006091\n",
      "008535\n",
      "000121\n",
      "005418\n",
      "004359\n",
      "006030\n",
      "005507\n",
      "004662\n",
      "002938\n",
      "007213\n",
      "000303\n",
      "006602\n",
      "009950\n",
      "007639\n",
      "003047\n",
      "000661\n",
      "009518\n",
      "000337\n",
      "006647\n",
      "003970\n",
      "000620\n",
      "003987\n",
      "009733\n",
      "003271\n",
      "007855\n",
      "001443\n",
      "004365\n",
      "001870\n",
      "007148\n",
      "007709\n",
      "008819\n",
      "003918\n",
      "000474\n",
      "008970\n",
      "003032\n",
      "002179\n",
      "006249\n",
      "002104\n",
      "007863\n",
      "000912\n",
      "004436\n",
      "006829\n",
      "007438\n",
      "003791\n",
      "000363\n",
      "003363\n",
      "000579\n",
      "006825\n",
      "003077\n",
      "002011\n",
      "003865\n",
      "003826\n",
      "007227\n",
      "001310\n",
      "009562\n",
      "002021\n",
      "003088\n",
      "007297\n",
      "007576\n",
      "008437\n",
      "002273\n",
      "001711\n",
      "008695\n",
      "006450\n",
      "000328\n",
      "003703\n",
      "002015\n",
      "005248\n",
      "009469\n",
      "008784\n",
      "000354\n",
      "005831\n",
      "001091\n",
      "005648\n",
      "005695\n",
      "004149\n",
      "000236\n",
      "009465\n",
      "004896\n",
      "004193\n",
      "009756\n",
      "009080\n",
      "009418\n",
      "004831\n",
      "007538\n",
      "001881\n",
      "005613\n",
      "001112\n",
      "008961\n",
      "009098\n",
      "000740\n",
      "009557\n",
      "004520\n",
      "002362\n",
      "004345\n",
      "005909\n",
      "005522\n",
      "006272\n",
      "007008\n",
      "008917\n",
      "000078\n",
      "008944\n",
      "001145\n",
      "006782\n",
      "002717\n",
      "006690\n",
      "002776\n",
      "004171\n",
      "007036\n",
      "002158\n",
      "001816\n",
      "000210\n",
      "009619\n",
      "005270\n",
      "004976\n",
      "001759\n",
      "004142\n",
      "004754\n",
      "008332\n",
      "009894\n",
      "009230\n",
      "009133\n",
      "002757\n",
      "009726\n",
      "007612\n",
      "000380\n",
      "004526\n",
      "008116\n",
      "003429\n",
      "007898\n",
      "005514\n",
      "003911\n",
      "005968\n",
      "005230\n",
      "006344\n",
      "000329\n",
      "003808\n",
      "004903\n",
      "004129\n",
      "009900\n",
      "009480\n",
      "004929\n",
      "007308\n",
      "006306\n",
      "007905\n",
      "006070\n",
      "009281\n",
      "001678\n",
      "008292\n",
      "007820\n",
      "005143\n",
      "006472\n",
      "008208\n",
      "005383\n",
      "007812\n",
      "002558\n",
      "008327\n",
      "009456\n",
      "004604\n",
      "007568\n",
      "003521\n",
      "008933\n",
      "008586\n",
      "007996\n",
      "004718\n",
      "005729\n",
      "008415\n",
      "008999\n",
      "005952\n",
      "009238\n",
      "002302\n",
      "008189\n",
      "000695\n",
      "009819\n",
      "001214\n",
      "008536\n",
      "002058\n",
      "000761\n",
      "003876\n",
      "002241\n",
      "004009\n",
      "005057\n",
      "005715\n",
      "009499\n",
      "009520\n",
      "000107\n",
      "005508\n",
      "002393\n",
      "006319\n",
      "007585\n",
      "000771\n",
      "002683\n",
      "001384\n",
      "009072\n",
      "002540\n",
      "002165\n",
      "009670\n",
      "008232\n",
      "006910\n",
      "003343\n",
      "007821\n",
      "009767\n",
      "003464\n",
      "007998\n",
      "009079\n",
      "007105\n",
      "002625\n",
      "000359\n",
      "005045\n",
      "008709\n",
      "006001\n",
      "002043\n",
      "004634\n",
      "004484\n",
      "000667\n",
      "003871\n",
      "008556\n",
      "008137\n",
      "007810\n",
      "000246\n",
      "007724\n",
      "009354\n",
      "000489\n",
      "008317\n",
      "008355\n",
      "004555\n",
      "000462\n",
      "003107\n",
      "007791\n",
      "001292\n",
      "009331\n",
      "004434\n",
      "006066\n",
      "004916\n",
      "000228\n",
      "002715\n",
      "004913\n",
      "000812\n",
      "009785\n",
      "002270\n",
      "006520\n",
      "001732\n",
      "001426\n",
      "002454\n",
      "002224\n",
      "001854\n",
      "003219\n",
      "009270\n",
      "008381\n",
      "005438\n",
      "002039\n",
      "008639\n",
      "008223\n",
      "003539\n",
      "003979\n",
      "006458\n",
      "002774\n",
      "002368\n",
      "004242\n",
      "003620\n",
      "002308\n",
      "006553\n",
      "000382\n",
      "004349\n",
      "008296\n",
      "003780\n",
      "005815\n",
      "001849\n",
      "006210\n",
      "005806\n",
      "002935\n",
      "009679\n",
      "000787\n",
      "005893\n",
      "004931\n",
      "006449\n",
      "009494\n",
      "000019\n",
      "009378\n",
      "007670\n",
      "006455\n",
      "003915\n",
      "003921\n",
      "009825\n",
      "002649\n",
      "002990\n",
      "006911\n",
      "008775\n",
      "007302\n",
      "007671\n",
      "000400\n",
      "008244\n",
      "007244\n",
      "003098\n",
      "006987\n",
      "005297\n",
      "001106\n",
      "008313\n",
      "000338\n",
      "000110\n",
      "007481\n",
      "000799\n",
      "007523\n",
      "001467\n",
      "007243\n",
      "000714\n",
      "003176\n",
      "002653\n",
      "008572\n",
      "004192\n",
      "005658\n",
      "000898\n",
      "009620\n",
      "005783\n",
      "009032\n",
      "007054\n",
      "002191\n",
      "000509\n",
      "001097\n",
      "003608\n",
      "003713\n",
      "007454\n",
      "000420\n",
      "009597\n",
      "005631\n",
      "004808\n",
      "005246\n",
      "001113\n",
      "008101\n",
      "000847\n",
      "003700\n",
      "005859\n",
      "003256\n",
      "000577\n",
      "004591\n",
      "005052\n",
      "004735\n",
      "000878\n",
      "008620\n",
      "008372\n",
      "008698\n",
      "006945\n",
      "009801\n",
      "001738\n",
      "006221\n",
      "008621\n",
      "006020\n",
      "006276\n",
      "005340\n",
      "002555\n",
      "003528\n",
      "002047\n",
      "008376\n",
      "000947\n",
      "005242\n",
      "009394\n",
      "002952\n",
      "007101\n",
      "006445\n",
      "002934\n",
      "002718\n",
      "001465\n",
      "001345\n",
      "007600\n",
      "001920\n",
      "008929\n",
      "000109\n",
      "002277\n",
      "002775\n",
      "007536\n",
      "008141\n",
      "000061\n",
      "002738\n",
      "006097\n",
      "003946\n",
      "000093\n",
      "004737\n",
      "009105\n",
      "001066\n",
      "007566\n",
      "004369\n",
      "001140\n",
      "000613\n",
      "006150\n",
      "006989\n",
      "000763\n",
      "007104\n",
      "004962\n",
      "004168\n",
      "008001\n",
      "006900\n",
      "009542\n",
      "001286\n",
      "002578\n",
      "005988\n",
      "008103\n",
      "009405\n",
      "006136\n",
      "002599\n",
      "009709\n",
      "002259\n",
      "007314\n",
      "001390\n",
      "001397\n",
      "004286\n",
      "006799\n",
      "001434\n",
      "003007\n",
      "005259\n",
      "008794\n",
      "007163\n",
      "000660\n",
      "008521\n",
      "002800\n",
      "007271\n",
      "000171\n",
      "000563\n",
      "006325\n",
      "001927\n",
      "001430\n",
      "002186\n",
      "006442\n",
      "000501\n",
      "009524\n",
      "006914\n",
      "006944\n",
      "003580\n",
      "005072\n",
      "009422\n",
      "001691\n",
      "005001\n",
      "007214\n",
      "000051\n",
      "008495\n",
      "000767\n",
      "001970\n",
      "000066\n",
      "005584\n",
      "005007\n",
      "000180\n",
      "006880\n",
      "005421\n",
      "006507\n",
      "004380\n",
      "007480\n",
      "002953\n",
      "009347\n",
      "002155\n",
      "002347\n",
      "007435\n",
      "006201\n",
      "009805\n",
      "008171\n",
      "007694\n",
      "001976\n",
      "001662\n",
      "007088\n",
      "007699\n",
      "003162\n",
      "006751\n",
      "007419\n",
      "007940\n",
      "002804\n",
      "006123\n",
      "006220\n",
      "003163\n",
      "003663\n",
      "009185\n",
      "008127\n",
      "001056\n",
      "002946\n",
      "002634\n",
      "002497\n",
      "004158\n",
      "001327\n",
      "007954\n",
      "007149\n",
      "005160\n",
      "006148\n",
      "002069\n",
      "004432\n",
      "002310\n",
      "002427\n",
      "006959\n",
      "003848\n",
      "005454\n",
      "009068\n",
      "004654\n",
      "003444\n",
      "009157\n",
      "008466\n",
      "000089\n",
      "003587\n",
      "009059\n",
      "007224\n",
      "004987\n",
      "003184\n",
      "004995\n",
      "001236\n",
      "002290\n",
      "002567\n",
      "006769\n",
      "002086\n",
      "007910\n",
      "000756\n",
      "007886\n",
      "004481\n",
      "001192\n",
      "004936\n",
      "005405\n",
      "002355\n",
      "007947\n",
      "004498\n",
      "001385\n",
      "007294\n",
      "001463\n",
      "008744\n",
      "001642\n",
      "009078\n",
      "008319\n",
      "002479\n",
      "003355\n",
      "005723\n",
      "004707\n",
      "009718\n",
      "006480\n",
      "008759\n",
      "009577\n",
      "003992\n",
      "003695\n",
      "004037\n",
      "001234\n",
      "005110\n",
      "006069\n",
      "003835\n",
      "009161\n",
      "001636\n",
      "003644\n",
      "002178\n",
      "000635\n",
      "005208\n",
      "003585\n",
      "002785\n",
      "009272\n",
      "007289\n",
      "007284\n",
      "008461\n",
      "005410\n",
      "000582\n",
      "008564\n",
      "004706\n",
      "007528\n",
      "006703\n",
      "000730\n",
      "006301\n",
      "004284\n",
      "009168\n",
      "004371\n",
      "004047\n",
      "001172\n",
      "005964\n",
      "001898\n",
      "005283\n",
      "009308\n",
      "006950\n",
      "006305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009290\n",
      "009476\n",
      "007678\n",
      "002481\n",
      "003338\n",
      "006682\n",
      "009868\n",
      "003335\n",
      "001544\n",
      "005911\n",
      "006519\n",
      "001593\n",
      "006849\n",
      "002126\n",
      "004452\n",
      "003721\n",
      "008988\n",
      "004579\n",
      "002632\n",
      "001176\n",
      "005825\n",
      "002311\n",
      "004441\n",
      "001045\n",
      "008096\n",
      "006523\n",
      "000060\n",
      "004627\n",
      "001127\n",
      "002067\n",
      "003038\n",
      "002932\n",
      "004474\n",
      "002228\n",
      "004110\n",
      "001684\n",
      "004281\n",
      "007672\n",
      "000407\n",
      "002139\n",
      "007040\n",
      "006933\n",
      "003849\n",
      "001603\n",
      "001827\n",
      "008098\n",
      "006214\n",
      "004025\n",
      "008250\n",
      "000321\n",
      "008596\n",
      "004998\n",
      "000417\n",
      "001948\n",
      "007521\n",
      "004544\n",
      "000625\n",
      "008044\n",
      "007211\n",
      "009613\n",
      "004439\n",
      "003949\n",
      "000367\n",
      "003435\n",
      "009832\n",
      "007611\n",
      "002611\n",
      "006046\n",
      "005408\n",
      "006696\n",
      "008576\n",
      "008942\n",
      "004239\n",
      "004170\n",
      "000997\n",
      "002571\n",
      "004013\n",
      "004584\n",
      "001136\n",
      "009792\n",
      "005655\n",
      "003057\n",
      "001982\n",
      "002682\n",
      "006570\n",
      "009823\n",
      "007411\n",
      "006512\n",
      "007498\n",
      "002836\n",
      "006171\n",
      "006436\n",
      "007230\n",
      "003603\n",
      "003202\n",
      "008699\n",
      "006103\n",
      "000882\n",
      "005910\n",
      "008755\n",
      "007493\n",
      "004595\n",
      "004588\n",
      "007007\n",
      "002212\n",
      "008509\n",
      "009810\n",
      "009163\n",
      "005398\n",
      "006369\n",
      "005519\n",
      "003548\n",
      "005918\n",
      "004384\n",
      "003412\n",
      "006074\n",
      "000233\n",
      "003045\n",
      "006548\n",
      "009940\n",
      "002884\n",
      "003108\n",
      "007058\n",
      "004912\n",
      "009221\n",
      "008258\n",
      "009091\n",
      "002637\n",
      "007197\n",
      "004872\n",
      "007712\n",
      "009016\n",
      "002810\n",
      "001406\n",
      "008433\n",
      "005536\n",
      "001537\n",
      "009406\n",
      "008040\n",
      "003491\n",
      "006134\n",
      "000800\n",
      "005784\n",
      "005097\n",
      "007033\n",
      "005854\n",
      "008783\n",
      "009193\n",
      "000522\n",
      "001069\n",
      "006839\n",
      "002417\n",
      "001274\n",
      "008263\n",
      "008979\n",
      "009309\n",
      "002745\n",
      "001378\n",
      "004825\n",
      "004743\n",
      "006028\n",
      "006698\n",
      "003083\n",
      "002492\n",
      "009330\n",
      "006411\n",
      "001553\n",
      "005592\n",
      "006564\n",
      "001980\n",
      "005618\n",
      "006061\n",
      "002352\n",
      "000610\n",
      "004699\n",
      "009421\n",
      "001793\n",
      "009282\n",
      "003392\n",
      "004842\n",
      "004315\n",
      "007921\n",
      "004003\n",
      "000140\n",
      "009316\n",
      "003556\n",
      "006419\n",
      "004683\n",
      "009439\n",
      "004089\n",
      "001801\n",
      "001445\n",
      "005682\n",
      "006948\n",
      "006418\n",
      "002838\n",
      "005465\n",
      "009148\n",
      "005042\n",
      "006236\n",
      "009337\n",
      "007071\n",
      "000221\n",
      "003717\n",
      "004310\n",
      "001294\n",
      "007011\n",
      "000622\n",
      "008550\n",
      "002755\n",
      "006678\n",
      "006125\n",
      "002387\n",
      "009507\n",
      "009027\n",
      "000675\n",
      "007140\n",
      "000549\n",
      "005637\n",
      "009019\n",
      "002816\n",
      "005281\n",
      "006549\n",
      "003627\n",
      "003027\n",
      "008562\n",
      "009644\n",
      "009181\n",
      "009150\n",
      "004631\n",
      "007968\n",
      "007713\n",
      "005868\n",
      "007642\n",
      "006385\n",
      "008453\n",
      "006995\n",
      "004146\n",
      "009490\n",
      "004958\n",
      "003708\n",
      "008139\n",
      "003331\n",
      "006652\n",
      "005990\n",
      "002537\n",
      "006670\n",
      "004190\n",
      "002842\n",
      "006739\n",
      "002747\n",
      "005577\n",
      "003629\n",
      "006202\n",
      "009571\n",
      "000689\n",
      "009224\n",
      "003797\n",
      "002266\n",
      "006129\n",
      "003856\n",
      "003354\n",
      "006968\n",
      "003307\n",
      "003465\n",
      "001521\n",
      "005189\n",
      "009362\n",
      "001414\n",
      "001532\n",
      "006943\n",
      "001316\n",
      "000598\n",
      "001001\n",
      "005039\n",
      "008329\n",
      "004966\n",
      "007147\n",
      "006884\n",
      "003261\n",
      "009191\n",
      "004553\n",
      "003449\n",
      "009621\n",
      "005948\n",
      "005107\n",
      "002209\n",
      "002024\n",
      "004272\n",
      "001480\n",
      "005582\n",
      "005971\n",
      "001789\n",
      "004628\n",
      "001622\n",
      "002478\n",
      "000717\n",
      "001945\n",
      "009816\n",
      "000470\n",
      "008506\n",
      "009045\n",
      "007121\n",
      "003064\n",
      "004826\n",
      "000937\n",
      "006377\n",
      "004570\n",
      "001010\n",
      "008502\n",
      "001168\n",
      "006896\n",
      "006172\n",
      "005222\n",
      "009433\n",
      "001201\n",
      "004715\n",
      "006440\n",
      "003272\n",
      "004429\n",
      "004237\n",
      "001529\n",
      "005975\n",
      "005254\n",
      "003984\n",
      "006391\n",
      "005647\n",
      "009828\n",
      "006506\n",
      "001843\n",
      "002318\n",
      "003004\n",
      "008498\n",
      "006560\n",
      "000804\n",
      "009324\n",
      "002542\n",
      "000143\n",
      "003622\n",
      "005062\n",
      "006181\n",
      "005056\n",
      "005568\n",
      "009706\n",
      "005728\n",
      "005264\n",
      "003658\n",
      "003773\n",
      "005081\n",
      "006931\n",
      "002505\n",
      "006643\n",
      "002095\n",
      "004008\n",
      "001977\n",
      "002419\n",
      "002564\n",
      "009516\n",
      "000187\n",
      "007958\n",
      "008891\n",
      "009246\n",
      "002083\n",
      "007050\n",
      "003391\n",
      "009214\n",
      "000677\n",
      "001348\n",
      "007394\n",
      "005992\n",
      "002012\n",
      "004786\n",
      "005641\n",
      "002354\n",
      "005805\n",
      "002992\n",
      "009904\n",
      "005829\n",
      "001408\n",
      "004229\n",
      "003905\n",
      "005285\n",
      "008865\n",
      "009656\n",
      "004466\n",
      "005563\n",
      "006438\n",
      "008082\n",
      "008533\n",
      "007793\n",
      "006041\n",
      "007746\n",
      "006348\n",
      "005395\n",
      "007704\n",
      "007814\n",
      "002101\n",
      "009917\n",
      "008285\n",
      "005263\n",
      "006781\n",
      "006893\n",
      "002125\n",
      "007056\n",
      "009685\n",
      "005214\n",
      "001061\n",
      "005036\n",
      "009772\n",
      "006719\n",
      "000005\n",
      "004805\n",
      "002265\n",
      "005713\n",
      "004051\n",
      "008427\n",
      "000336\n",
      "002697\n",
      "005014\n",
      "001654\n",
      "006599\n",
      "008083\n",
      "008203\n",
      "008615\n",
      "001595\n",
      "003681\n",
      "009160\n",
      "008793\n",
      "001073\n",
      "000158\n",
      "002136\n",
      "005245\n",
      "003044\n",
      "009944\n",
      "003536\n",
      "009445\n",
      "003566\n",
      "001576\n",
      "005325\n",
      "001079\n",
      "008261\n",
      "002835\n",
      "008151\n",
      "004651\n",
      "006105\n",
      "003684\n",
      "003157\n",
      "001064\n",
      "004057\n",
      "008284\n",
      "006667\n",
      "004255\n",
      "007413\n",
      "007457\n",
      "006551\n",
      "008534\n",
      "007133\n",
      "007039\n",
      "008197\n",
      "009717\n",
      "001539\n",
      "001074\n",
      "007416\n",
      "007715\n",
      "005090\n",
      "003063\n",
      "008130\n",
      "003651\n",
      "005288\n",
      "008200\n",
      "003122\n",
      "002779\n",
      "002627\n",
      "002886\n",
      "003258\n",
      "001721\n",
      "007074\n",
      "000583\n",
      "002117\n",
      "004592\n",
      "005963\n",
      "002893\n",
      "007760\n",
      "003186\n",
      "000232\n",
      "004052\n",
      "002647\n",
      "005680\n",
      "004549\n",
      "002943\n",
      "000344\n",
      "003861\n",
      "006095\n",
      "009401\n",
      "007555\n",
      "002648\n",
      "007590\n",
      "006183\n",
      "006983\n",
      "004220\n",
      "004902\n",
      "008585\n",
      "007189\n",
      "002233\n",
      "005104\n",
      "006664\n",
      "009808\n",
      "001142\n",
      "006250\n",
      "004092\n",
      "007615\n",
      "001199\n",
      "002721\n",
      "005290\n",
      "005026\n",
      "001270\n",
      "005345\n",
      "001597\n",
      "007216\n",
      "009880\n",
      "007167\n",
      "003814\n",
      "009732\n",
      "002285\n",
      "006892\n",
      "002248\n",
      "000491\n",
      "003625\n",
      "001928\n",
      "006139\n",
      "007344\n",
      "007834\n",
      "009851\n",
      "002391\n",
      "001062\n",
      "009446\n",
      "002817\n",
      "000523\n",
      "008923\n",
      "002523\n",
      "009517\n",
      "009638\n",
      "006166\n",
      "001258\n",
      "004204\n",
      "008450\n",
      "001543\n",
      "000936\n",
      "002545\n",
      "008769\n",
      "005781\n",
      "009457\n",
      "000209\n",
      "004714\n",
      "003000\n",
      "008676\n",
      "000387\n",
      "004066\n",
      "007765\n",
      "009747\n",
      "009327\n",
      "009005\n",
      "006726\n",
      "002361\n",
      "004318\n",
      "003086\n",
      "003846\n",
      "000483\n",
      "005615\n",
      "009949\n",
      "009288\n",
      "001598\n",
      "006747\n",
      "008813\n",
      "006731\n",
      "000343\n",
      "008229\n",
      "004087\n",
      "004750\n",
      "003415\n",
      "009242\n",
      "008297\n",
      "007460\n",
      "001221\n",
      "008444\n",
      "000543\n",
      "002524\n",
      "005371\n",
      "006473\n",
      "005881\n",
      "000832\n",
      "007682\n",
      "001404\n",
      "003919\n",
      "007735\n",
      "005068\n",
      "004867\n",
      "009128\n",
      "000177\n",
      "008023\n",
      "009208\n",
      "006784\n",
      "000242\n",
      "005704\n",
      "006470\n",
      "009147\n",
      "004907\n",
      "005699\n",
      "007732\n",
      "007035\n",
      "004794\n",
      "002994\n",
      "009236\n",
      "002710\n",
      "003255\n",
      "002219\n",
      "002662\n",
      "001277\n",
      "001466\n",
      "001204\n",
      "002691\n",
      "004312\n",
      "009392\n",
      "001004\n",
      "006079\n",
      "008429\n",
      "007680\n",
      "000170\n",
      "001237\n",
      "000700\n",
      "005338\n",
      "001864\n",
      "005863\n",
      "008029\n",
      "008017\n",
      "008072\n",
      "002476\n",
      "008492\n",
      "001109\n",
      "005159\n",
      "008773\n",
      "008584\n",
      "006000\n",
      "003451\n",
      "006576\n",
      "001647\n",
      "001563\n",
      "002350\n",
      "008752\n",
      "004265\n",
      "007025\n",
      "009541\n",
      "003417\n",
      "009349\n",
      "009212\n",
      "008665\n",
      "003228\n",
      "003370\n",
      "005674\n",
      "001206\n",
      "008601\n",
      "005212\n",
      "006694\n",
      "008323\n",
      "000083\n",
      "004010\n",
      "004551\n",
      "006374\n",
      "000307\n",
      "007180\n",
      "003367\n",
      "007408\n",
      "003164\n",
      "007924\n",
      "004143\n",
      "006338\n",
      "002586\n",
      "001799\n",
      "009373\n",
      "000428\n",
      "007688\n",
      "002778\n",
      "002669\n",
      "003786\n",
      "005894\n",
      "008581\n",
      "005752\n",
      "006196\n",
      "002820\n",
      "003956\n",
      "002305\n",
      "004508\n",
      "003211\n",
      "002957\n",
      "002962\n",
      "009920\n",
      "007939\n",
      "001187\n",
      "005150\n",
      "009112\n",
      "009666\n",
      "000263\n",
      "000776\n",
      "001561\n",
      "001640\n",
      "008064\n",
      "007546\n",
      "009946\n",
      "000860\n",
      "004076\n",
      "003200\n",
      "009830\n",
      "009174\n",
      "000241\n",
      "009443\n",
      "007089\n",
      "007396\n",
      "008702\n",
      "009591\n",
      "006797\n",
      "002984\n",
      "007356\n",
      "004606\n",
      "005813\n",
      "006722\n",
      "001630\n",
      "002798\n",
      "003146\n",
      "007790\n",
      "002114\n",
      "002377\n",
      "002187\n",
      "004753\n",
      "007865\n",
      "008524\n",
      "006621\n",
      "001818\n",
      "008618\n",
      "002533\n",
      "000612\n",
      "008051\n",
      "004796\n",
      "001528\n",
      "007854\n",
      "005601\n",
      "007049\n",
      "008888\n",
      "005705\n",
      "009138\n",
      "007152\n",
      "003194\n",
      "003489\n",
      "002496\n",
      "005629\n",
      "004232\n",
      "002329\n",
      "001427\n",
      "001362\n",
      "004490\n",
      "003313\n",
      "003530\n",
      "004832\n",
      "009693\n",
      "003242\n",
      "006252\n",
      "005710\n",
      "002176\n",
      "002870\n",
      "000503\n",
      "005306\n",
      "007696\n",
      "004085\n",
      "005912\n",
      "009410\n",
      "006042\n",
      "006503\n",
      "006185\n",
      "003664\n",
      "001887\n",
      "001009\n",
      "008475\n",
      "007603\n",
      "001383\n",
      "003292\n",
      "002415\n",
      "008175\n",
      "001333\n",
      "002202\n",
      "003254\n",
      "003015\n",
      "001175\n",
      "009831\n",
      "009060\n",
      "004609\n",
      "008282\n",
      "000923\n",
      "008953\n",
      "004223\n",
      "009342\n",
      "002220\n",
      "000918\n",
      "003175\n",
      "007363\n",
      "009627\n",
      "005782\n",
      "003879\n",
      "008519\n",
      "004270\n",
      "003679\n",
      "001324\n",
      "005861\n",
      "002675\n",
      "000626\n",
      "001604\n",
      "004304\n",
      "004360\n",
      "008836\n",
      "007666\n",
      "008749\n",
      "009862\n",
      "000709\n",
      "003645\n",
      "009048\n",
      "005451\n",
      "003231\n",
      "003889\n",
      "009488\n",
      "007193\n",
      "000874\n",
      "004830\n",
      "006835\n",
      "001402\n",
      "007594\n",
      "003796\n",
      "001586\n",
      "007909\n",
      "004100\n",
      "003102\n",
      "004839\n",
      "007383\n",
      "000508\n",
      "007923\n",
      "004351\n",
      "007369\n",
      "005129\n",
      "008943\n",
      "009780\n",
      "009114\n",
      "001240\n",
      "004200\n",
      "001872\n",
      "004563\n",
      "007159\n",
      "008636\n",
      "003993\n",
      "003899\n",
      "009713\n",
      "005583\n",
      "002539\n",
      "004625\n",
      "002441\n",
      "003657\n",
      "009762\n",
      "002569\n",
      "006029\n",
      "004329\n",
      "005102\n",
      "003120\n",
      "006290\n",
      "001230\n",
      "001749\n",
      "000391\n",
      "000601\n",
      "000653\n",
      "001940\n",
      "004878\n",
      "008368\n",
      "007633\n",
      "008142\n",
      "005499\n",
      "004761\n",
      "003336\n",
      "002924\n",
      "001785\n",
      "009748\n",
      "004178\n",
      "004067\n",
      "003838\n",
      "003606\n",
      "007449\n",
      "000091\n",
      "000750\n",
      "004138\n",
      "008983\n",
      "003632\n",
      "005406\n",
      "003056\n",
      "001747\n",
      "007417\n",
      "009558\n",
      "009296\n",
      "000095\n",
      "007511\n",
      "003413\n",
      "005940\n",
      "000046\n",
      "002919\n",
      "009386\n",
      "000935\n",
      "004866\n",
      "003250\n",
      "002737\n",
      "000220\n",
      "004246\n",
      "002025\n",
      "001903\n",
      "000738\n",
      "006648\n",
      "005819\n",
      "008262\n",
      "009842\n",
      "000999\n",
      "009326\n",
      "006838\n",
      "007685\n",
      "000822\n",
      "009897\n",
      "004879\n",
      "006773\n",
      "008144\n",
      "000235\n",
      "009438\n",
      "006786\n",
      "003420\n",
      "006762\n",
      "008776\n",
      "008931\n",
      "000306\n",
      "007540\n",
      "005344\n",
      "001588\n",
      "006868\n",
      "007204\n",
      "005814\n",
      "000323\n",
      "004856\n",
      "007373\n",
      "002534\n",
      "000712\n",
      "004106\n",
      "004863\n",
      "008966\n",
      "001212\n",
      "009455\n",
      "002238\n",
      "000023\n",
      "009734\n",
      "000731\n",
      "003290\n",
      "009918\n",
      "008365\n",
      "009692\n",
      "006556\n",
      "009408\n",
      "001375\n",
      "001833\n",
      "008326\n",
      "008499\n",
      "000050\n",
      "003779\n",
      "005215\n",
      "000200\n",
      "001754\n",
      "004298\n",
      "002435\n",
      "001072\n",
      "008424\n",
      "007305\n",
      "000190\n",
      "004816\n",
      "002914\n",
      "004852\n",
      "003690\n",
      "007856\n",
      "003830\n",
      "008725\n",
      "009898\n",
      "000865\n",
      "007295\n",
      "006821\n",
      "000032\n",
      "005122\n",
      "008811\n",
      "003154\n",
      "000720\n",
      "000289\n",
      "007436\n",
      "005365\n",
      "002208\n",
      "008838\n",
      "005355\n",
      "007526\n",
      "009459\n",
      "003678\n",
      "004768\n",
      "001365\n",
      "008701\n",
      "005315\n",
      "006958\n",
      "002371\n",
      "009377\n",
      "000902\n",
      "005718\n",
      "002713\n",
      "007329\n",
      "005348\n",
      "001682\n",
      "002037\n",
      "000780\n",
      "003236\n",
      "008880\n",
      "002433\n",
      "009333\n",
      "005573\n",
      "002940\n",
      "000895\n",
      "003937\n",
      "008173\n",
      "003611\n",
      "004247\n",
      "008799\n",
      "001782\n",
      "000159\n",
      "003188\n",
      "009175\n",
      "003750\n",
      "009877\n",
      "009202\n",
      "008559\n",
      "009186\n",
      "000711\n",
      "005331\n",
      "000676\n",
      "002730\n",
      "006660\n",
      "003639\n",
      "005874\n",
      "003327\n",
      "001931\n",
      "007824\n",
      "006886\n",
      "003216\n",
      "007675\n",
      "003469\n",
      "001386\n",
      "009287\n",
      "005183\n",
      "009629\n",
      "001309\n",
      "002956\n",
      "002466\n",
      "008691\n",
      "004060\n",
      "008385\n",
      "005769\n",
      "005693\n",
      "009022\n",
      "004748\n",
      "009358\n",
      "004499\n",
      "005983\n",
      "000331\n",
      "003564\n",
      "000174\n",
      "004322\n",
      "003074\n",
      "004141\n",
      "001028\n",
      "003811\n",
      "001053\n",
      "000920\n",
      "009822\n",
      "001853\n",
      "005257\n",
      "009879\n",
      "007999\n",
      "005742\n",
      "000966\n",
      "006668\n",
      "004224\n",
      "007154\n",
      "002549\n",
      "007563\n",
      "003365\n",
      "002875\n",
      "007298\n",
      "005821\n",
      "006161\n",
      "004890\n",
      "001147\n",
      "006254\n",
      "005640\n",
      "005731\n",
      "003936\n",
      "007042\n",
      "000991\n",
      "007543\n",
      "003240\n",
      "001713\n",
      "006934\n",
      "001685\n",
      "004779\n",
      "005171\n",
      "003024\n",
      "006637\n",
      "000498\n",
      "000926\n",
      "003452\n",
      "000250\n",
      "006295\n",
      "009858\n",
      "007168\n",
      "009845\n",
      "006429\n",
      "004091\n",
      "002585\n",
      "000609\n",
      "008713\n",
      "001060\n",
      "009042\n",
      "005455\n",
      "007926\n",
      "006349\n",
      "001436\n",
      "005914\n",
      "008892\n",
      "003998\n",
      "001092\n",
      "003685\n",
      "007773\n",
      "009678\n",
      "009184\n",
      "005190\n",
      "000987\n",
      "006962\n",
      "000863\n",
      "000268\n",
      "006299\n",
      "006819\n",
      "006918\n",
      "009388\n",
      "006184\n",
      "006177\n",
      "007075\n",
      "001608\n",
      "009374\n",
      "004723\n",
      "007465\n",
      "008549\n",
      "008252\n",
      "003493\n",
      "005114\n",
      "002696\n",
      "003529\n",
      "000443\n",
      "003078\n",
      "003859\n",
      "000768\n",
      "005124\n",
      "008222\n",
      "009024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005108\n",
      "005917\n",
      "000672\n",
      "005268\n",
      "000035\n",
      "000102\n",
      "001057\n",
      "000827\n",
      "006206\n",
      "001882\n",
      "004148\n",
      "001772\n",
      "003477\n",
      "004948\n",
      "000688\n",
      "006734\n",
      "003996\n",
      "006605\n",
      "006483\n",
      "006158\n",
      "006425\n",
      "009551\n",
      "007385\n",
      "005336\n",
      "004783\n",
      "001577\n",
      "004836\n",
      "004095\n",
      "004655\n",
      "004273\n",
      "000713\n",
      "003740\n",
      "007916\n",
      "009580\n",
      "007626\n",
      "004898\n",
      "000786\n",
      "005773\n",
      "009707\n",
      "000430\n",
      "007841\n",
      "003377\n",
      "002334\n",
      "003499\n",
      "006241\n",
      "000214\n",
      "005033\n",
      "004793\n",
      "009755\n",
      "002461\n",
      "002605\n",
      "003138\n",
      "007486\n",
      "001862\n",
      "000537\n",
      "007374\n",
      "003605\n",
      "006330\n",
      "006170\n",
      "007250\n",
      "006071\n",
      "000042\n",
      "006488\n",
      "003886\n",
      "009568\n",
      "002102\n",
      "003339\n",
      "003555\n",
      "003034\n",
      "003205\n",
      "000460\n",
      "004785\n",
      "001288\n",
      "004075\n",
      "000189\n",
      "009761\n",
      "002221\n",
      "001263\n",
      "007422\n",
      "001330\n",
      "008624\n",
      "007210\n",
      "002315\n",
      "003784\n",
      "007182\n",
      "006004\n",
      "002494\n",
      "005136\n",
      "006626\n",
      "009448\n",
      "009351\n",
      "005239\n",
      "006833\n",
      "004164\n",
      "008815\n",
      "009412\n",
      "008790\n",
      "002004\n",
      "007819\n",
      "008862\n",
      "002827\n",
      "004303\n",
      "007458\n",
      "001999\n",
      "005461\n",
      "003609\n",
      "007723\n",
      "006462\n",
      "004812\n",
      "003009\n",
      "006740\n",
      "007184\n",
      "001780\n",
      "005037\n",
      "002201\n",
      "001027\n",
      "002364\n",
      "006842\n",
      "009781\n",
      "003455\n",
      "001451\n",
      "007489\n",
      "001972\n",
      "001557\n",
      "009800\n",
      "001699\n",
      "004574\n",
      "007868\n",
      "002646\n",
      "004275\n",
      "007477\n",
      "002375\n",
      "005579\n",
      "009687\n",
      "008477\n",
      "007513\n",
      "006033\n",
      "008930\n",
      "008387\n",
      "008753\n",
      "005588\n",
      "008140\n",
      "006971\n",
      "000194\n",
      "001312\n",
      "008522\n",
      "000559\n",
      "003058\n",
      "007889\n",
      "006176\n",
      "009533\n",
      "008858\n",
      "002609\n",
      "000647\n",
      "003788\n",
      "006689\n",
      "004386\n",
      "008159\n",
      "009440\n",
      "003941\n",
      "000404\n",
      "004215\n",
      "007177\n",
      "000948\n",
      "002323\n",
      "003458\n",
      "000753\n",
      "007483\n",
      "004016\n",
      "008848\n",
      "005552\n",
      "005509\n",
      "007144\n",
      "004679\n",
      "007963\n",
      "008484\n",
      "002977\n",
      "001017\n",
      "006492\n",
      "007749\n",
      "005879\n",
      "003092\n",
      "009460\n",
      "001484\n",
      "007920\n",
      "003623\n",
      "007640\n",
      "005860\n",
      "000063\n",
      "006341\n",
      "007045\n",
      "000117\n",
      "008587\n",
      "005396\n",
      "003492\n",
      "001937\n",
      "008837\n",
      "009773\n",
      "002359\n",
      "009955\n",
      "000599\n",
      "006392\n",
      "006808\n",
      "007524\n",
      "002196\n",
      "009178\n",
      "006708\n",
      "009848\n",
      "008687\n",
      "000525\n",
      "000427\n",
      "003966\n",
      "002444\n",
      "005853\n",
      "006766\n",
      "003089\n",
      "008604\n",
      "009429\n",
      "000468\n",
      "008002\n",
      "006585\n",
      "001962\n",
      "001725\n",
      "007836\n",
      "002783\n",
      "000288\n",
      "002784\n",
      "007964\n",
      "000917\n",
      "002124\n",
      "009279\n",
      "005599\n",
      "003748\n",
      "006096\n",
      "007673\n",
      "001810\n",
      "009200\n",
      "004263\n",
      "009546\n",
      "003751\n",
      "000161\n",
      "007691\n",
      "004507\n",
      "001855\n",
      "004231\n",
      "009526\n",
      "001015\n",
      "006447\n",
      "001265\n",
      "002963\n",
      "006908\n",
      "000016\n",
      "009863\n",
      "007991\n",
      "002618\n",
      "009699\n",
      "003386\n",
      "006768\n",
      "004790\n",
      "006953\n",
      "001650\n",
      "000843\n",
      "006045\n",
      "005527\n",
      "000302\n",
      "008770\n",
      "001457\n",
      "001052\n",
      "009654\n",
      "004331\n",
      "004347\n",
      "007448\n",
      "001497\n",
      "003519\n",
      "005063\n",
      "007736\n",
      "002001\n",
      "005128\n",
      "005453\n",
      "001101\n",
      "009029\n",
      "004292\n",
      "003673\n",
      "004455\n",
      "007779\n",
      "008359\n",
      "002237\n",
      "002251\n",
      "003565\n",
      "003282\n",
      "005389\n",
      "000530\n",
      "006597\n",
      "001836\n",
      "007547\n",
      "003106\n",
      "008254\n",
      "002249\n",
      "007123\n",
      "004259\n",
      "003436\n",
      "002791\n",
      "007245\n",
      "001421\n",
      "008370\n",
      "002000\n",
      "000820\n",
      "008608\n",
      "005762\n",
      "008086\n",
      "007622\n",
      "002937\n",
      "004352\n",
      "007527\n",
      "009268\n",
      "005547\n",
      "006736\n",
      "003181\n",
      "002163\n",
      "009121\n",
      "003404\n",
      "000848\n",
      "005199\n",
      "007655\n",
      "002450\n",
      "009887\n",
      "002939\n",
      "004643\n",
      "002659\n",
      "006247\n",
      "009664\n",
      "002547\n",
      "005337\n",
      "008087\n",
      "001225\n",
      "008513\n",
      "002714\n",
      "003948\n",
      "005073\n",
      "008730\n",
      "008374\n",
      "004039\n",
      "003223\n",
      "000222\n",
      "007647\n",
      "003669\n",
      "004241\n",
      "003134\n",
      "006234\n",
      "009339\n",
      "001211\n",
      "001510\n",
      "006612\n",
      "004770\n",
      "000632\n",
      "007946\n",
      "003422\n",
      "007497\n",
      "002293\n",
      "008835\n",
      "002519\n",
      "008164\n",
      "009790\n",
      "007439\n",
      "005608\n",
      "007664\n",
      "005168\n",
      "002456\n",
      "008932\n",
      "002108\n",
      "004983\n",
      "005071\n",
      "009623\n",
      "002030\n",
      "000590\n",
      "006240\n",
      "009729\n",
      "004230\n",
      "007571\n",
      "007431\n",
      "007114\n",
      "006844\n",
      "007758\n",
      "008690\n",
      "001723\n",
      "007979\n",
      "006351\n",
      "000355\n",
      "006806\n",
      "004797\n",
      "002255\n",
      "003053\n",
      "000007\n",
      "008224\n",
      "007592\n",
      "002565\n",
      "001450\n",
      "007187\n",
      "009774\n",
      "007283\n",
      "003082\n",
      "008733\n",
      "000499\n",
      "004487\n",
      "008913\n",
      "001752\n",
      "005672\n",
      "009409\n",
      "006286\n",
      "007578\n",
      "006501\n",
      "002782\n",
      "006619\n",
      "003845\n",
      "005327\n",
      "004540\n",
      "008403\n",
      "009566\n",
      "001707\n",
      "008351\n",
      "003550\n",
      "005889\n",
      "006899\n",
      "008260\n",
      "002772\n",
      "009560\n",
      "007813\n",
      "005696\n",
      "008004\n",
      "006212\n",
      "002214\n",
      "000772\n",
      "006188\n",
      "000484\n",
      "002049\n",
      "003696\n",
      "002088\n",
      "005676\n",
      "009789\n",
      "008878\n",
      "003344\n",
      "001571\n",
      "004849\n",
      "009573\n",
      "001958\n",
      "001565\n",
      "001512\n",
      "005047\n",
      "007323\n",
      "004518\n",
      "007530\n",
      "006366\n",
      "007437\n",
      "002335\n",
      "001733\n",
      "004264\n",
      "000039\n",
      "005836\n",
      "005554\n",
      "008281\n",
      "009504\n",
      "009852\n",
      "001315\n",
      "006433\n",
      "008084\n",
      "002382\n",
      "008472\n",
      "006917\n",
      "007740\n",
      "008204\n",
      "002068\n",
      "009737\n",
      "002002\n",
      "001807\n",
      "005067\n",
      "003691\n",
      "009668\n",
      "006887\n",
      "003269\n",
      "006180\n",
      "002986\n",
      "000446\n",
      "002796\n",
      "009269\n",
      "002027\n",
      "006296\n",
      "001714\n",
      "005231\n",
      "002677\n",
      "000951\n",
      "009911\n",
      "000419\n",
      "007217\n",
      "003351\n",
      "006100\n",
      "002702\n",
      "007334\n",
      "005657\n",
      "002169\n",
      "009417\n",
      "006813\n",
      "000163\n",
      "003549\n",
      "008867\n",
      "002090\n",
      "004397\n",
      "004205\n",
      "006218\n",
      "000153\n",
      "008019\n",
      "005991\n",
      "001941\n",
      "001632\n",
      "008335\n",
      "003990\n",
      "009466\n",
      "002442\n",
      "007020\n",
      "005660\n",
      "002615\n",
      "004326\n",
      "005524\n",
      "004702\n",
      "006865\n",
      "006371\n",
      "008747\n",
      "003662\n",
      "009540\n",
      "000900\n",
      "008388\n",
      "000147\n",
      "005791\n",
      "005747\n",
      "003656\n",
      "009874\n",
      "009254\n",
      "008434\n",
      "008750\n",
      "007935\n",
      "006542\n",
      "006223\n",
      "006428\n",
      "004113\n",
      "001888\n",
      "007748\n",
      "004990\n",
      "000868\n",
      "003178\n",
      "000334\n",
      "005024\n",
      "009550\n",
      "005539\n",
      "004691\n",
      "007677\n",
      "005654\n",
      "000564\n",
      "000565\n",
      "006930\n",
      "008166\n",
      "009923\n",
      "005757\n",
      "000828\n",
      "002513\n",
      "003735\n",
      "009763\n",
      "004031\n",
      "002670\n",
      "000962\n",
      "000540\n",
      "008841\n",
      "008105\n",
      "009192\n",
      "004622\n",
      "002960\n",
      "002244\n",
      "001343\n",
      "009724\n",
      "006609\n",
      "007899\n",
      "003575\n",
      "000645\n",
      "005431\n",
      "004196\n",
      "006486\n",
      "000496\n",
      "003118\n",
      "009393\n",
      "003807\n",
      "002132\n",
      "009454\n",
      "004626\n",
      "001041\n",
      "008849\n",
      "006382\n",
      "001825\n",
      "007697\n",
      "001944\n",
      "002500\n",
      "006972\n",
      "005830\n",
      "004840\n",
      "002022\n",
      "005314\n",
      "000024\n",
      "005223\n",
      "002181\n",
      "002965\n",
      "003709\n",
      "009162\n",
      "007247\n",
      "004291\n",
      "007838\n",
      "001729\n",
      "007826\n",
      "005989\n",
      "000854\n",
      "004928\n",
      "001455\n",
      "002471\n",
      "002061\n",
      "005018\n",
      "007654\n",
      "001439\n",
      "001847\n",
      "000619\n",
      "003210\n",
      "007679\n",
      "000889\n",
      "006532\n",
      "004868\n",
      "005535\n",
      "002306\n",
      "004558\n",
      "007618\n",
      "003758\n",
      "009527\n",
      "001686\n",
      "007375\n",
      "004955\n",
      "000048\n",
      "000657\n",
      "006465\n",
      "000411\n",
      "008706\n",
      "004848\n",
      "003705\n",
      "008541\n",
      "006636\n",
      "000251\n",
      "009549\n",
      "006783\n",
      "007205\n",
      "002760\n",
      "003508\n",
      "002600\n",
      "009603\n",
      "007857\n",
      "006009\n",
      "008557\n",
      "003945\n",
      "008467\n",
      "000113\n",
      "000588\n",
      "009086\n",
      "004446\n",
      "004653\n",
      "001400\n",
      "008948\n",
      "008452\n",
      "005016\n",
      "000211\n",
      "007299\n",
      "005919\n",
      "001152\n",
      "001149\n",
      "001224\n",
      "006583\n",
      "003243\n",
      "001610\n",
      "006748\n",
      "001156\n",
      "003809\n",
      "006845\n",
      "007003\n",
      "005998\n",
      "002502\n",
      "005391\n",
      "009058\n",
      "003279\n",
      "004046\n",
      "001517\n",
      "009099\n",
      "007777\n",
      "007129\n",
      "005780\n",
      "000052\n",
      "003165\n",
      "003233\n",
      "006282\n",
      "005032\n",
      "006131\n",
      "000120\n",
      "001481\n",
      "000193\n",
      "004943\n",
      "003597\n",
      "000746\n",
      "005450\n",
      "000656\n",
      "006584\n",
      "005530\n",
      "007361\n",
      "002019\n",
      "006673\n",
      "003207\n",
      "004150\n",
      "000138\n",
      "005433\n",
      "005175\n",
      "006279\n",
      "003522\n",
      "006876\n",
      "001758\n",
      "000317\n",
      "001364\n",
      "005852\n",
      "000133\n",
      "001675\n",
      "006606\n",
      "003031\n",
      "001209\n",
      "005481\n",
      "008311\n",
      "009252\n",
      "007466\n",
      "008962\n",
      "008091\n",
      "006284\n",
      "008748\n",
      "008423\n",
      "005101\n",
      "007637\n",
      "007018\n",
      "006104\n",
      "004600\n",
      "006120\n",
      "000663\n",
      "006684\n",
      "007365\n",
      "006078\n",
      "005768\n",
      "007853\n",
      "002709\n",
      "005448\n",
      "000797\n",
      "001894\n",
      "000628\n",
      "007490\n",
      "001346\n",
      "002320\n",
      "006848\n",
      "003142\n",
      "007122\n",
      "009813\n",
      "000065\n",
      "001171\n",
      "005385\n",
      "002490\n",
      "003863\n",
      "003410\n",
      "005310\n",
      "008188\n",
      "004873\n",
      "008462\n",
      "005895\n",
      "001371\n",
      "005818\n",
      "005888\n",
      "007153\n",
      "004450\n",
      "008921\n",
      "005843\n",
      "006084\n",
      "003953\n",
      "004799\n",
      "003660\n",
      "005384\n",
      "008936\n",
      "001906\n",
      "008338\n",
      "005995\n",
      "008485\n",
      "006912\n",
      "005518\n",
      "004136\n",
      "000872\n",
      "005920\n",
      "007943\n",
      "002666\n",
      "005574\n",
      "003599\n",
      "003003\n",
      "007914\n",
      "004137\n",
      "007984\n",
      "005521\n",
      "008341\n",
      "006940\n",
      "008617\n",
      "008112\n",
      "003500\n",
      "006444\n",
      "004652\n",
      "008741\n",
      "005436\n",
      "007388\n",
      "000041\n",
      "004618\n",
      "007070\n",
      "001071\n",
      "006443\n",
      "002801\n",
      "004293\n",
      "004747\n",
      "001284\n",
      "002941\n",
      "000099\n",
      "009886\n",
      "002613\n",
      "005811\n",
      "004287\n",
      "005311\n",
      "005938\n",
      "001325\n",
      "003116\n",
      "002606\n",
      "003890\n",
      "005749\n",
      "000876\n",
      "000550\n",
      "003817\n",
      "007166\n",
      "009702\n",
      "001683\n",
      "004846\n",
      "009637\n",
      "009063\n",
      "000729\n",
      "002598\n",
      "002384\n",
      "003792\n",
      "009035\n",
      "004694\n",
      "000915\n",
      "006638\n",
      "000285\n",
      "005004\n",
      "005131\n",
      "001337\n",
      "006760\n",
      "005485\n",
      "001964\n",
      "000278\n",
      "006572\n",
      "007781\n",
      "001830\n",
      "001226\n",
      "006635\n",
      "003406\n",
      "006515\n",
      "004354\n",
      "009472\n",
      "009002\n",
      "003516\n",
      "004323\n",
      "007687\n",
      "006850\n",
      "005445\n",
      "001241\n",
      "004961\n",
      "007833\n",
      "003170\n",
      "008955\n",
      "003648\n",
      "000150\n",
      "004648\n",
      "003169\n",
      "007754\n",
      "007241\n",
      "009881\n",
      "006789\n",
      "009855\n",
      "004605\n",
      "005901\n",
      "007872\n",
      "005996\n",
      "005624\n",
      "001129\n",
      "009239\n",
      "009870\n",
      "000818\n",
      "000791\n",
      "003855\n",
      "000633\n",
      "004035\n",
      "006627\n",
      "007925\n",
      "008873\n",
      "009173\n",
      "000322\n",
      "006862\n",
      "001580\n",
      "004338\n",
      "005954\n",
      "001293\n",
      "001907\n",
      "006430\n",
      "000541\n",
      "008386\n",
      "009758\n",
      "002261\n",
      "005687\n",
      "008976\n",
      "004221\n",
      "009719\n",
      "004387\n",
      "004028\n",
      "002151\n",
      "001130\n",
      "005664\n",
      "008349\n",
      "002636\n",
      "001784\n",
      "000911\n",
      "005084\n",
      "002544\n",
      "007343\n",
      "000752\n",
      "007537\n",
      "005093\n",
      "008612\n",
      "001611\n",
      "004424\n",
      "009000\n",
      "002439\n",
      "004327\n",
      "004972\n",
      "007786\n",
      "000857\n",
      "009004\n",
      "005367\n",
      "001545\n",
      "008079\n",
      "006117\n",
      "004014\n",
      "007002\n",
      "004792\n",
      "007657\n",
      "005439\n",
      "004994\n",
      "005224\n",
      "001161\n",
      "004886\n",
      "009615\n",
      "001960\n",
      "008057\n",
      "007911\n",
      "007702\n",
      "002436\n",
      "000774\n",
      "003443\n",
      "009658\n",
      "004488\n",
      "001124\n",
      "001915\n",
      "005559\n",
      "002664\n",
      "005645\n",
      "003301\n",
      "003818\n",
      "007165\n",
      "001911\n",
      "005065\n",
      "007461\n",
      "005262\n",
      "006135\n",
      "001323\n",
      "003772\n",
      "008163\n",
      "000123\n",
      "001191\n",
      "006012\n",
      "005817\n",
      "005195\n",
      "002841\n",
      "004985\n",
      "002142\n",
      "000396\n",
      "004280\n",
      "003635\n",
      "007234\n",
      "006822\n",
      "008512\n",
      "000294\n",
      "002182\n",
      "007570\n",
      "007845\n",
      "006318\n",
      "005260\n",
      "005611\n",
      "002910\n",
      "009187\n",
      "007629\n",
      "006547\n",
      "003270\n",
      "001279\n",
      "008315\n",
      "005961\n",
      "006367\n",
      "006981\n",
      "006151\n",
      "004163\n",
      "000173\n",
      "004212\n",
      "008602\n",
      "009515\n",
      "006434\n",
      "008670\n",
      "005423\n",
      "000118\n",
      "008969\n",
      "000733\n",
      "001361\n",
      "000112\n",
      "003330\n",
      "004689\n",
      "004951\n",
      "003273\n",
      "009106\n",
      "008764\n",
      "003711\n",
      "007433\n",
      "006543\n",
      "003484\n",
      "003640\n",
      "006565\n",
      "005312\n",
      "002443\n",
      "001730\n",
      "005603\n",
      "000694\n",
      "003005\n",
      "000855\n",
      "001618\n",
      "009116\n",
      "000072\n",
      "002373\n",
      "005293\n",
      "002554\n",
      "009336\n",
      "009545\n",
      "004058\n",
      "002199\n",
      "007467\n",
      "005320\n",
      "006073\n",
      "005765\n",
      "001661\n",
      "001724\n",
      "008397\n",
      "005644\n",
      "001795\n",
      "009251\n",
      "004818\n",
      "009932\n",
      "009839\n",
      "005511\n",
      "008251\n",
      "008530\n",
      "002425\n",
      "006190\n",
      "002735\n",
      "006495\n",
      "005121\n",
      "001673\n",
      "003729\n",
      "002411\n",
      "005515\n",
      "003065\n",
      "006219\n",
      "006141\n",
      "002483\n",
      "006988\n",
      "002868\n",
      "009006\n",
      "009754\n",
      "008095\n",
      "009249\n",
      "000340\n",
      "000207\n",
      "009129\n",
      "007705\n",
      "000262\n",
      "000871\n",
      "003752\n",
      "008806\n",
      "000739\n",
      "003749\n",
      "000830\n",
      "002280\n",
      "006759\n",
      "009797\n",
      "002763\n",
      "001488\n",
      "001460\n",
      "004801\n",
      "001194\n",
      "007090\n",
      "004493\n",
      "003424\n",
      "008160\n",
      "000671\n",
      "009100\n",
      "007869\n",
      "005714\n",
      "000101\n",
      "005497\n",
      "008739\n",
      "007031\n",
      "002635\n",
      "001985\n",
      "007873\n",
      "007113\n",
      "000044\n",
      "006956\n",
      "001800\n",
      "008717\n",
      "009414\n",
      "009598\n",
      "007902\n",
      "006976\n",
      "007743\n",
      "009166\n",
      "006362\n",
      "008890\n",
      "001514\n",
      "000492\n",
      "004954\n",
      "001541\n",
      "002045\n",
      "007775\n",
      "002975\n",
      "003973\n",
      "007270\n",
      "004982\n",
      "007174\n",
      "008384\n",
      "007653\n",
      "007346\n",
      "004686\n",
      "001653\n",
      "003954\n",
      "000009\n",
      "000513\n",
      "002765\n",
      "002407\n",
      "001207\n",
      "000184\n",
      "006578\n",
      "006235\n",
      "003028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001766\n",
      "009382\n",
      "008919\n",
      "007525\n",
      "003253\n",
      "002023\n",
      "005593\n",
      "008716\n",
      "003759\n",
      "000764\n",
      "001479\n",
      "004012\n",
      "000710\n",
      "001432\n",
      "009584\n",
      "003401\n",
      "007108\n",
      "006755\n",
      "006140\n",
      "005387\n",
      "000406\n",
      "005826\n",
      "001304\n",
      "004732\n",
      "002458\n",
      "000424\n",
      "006805\n",
      "000544\n",
      "007021\n",
      "002590\n",
      "008939\n",
      "002376\n",
      "006990\n",
      "002328\n",
      "001746\n",
      "006994\n",
      "001184\n",
      "003183\n",
      "009195\n",
      "000208\n",
      "006156\n",
      "000597\n",
      "006730\n",
      "009179\n",
      "004020\n",
      "001093\n",
      "003924\n",
      "004519\n",
      "004372\n",
      "005760\n",
      "003593\n",
      "008971\n",
      "001954\n",
      "004333\n",
      "008062\n",
      "005609\n",
      "003126\n",
      "002866\n",
      "001148\n",
      "003380\n",
      "006222\n",
      "004693\n",
      "008438\n",
      "005630\n",
      "006524\n",
      "009087\n",
      "006709\n",
      "003957\n",
      "001761\n",
      "003594\n",
      "006058\n",
      "005738\n",
      "006448\n",
      "006230\n",
      "009259\n",
      "008322\n",
      "009073\n",
      "003988\n",
      "008009\n",
      "006107\n",
      "002448\n",
      "001821\n",
      "009588\n",
      "003596\n",
      "003149\n",
      "006088\n",
      "009519\n",
      "005349\n",
      "005326\n",
      "008568\n",
      "004782\n",
      "005209\n",
      "000077\n",
      "005003\n",
      "004660\n",
      "008517\n",
      "007065\n",
      "004823\n",
      "008150\n",
      "007336\n",
      "009700\n",
      "007933\n",
      "000796\n",
      "008413\n",
      "001388\n",
      "007296\n",
      "002392\n",
      "007572\n",
      "007799\n",
      "002989\n",
      "002146\n",
      "006569\n",
      "006738\n",
      "002491\n",
      "008606\n",
      "007185\n",
      "009470\n",
      "006847\n",
      "003303\n",
      "005304\n",
      "001756\n",
      "001536\n",
      "006163\n",
      "009671\n",
      "002330\n",
      "005470\n",
      "007720\n",
      "005496\n",
      "005303\n",
      "008053\n",
      "005824\n",
      "000416\n",
      "007662\n",
      "000850\n",
      "003325\n",
      "004939\n",
      "005740\n",
      "009245\n",
      "003397\n",
      "009334\n",
      "004837\n",
      "001395\n",
      "009218\n",
      "005679\n",
      "002098\n",
      "006810\n",
      "000526\n",
      "005078\n",
      "004194\n",
      "005319\n",
      "000702\n",
      "003939\n",
      "008218\n",
      "007742\n",
      "006695\n",
      "003577\n",
      "003439\n",
      "009464\n",
      "002020\n",
      "004283\n",
      "001077\n",
      "004895\n",
      "001775\n",
      "005054\n",
      "003753\n",
      "002751\n",
      "004509\n",
      "005135\n",
      "003293\n",
      "006005\n",
      "008680\n",
      "004601\n",
      "008107\n",
      "004960\n",
      "009841\n",
      "002462\n",
      "008826\n",
      "001809\n",
      "009579\n",
      "001834\n",
      "002055\n",
      "009113\n",
      "005219\n",
      "001405\n",
      "003189\n",
      "009051\n",
      "008772\n",
      "002706\n",
      "002183\n",
      "009695\n",
      "004471\n",
      "004977\n",
      "005794\n",
      "003872\n",
      "007322\n",
      "002978\n",
      "005850\n",
      "008588\n",
      "000162\n",
      "008117\n",
      "006714\n",
      "007614\n",
      "009833\n",
      "004005\n",
      "007128\n",
      "004390\n",
      "002833\n",
      "004532\n",
      "009375\n",
      "000020\n",
      "000980\n",
      "007006\n",
      "009649\n",
      "004203\n",
      "004760\n",
      "001690\n",
      "002889\n",
      "004530\n",
      "008211\n",
      "009318\n",
      "002332\n",
      "008768\n",
      "009484\n",
      "002082\n",
      "003974\n",
      "001326\n",
      "008301\n",
      "009942\n",
      "003453\n",
      "000394\n",
      "006952\n",
      "008732\n",
      "001158\n",
      "007931\n",
      "003199\n",
      "003296\n",
      "001963\n",
      "002152\n",
      "005864\n",
      "009307\n",
      "001832\n",
      "005730\n",
      "002643\n",
      "005947\n",
      "007256\n",
      "007092\n",
      "002525\n",
      "006174\n",
      "006062\n",
      "004623\n",
      "008683\n",
      "007776\n",
      "004828\n",
      "002403\n",
      "007249\n",
      "003185\n",
      "002278\n",
      "008121\n",
      "002070\n",
      "001930\n",
      "008989\n",
      "003195\n",
      "008805\n",
      "006277\n",
      "007215\n",
      "006645\n",
      "008809\n",
      "001269\n",
      "003373\n",
      "001083\n",
      "002762\n",
      "001669\n",
      "001922\n",
      "001797\n",
      "009711\n",
      "005267\n",
      "004464\n",
      "000244\n",
      "004967\n",
      "000030\n",
      "003285\n",
      "009348\n",
      "007443\n",
      "006966\n",
      "006869\n",
      "008033\n",
      "006476\n",
      "007062\n",
      "000842\n",
      "009947\n",
      "002051\n",
      "007878\n",
      "004510\n",
      "001840\n",
      "006603\n",
      "005153\n",
      "006267\n",
      "008885\n",
      "002378\n",
      "000064\n",
      "000887\n",
      "003506\n",
      "004296\n",
      "001896\n",
      "001971\n",
      "000535\n",
      "005380\n",
      "008226\n",
      "004367\n",
      "000581\n",
      "008024\n",
      "003891\n",
      "005298\n",
      "008997\n",
      "007650\n",
      "008573\n",
      "000229\n",
      "007266\n",
      "001078\n",
      "005156\n",
      "006707\n",
      "009153\n",
      "000373\n",
      "008295\n",
      "003085\n",
      "006187\n",
      "002621\n"
     ]
    }
   ],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((resnet_input,resnet_input)),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor()])\n",
    "train_dataset = hound_dataset(root_dir='.', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "# test_dataset = hound_dataset(root_dir='.', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "Litlefinger has brought you a pre-trained network. Fine-tune the network in the following section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 21)\n",
    "\n",
    "# Add code for using CUDA here\n",
    "use_gpu = False\n",
    "if(torch.cuda.is_available()):\n",
    "    use_gpu = True\n",
    "    resnet18.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Update if any errors occur\n",
    "optimizer = torch.optim.SGD(resnet18.parameters(), learning_rate, hyp_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arya_train():\n",
    "    # Begin\n",
    "    loss_arr = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Convert torch tensor to Variable\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if(use_gpu):\n",
    "                images=images.cuda()\n",
    "                labels=labels.cuda()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = resnet18(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_arr.append(loss.data[0])\n",
    "            if (i+1) % batch_size == 0:\n",
    "                print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "    plt.plot( np.array(range(1,len(loss_arr)+1)), np.array(loss_arr))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2/10336], Loss: 3.1157\n",
      "Epoch [1/5], Step [4/10336], Loss: 3.1148\n",
      "Epoch [1/5], Step [6/10336], Loss: 1.2156\n",
      "Epoch [1/5], Step [8/10336], Loss: 2.6169\n",
      "Epoch [1/5], Step [10/10336], Loss: 2.1820\n",
      "Epoch [1/5], Step [12/10336], Loss: 5.2420\n",
      "Epoch [1/5], Step [14/10336], Loss: 1.4026\n",
      "Epoch [1/5], Step [16/10336], Loss: 3.1209\n",
      "Epoch [1/5], Step [18/10336], Loss: 2.3037\n",
      "Epoch [1/5], Step [20/10336], Loss: 3.1656\n",
      "Epoch [1/5], Step [22/10336], Loss: 5.3041\n",
      "Epoch [1/5], Step [24/10336], Loss: 3.9647\n",
      "Epoch [1/5], Step [26/10336], Loss: 2.3611\n",
      "Epoch [1/5], Step [28/10336], Loss: 3.7858\n",
      "Epoch [1/5], Step [30/10336], Loss: 2.4816\n",
      "Epoch [1/5], Step [32/10336], Loss: 4.4216\n",
      "Epoch [1/5], Step [34/10336], Loss: 2.8029\n",
      "Epoch [1/5], Step [36/10336], Loss: 1.7905\n",
      "Epoch [1/5], Step [38/10336], Loss: 3.5114\n",
      "Epoch [1/5], Step [40/10336], Loss: 4.8595\n",
      "Epoch [1/5], Step [42/10336], Loss: 1.9893\n",
      "Epoch [1/5], Step [44/10336], Loss: 2.3079\n",
      "Epoch [1/5], Step [46/10336], Loss: 4.2023\n",
      "Epoch [1/5], Step [48/10336], Loss: 3.2979\n",
      "Epoch [1/5], Step [50/10336], Loss: 0.7522\n",
      "Epoch [1/5], Step [52/10336], Loss: 1.3917\n",
      "Epoch [1/5], Step [54/10336], Loss: 1.6701\n",
      "Epoch [1/5], Step [56/10336], Loss: 0.9388\n",
      "Epoch [1/5], Step [58/10336], Loss: 3.1382\n",
      "Epoch [1/5], Step [60/10336], Loss: 0.9291\n",
      "Epoch [1/5], Step [62/10336], Loss: 2.4952\n",
      "Epoch [1/5], Step [64/10336], Loss: 4.9292\n",
      "Epoch [1/5], Step [66/10336], Loss: 1.6235\n",
      "Epoch [1/5], Step [68/10336], Loss: 2.8933\n",
      "Epoch [1/5], Step [70/10336], Loss: 3.3836\n",
      "Epoch [1/5], Step [72/10336], Loss: 1.0912\n",
      "Epoch [1/5], Step [74/10336], Loss: 2.0121\n",
      "Epoch [1/5], Step [76/10336], Loss: 1.9121\n",
      "Epoch [1/5], Step [78/10336], Loss: 3.8872\n",
      "Epoch [1/5], Step [80/10336], Loss: 3.2863\n",
      "Epoch [1/5], Step [82/10336], Loss: 3.2428\n",
      "Epoch [1/5], Step [84/10336], Loss: 0.2953\n",
      "Epoch [1/5], Step [86/10336], Loss: 2.0995\n",
      "Epoch [1/5], Step [88/10336], Loss: 3.5015\n",
      "Epoch [1/5], Step [90/10336], Loss: 3.3624\n",
      "Epoch [1/5], Step [92/10336], Loss: 2.8471\n",
      "Epoch [1/5], Step [94/10336], Loss: 2.3279\n",
      "Epoch [1/5], Step [96/10336], Loss: 2.9069\n",
      "Epoch [1/5], Step [98/10336], Loss: 2.0732\n",
      "Epoch [1/5], Step [100/10336], Loss: 4.3205\n",
      "Epoch [1/5], Step [102/10336], Loss: 3.2862\n",
      "Epoch [1/5], Step [104/10336], Loss: 1.0536\n",
      "Epoch [1/5], Step [106/10336], Loss: 1.2665\n",
      "Epoch [1/5], Step [108/10336], Loss: 5.5432\n",
      "Epoch [1/5], Step [110/10336], Loss: 2.6384\n",
      "Epoch [1/5], Step [112/10336], Loss: 2.9887\n",
      "Epoch [1/5], Step [114/10336], Loss: 2.8973\n",
      "Epoch [1/5], Step [116/10336], Loss: 1.6816\n",
      "Epoch [1/5], Step [118/10336], Loss: 1.1462\n",
      "Epoch [1/5], Step [120/10336], Loss: 5.3353\n",
      "Epoch [1/5], Step [122/10336], Loss: 0.3513\n",
      "Epoch [1/5], Step [124/10336], Loss: 2.0363\n",
      "Epoch [1/5], Step [126/10336], Loss: 2.6593\n",
      "Epoch [1/5], Step [128/10336], Loss: 3.5900\n",
      "Epoch [1/5], Step [130/10336], Loss: 3.4519\n",
      "Epoch [1/5], Step [132/10336], Loss: 1.3618\n",
      "Epoch [1/5], Step [134/10336], Loss: 2.3615\n",
      "Epoch [1/5], Step [136/10336], Loss: 3.2691\n",
      "Epoch [1/5], Step [138/10336], Loss: 2.8232\n",
      "Epoch [1/5], Step [140/10336], Loss: 1.0183\n",
      "Epoch [1/5], Step [142/10336], Loss: 3.0952\n",
      "Epoch [1/5], Step [144/10336], Loss: 3.8351\n",
      "Epoch [1/5], Step [146/10336], Loss: 2.1346\n",
      "Epoch [1/5], Step [148/10336], Loss: 2.1091\n",
      "Epoch [1/5], Step [150/10336], Loss: 1.9124\n",
      "Epoch [1/5], Step [152/10336], Loss: 1.7608\n",
      "Epoch [1/5], Step [154/10336], Loss: 0.1928\n",
      "Epoch [1/5], Step [156/10336], Loss: 0.8649\n",
      "Epoch [1/5], Step [158/10336], Loss: 0.8075\n",
      "Epoch [1/5], Step [160/10336], Loss: 4.4018\n",
      "Epoch [1/5], Step [162/10336], Loss: 2.0517\n",
      "Epoch [1/5], Step [164/10336], Loss: 0.8993\n",
      "Epoch [1/5], Step [166/10336], Loss: 2.4943\n",
      "Epoch [1/5], Step [168/10336], Loss: 0.7594\n",
      "Epoch [1/5], Step [170/10336], Loss: 4.4825\n",
      "Epoch [1/5], Step [172/10336], Loss: 2.7483\n",
      "Epoch [1/5], Step [174/10336], Loss: 2.3706\n",
      "Epoch [1/5], Step [176/10336], Loss: 2.9563\n",
      "Epoch [1/5], Step [178/10336], Loss: 3.8048\n",
      "Epoch [1/5], Step [180/10336], Loss: 2.5348\n",
      "Epoch [1/5], Step [182/10336], Loss: 1.6502\n",
      "Epoch [1/5], Step [184/10336], Loss: 6.3784\n",
      "Epoch [1/5], Step [186/10336], Loss: 5.6054\n",
      "Epoch [1/5], Step [188/10336], Loss: 4.3623\n",
      "Epoch [1/5], Step [190/10336], Loss: 1.6981\n",
      "Epoch [1/5], Step [192/10336], Loss: 3.2237\n",
      "Epoch [1/5], Step [194/10336], Loss: 2.3389\n",
      "Epoch [1/5], Step [196/10336], Loss: 3.5229\n",
      "Epoch [1/5], Step [198/10336], Loss: 1.9629\n",
      "Epoch [1/5], Step [200/10336], Loss: 3.1510\n",
      "Epoch [1/5], Step [202/10336], Loss: 4.0052\n",
      "Epoch [1/5], Step [204/10336], Loss: 0.1697\n",
      "Epoch [1/5], Step [206/10336], Loss: 2.4558\n",
      "Epoch [1/5], Step [208/10336], Loss: 4.6155\n",
      "Epoch [1/5], Step [210/10336], Loss: 2.6241\n",
      "Epoch [1/5], Step [212/10336], Loss: 3.5809\n",
      "Epoch [1/5], Step [214/10336], Loss: 4.5050\n",
      "Epoch [1/5], Step [216/10336], Loss: 3.3728\n",
      "Epoch [1/5], Step [218/10336], Loss: 1.4927\n",
      "Epoch [1/5], Step [220/10336], Loss: 2.9652\n",
      "Epoch [1/5], Step [222/10336], Loss: 1.0082\n",
      "Epoch [1/5], Step [224/10336], Loss: 2.9035\n",
      "Epoch [1/5], Step [226/10336], Loss: 5.3597\n",
      "Epoch [1/5], Step [228/10336], Loss: 2.5560\n",
      "Epoch [1/5], Step [230/10336], Loss: 3.1345\n",
      "Epoch [1/5], Step [232/10336], Loss: 3.9131\n",
      "Epoch [1/5], Step [234/10336], Loss: 1.3462\n",
      "Epoch [1/5], Step [236/10336], Loss: 1.8441\n",
      "Epoch [1/5], Step [238/10336], Loss: 0.7728\n",
      "Epoch [1/5], Step [240/10336], Loss: 1.4435\n",
      "Epoch [1/5], Step [242/10336], Loss: 0.1202\n",
      "Epoch [1/5], Step [244/10336], Loss: 0.7294\n",
      "Epoch [1/5], Step [246/10336], Loss: 3.5955\n",
      "Epoch [1/5], Step [248/10336], Loss: 0.8064\n",
      "Epoch [1/5], Step [250/10336], Loss: 2.1528\n",
      "Epoch [1/5], Step [252/10336], Loss: 0.5294\n",
      "Epoch [1/5], Step [254/10336], Loss: 0.4893\n",
      "Epoch [1/5], Step [256/10336], Loss: 4.0919\n",
      "Epoch [1/5], Step [258/10336], Loss: 0.4968\n",
      "Epoch [1/5], Step [260/10336], Loss: 0.9354\n",
      "Epoch [1/5], Step [262/10336], Loss: 3.7433\n",
      "Epoch [1/5], Step [264/10336], Loss: 7.5346\n",
      "Epoch [1/5], Step [266/10336], Loss: 0.1930\n",
      "Epoch [1/5], Step [268/10336], Loss: 4.8921\n",
      "Epoch [1/5], Step [270/10336], Loss: 2.1918\n",
      "Epoch [1/5], Step [272/10336], Loss: 2.7843\n",
      "Epoch [1/5], Step [274/10336], Loss: 1.3163\n",
      "Epoch [1/5], Step [276/10336], Loss: 2.8196\n",
      "Epoch [1/5], Step [278/10336], Loss: 1.9205\n",
      "Epoch [1/5], Step [280/10336], Loss: 1.4847\n",
      "Epoch [1/5], Step [282/10336], Loss: 0.6533\n",
      "Epoch [1/5], Step [284/10336], Loss: 1.7155\n",
      "Epoch [1/5], Step [286/10336], Loss: 1.3828\n",
      "Epoch [1/5], Step [288/10336], Loss: 0.5346\n",
      "Epoch [1/5], Step [290/10336], Loss: 1.2679\n",
      "Epoch [1/5], Step [292/10336], Loss: 2.2307\n",
      "Epoch [1/5], Step [294/10336], Loss: 2.4882\n",
      "Epoch [1/5], Step [296/10336], Loss: 2.2807\n",
      "Epoch [1/5], Step [298/10336], Loss: 2.2203\n",
      "Epoch [1/5], Step [300/10336], Loss: 3.5026\n",
      "Epoch [1/5], Step [302/10336], Loss: 1.2329\n",
      "Epoch [1/5], Step [304/10336], Loss: 3.8463\n",
      "Epoch [1/5], Step [306/10336], Loss: 2.8235\n",
      "Epoch [1/5], Step [308/10336], Loss: 1.9687\n",
      "Epoch [1/5], Step [310/10336], Loss: 3.9041\n",
      "Epoch [1/5], Step [312/10336], Loss: 5.8621\n",
      "Epoch [1/5], Step [314/10336], Loss: 4.5942\n",
      "Epoch [1/5], Step [316/10336], Loss: 5.6966\n",
      "Epoch [1/5], Step [318/10336], Loss: 3.1681\n",
      "Epoch [1/5], Step [320/10336], Loss: 3.8344\n",
      "Epoch [1/5], Step [322/10336], Loss: 2.5941\n",
      "Epoch [1/5], Step [324/10336], Loss: 3.8624\n",
      "Epoch [1/5], Step [326/10336], Loss: 0.1455\n",
      "Epoch [1/5], Step [328/10336], Loss: 0.5286\n",
      "Epoch [1/5], Step [330/10336], Loss: 1.7834\n",
      "Epoch [1/5], Step [332/10336], Loss: 1.3074\n",
      "Epoch [1/5], Step [334/10336], Loss: 1.0237\n",
      "Epoch [1/5], Step [336/10336], Loss: 4.9642\n",
      "Epoch [1/5], Step [338/10336], Loss: 3.7392\n",
      "Epoch [1/5], Step [340/10336], Loss: 2.1888\n",
      "Epoch [1/5], Step [342/10336], Loss: 2.3264\n",
      "Epoch [1/5], Step [344/10336], Loss: 0.7583\n",
      "Epoch [1/5], Step [346/10336], Loss: 1.4850\n",
      "Epoch [1/5], Step [348/10336], Loss: 2.1766\n",
      "Epoch [1/5], Step [350/10336], Loss: 3.5666\n",
      "Epoch [1/5], Step [352/10336], Loss: 4.5398\n",
      "Epoch [1/5], Step [354/10336], Loss: 2.5946\n",
      "Epoch [1/5], Step [356/10336], Loss: 2.1760\n",
      "Epoch [1/5], Step [358/10336], Loss: 0.9455\n",
      "Epoch [1/5], Step [360/10336], Loss: 1.0411\n",
      "Epoch [1/5], Step [362/10336], Loss: 2.8361\n",
      "Epoch [1/5], Step [364/10336], Loss: 3.1308\n",
      "Epoch [1/5], Step [366/10336], Loss: 1.2212\n",
      "Epoch [1/5], Step [368/10336], Loss: 0.4551\n",
      "Epoch [1/5], Step [370/10336], Loss: 4.1859\n",
      "Epoch [1/5], Step [372/10336], Loss: 3.2663\n",
      "Epoch [1/5], Step [374/10336], Loss: 0.9461\n",
      "Epoch [1/5], Step [376/10336], Loss: 2.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [378/10336], Loss: 0.4406\n",
      "Epoch [1/5], Step [380/10336], Loss: 4.9114\n",
      "Epoch [1/5], Step [382/10336], Loss: 0.7768\n",
      "Epoch [1/5], Step [384/10336], Loss: 3.1874\n",
      "Epoch [1/5], Step [386/10336], Loss: 1.7735\n",
      "Epoch [1/5], Step [388/10336], Loss: 2.0891\n",
      "Epoch [1/5], Step [390/10336], Loss: 2.3576\n",
      "Epoch [1/5], Step [392/10336], Loss: 3.7717\n",
      "Epoch [1/5], Step [394/10336], Loss: 0.2124\n",
      "Epoch [1/5], Step [396/10336], Loss: 4.4715\n",
      "Epoch [1/5], Step [398/10336], Loss: 0.3438\n",
      "Epoch [1/5], Step [400/10336], Loss: 1.0244\n",
      "Epoch [1/5], Step [402/10336], Loss: 1.9453\n",
      "Epoch [1/5], Step [404/10336], Loss: 0.2580\n",
      "Epoch [1/5], Step [406/10336], Loss: 2.3346\n",
      "Epoch [1/5], Step [408/10336], Loss: 2.4306\n",
      "Epoch [1/5], Step [410/10336], Loss: 1.3865\n",
      "Epoch [1/5], Step [412/10336], Loss: 0.9417\n",
      "Epoch [1/5], Step [414/10336], Loss: 1.2873\n",
      "Epoch [1/5], Step [416/10336], Loss: 1.0630\n",
      "Epoch [1/5], Step [418/10336], Loss: 0.8240\n",
      "Epoch [1/5], Step [420/10336], Loss: 0.8855\n",
      "Epoch [1/5], Step [422/10336], Loss: 4.6907\n",
      "Epoch [1/5], Step [424/10336], Loss: 5.5514\n",
      "Epoch [1/5], Step [426/10336], Loss: 0.2819\n",
      "Epoch [1/5], Step [428/10336], Loss: 3.3196\n",
      "Epoch [1/5], Step [430/10336], Loss: 3.2507\n",
      "Epoch [1/5], Step [432/10336], Loss: 2.6399\n",
      "Epoch [1/5], Step [434/10336], Loss: 2.0784\n",
      "Epoch [1/5], Step [436/10336], Loss: 1.5214\n",
      "Epoch [1/5], Step [438/10336], Loss: 0.6054\n",
      "Epoch [1/5], Step [440/10336], Loss: 5.8150\n",
      "Epoch [1/5], Step [442/10336], Loss: 0.2989\n",
      "Epoch [1/5], Step [444/10336], Loss: 2.3920\n",
      "Epoch [1/5], Step [446/10336], Loss: 3.8528\n",
      "Epoch [1/5], Step [448/10336], Loss: 2.3320\n",
      "Epoch [1/5], Step [450/10336], Loss: 3.6561\n",
      "Epoch [1/5], Step [452/10336], Loss: 4.2322\n",
      "Epoch [1/5], Step [454/10336], Loss: 3.7394\n",
      "Epoch [1/5], Step [456/10336], Loss: 1.1916\n",
      "Epoch [1/5], Step [458/10336], Loss: 2.4525\n",
      "Epoch [1/5], Step [460/10336], Loss: 3.3792\n",
      "Epoch [1/5], Step [462/10336], Loss: 0.7222\n",
      "Epoch [1/5], Step [464/10336], Loss: 4.0035\n",
      "Epoch [1/5], Step [466/10336], Loss: 1.9916\n",
      "Epoch [1/5], Step [468/10336], Loss: 4.0781\n",
      "Epoch [1/5], Step [470/10336], Loss: 1.6010\n",
      "Epoch [1/5], Step [472/10336], Loss: 2.5630\n",
      "Epoch [1/5], Step [474/10336], Loss: 4.1455\n",
      "Epoch [1/5], Step [476/10336], Loss: 1.4854\n",
      "Epoch [1/5], Step [478/10336], Loss: 2.0162\n",
      "Epoch [1/5], Step [480/10336], Loss: 2.9632\n",
      "Epoch [1/5], Step [482/10336], Loss: 3.2977\n",
      "Epoch [1/5], Step [484/10336], Loss: 3.4251\n",
      "Epoch [1/5], Step [486/10336], Loss: 3.8378\n",
      "Epoch [1/5], Step [488/10336], Loss: 1.7564\n",
      "Epoch [1/5], Step [490/10336], Loss: 1.2777\n",
      "Epoch [1/5], Step [492/10336], Loss: 2.1044\n",
      "Epoch [1/5], Step [494/10336], Loss: 1.9216\n",
      "Epoch [1/5], Step [496/10336], Loss: 1.9755\n",
      "Epoch [1/5], Step [498/10336], Loss: 1.4622\n",
      "Epoch [1/5], Step [500/10336], Loss: 5.8625\n",
      "Epoch [1/5], Step [502/10336], Loss: 0.1382\n",
      "Epoch [1/5], Step [504/10336], Loss: 4.4099\n",
      "Epoch [1/5], Step [506/10336], Loss: 1.9815\n",
      "Epoch [1/5], Step [508/10336], Loss: 2.8334\n",
      "Epoch [1/5], Step [510/10336], Loss: 0.6566\n",
      "Epoch [1/5], Step [512/10336], Loss: 0.4986\n",
      "Epoch [1/5], Step [514/10336], Loss: 0.1309\n",
      "Epoch [1/5], Step [516/10336], Loss: 0.7439\n",
      "Epoch [1/5], Step [518/10336], Loss: 1.6654\n",
      "Epoch [1/5], Step [520/10336], Loss: 1.9196\n",
      "Epoch [1/5], Step [522/10336], Loss: 2.1735\n",
      "Epoch [1/5], Step [524/10336], Loss: 0.1237\n",
      "Epoch [1/5], Step [526/10336], Loss: 2.0541\n",
      "Epoch [1/5], Step [528/10336], Loss: 0.1082\n",
      "Epoch [1/5], Step [530/10336], Loss: 1.3692\n",
      "Epoch [1/5], Step [532/10336], Loss: 0.7463\n",
      "Epoch [1/5], Step [534/10336], Loss: 2.9810\n",
      "Epoch [1/5], Step [536/10336], Loss: 0.8776\n",
      "Epoch [1/5], Step [538/10336], Loss: 2.9021\n",
      "Epoch [1/5], Step [540/10336], Loss: 1.2964\n",
      "Epoch [1/5], Step [542/10336], Loss: 4.6171\n",
      "Epoch [1/5], Step [544/10336], Loss: 1.3095\n",
      "Epoch [1/5], Step [546/10336], Loss: 1.2419\n",
      "Epoch [1/5], Step [548/10336], Loss: 2.6348\n",
      "Epoch [1/5], Step [550/10336], Loss: 2.6630\n",
      "Epoch [1/5], Step [552/10336], Loss: 2.2478\n",
      "Epoch [1/5], Step [554/10336], Loss: 1.7471\n",
      "Epoch [1/5], Step [556/10336], Loss: 4.2967\n",
      "Epoch [1/5], Step [558/10336], Loss: 2.7579\n",
      "Epoch [1/5], Step [560/10336], Loss: 2.4667\n",
      "Epoch [1/5], Step [562/10336], Loss: 0.3117\n",
      "Epoch [1/5], Step [564/10336], Loss: 2.2588\n",
      "Epoch [1/5], Step [566/10336], Loss: 2.6736\n",
      "Epoch [1/5], Step [568/10336], Loss: 3.1582\n",
      "Epoch [1/5], Step [570/10336], Loss: 1.5285\n",
      "Epoch [1/5], Step [572/10336], Loss: 0.3857\n",
      "Epoch [1/5], Step [574/10336], Loss: 0.7325\n",
      "Epoch [1/5], Step [576/10336], Loss: 1.4357\n",
      "Epoch [1/5], Step [578/10336], Loss: 3.7224\n",
      "Epoch [1/5], Step [580/10336], Loss: 2.6000\n",
      "Epoch [1/5], Step [582/10336], Loss: 0.7165\n",
      "Epoch [1/5], Step [584/10336], Loss: 3.4137\n",
      "Epoch [1/5], Step [586/10336], Loss: 2.0836\n",
      "Epoch [1/5], Step [588/10336], Loss: 0.9608\n",
      "Epoch [1/5], Step [590/10336], Loss: 1.5644\n",
      "Epoch [1/5], Step [592/10336], Loss: 1.3687\n",
      "Epoch [1/5], Step [594/10336], Loss: 1.9141\n",
      "Epoch [1/5], Step [596/10336], Loss: 1.9892\n",
      "Epoch [1/5], Step [598/10336], Loss: 1.4781\n",
      "Epoch [1/5], Step [600/10336], Loss: 3.5169\n",
      "Epoch [1/5], Step [602/10336], Loss: 3.1771\n",
      "Epoch [1/5], Step [604/10336], Loss: 0.8899\n",
      "Epoch [1/5], Step [606/10336], Loss: 1.8788\n",
      "Epoch [1/5], Step [608/10336], Loss: 1.7418\n",
      "Epoch [1/5], Step [610/10336], Loss: 0.9127\n",
      "Epoch [1/5], Step [612/10336], Loss: 1.0979\n",
      "Epoch [1/5], Step [614/10336], Loss: 1.8391\n",
      "Epoch [1/5], Step [616/10336], Loss: 0.1440\n",
      "Epoch [1/5], Step [618/10336], Loss: 5.0345\n",
      "Epoch [1/5], Step [620/10336], Loss: 2.6035\n",
      "Epoch [1/5], Step [622/10336], Loss: 2.4783\n",
      "Epoch [1/5], Step [624/10336], Loss: 2.1010\n",
      "Epoch [1/5], Step [626/10336], Loss: 1.9454\n",
      "Epoch [1/5], Step [628/10336], Loss: 2.8425\n",
      "Epoch [1/5], Step [630/10336], Loss: 0.1932\n",
      "Epoch [1/5], Step [632/10336], Loss: 4.0030\n",
      "Epoch [1/5], Step [634/10336], Loss: 3.4141\n",
      "Epoch [1/5], Step [636/10336], Loss: 3.5001\n",
      "Epoch [1/5], Step [638/10336], Loss: 0.6170\n",
      "Epoch [1/5], Step [640/10336], Loss: 0.5821\n",
      "Epoch [1/5], Step [642/10336], Loss: 0.6020\n",
      "Epoch [1/5], Step [644/10336], Loss: 1.7866\n",
      "Epoch [1/5], Step [646/10336], Loss: 1.8726\n",
      "Epoch [1/5], Step [648/10336], Loss: 6.1674\n",
      "Epoch [1/5], Step [650/10336], Loss: 0.6481\n",
      "Epoch [1/5], Step [652/10336], Loss: 3.4900\n",
      "Epoch [1/5], Step [654/10336], Loss: 1.1974\n",
      "Epoch [1/5], Step [656/10336], Loss: 2.6343\n",
      "Epoch [1/5], Step [658/10336], Loss: 2.6663\n",
      "Epoch [1/5], Step [660/10336], Loss: 1.6090\n",
      "Epoch [1/5], Step [662/10336], Loss: 2.7914\n",
      "Epoch [1/5], Step [664/10336], Loss: 3.0325\n",
      "Epoch [1/5], Step [666/10336], Loss: 4.9324\n",
      "Epoch [1/5], Step [668/10336], Loss: 1.5014\n",
      "Epoch [1/5], Step [670/10336], Loss: 2.7383\n",
      "Epoch [1/5], Step [672/10336], Loss: 2.4245\n",
      "Epoch [1/5], Step [674/10336], Loss: 2.5102\n",
      "Epoch [1/5], Step [676/10336], Loss: 3.0772\n",
      "Epoch [1/5], Step [678/10336], Loss: 3.3487\n",
      "Epoch [1/5], Step [680/10336], Loss: 2.3418\n",
      "Epoch [1/5], Step [682/10336], Loss: 2.0324\n",
      "Epoch [1/5], Step [684/10336], Loss: 2.6790\n",
      "Epoch [1/5], Step [686/10336], Loss: 6.1784\n",
      "Epoch [1/5], Step [688/10336], Loss: 1.1140\n",
      "Epoch [1/5], Step [690/10336], Loss: 4.2388\n",
      "Epoch [1/5], Step [692/10336], Loss: 3.3864\n",
      "Epoch [1/5], Step [694/10336], Loss: 1.5248\n",
      "Epoch [1/5], Step [696/10336], Loss: 2.0266\n",
      "Epoch [1/5], Step [698/10336], Loss: 1.9072\n",
      "Epoch [1/5], Step [700/10336], Loss: 2.6892\n",
      "Epoch [1/5], Step [702/10336], Loss: 2.1735\n",
      "Epoch [1/5], Step [704/10336], Loss: 0.8539\n",
      "Epoch [1/5], Step [706/10336], Loss: 4.9187\n",
      "Epoch [1/5], Step [708/10336], Loss: 4.7291\n",
      "Epoch [1/5], Step [710/10336], Loss: 0.7149\n",
      "Epoch [1/5], Step [712/10336], Loss: 2.6950\n",
      "Epoch [1/5], Step [714/10336], Loss: 3.5394\n",
      "Epoch [1/5], Step [716/10336], Loss: 1.6230\n",
      "Epoch [1/5], Step [718/10336], Loss: 2.3818\n",
      "Epoch [1/5], Step [720/10336], Loss: 2.2039\n",
      "Epoch [1/5], Step [722/10336], Loss: 0.5033\n",
      "Epoch [1/5], Step [724/10336], Loss: 6.0180\n",
      "Epoch [1/5], Step [726/10336], Loss: 2.1951\n",
      "Epoch [1/5], Step [728/10336], Loss: 0.5793\n",
      "Epoch [1/5], Step [730/10336], Loss: 1.1409\n",
      "Epoch [1/5], Step [732/10336], Loss: 2.2435\n",
      "Epoch [1/5], Step [734/10336], Loss: 0.6521\n",
      "Epoch [1/5], Step [736/10336], Loss: 0.7856\n",
      "Epoch [1/5], Step [738/10336], Loss: 1.4127\n",
      "Epoch [1/5], Step [740/10336], Loss: 2.5495\n",
      "Epoch [1/5], Step [742/10336], Loss: 1.1797\n",
      "Epoch [1/5], Step [744/10336], Loss: 1.8685\n",
      "Epoch [1/5], Step [746/10336], Loss: 4.8002\n",
      "Epoch [1/5], Step [748/10336], Loss: 3.7743\n",
      "Epoch [1/5], Step [750/10336], Loss: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [752/10336], Loss: 3.5866\n",
      "Epoch [1/5], Step [754/10336], Loss: 0.9890\n",
      "Epoch [1/5], Step [756/10336], Loss: 2.4233\n",
      "Epoch [1/5], Step [758/10336], Loss: 1.8693\n",
      "Epoch [1/5], Step [760/10336], Loss: 3.1513\n",
      "Epoch [1/5], Step [762/10336], Loss: 1.4006\n",
      "Epoch [1/5], Step [764/10336], Loss: 2.7045\n",
      "Epoch [1/5], Step [766/10336], Loss: 2.0460\n",
      "Epoch [1/5], Step [768/10336], Loss: 3.7936\n",
      "Epoch [1/5], Step [770/10336], Loss: 3.7918\n",
      "Epoch [1/5], Step [772/10336], Loss: 5.0932\n",
      "Epoch [1/5], Step [774/10336], Loss: 1.7390\n",
      "Epoch [1/5], Step [776/10336], Loss: 2.8166\n",
      "Epoch [1/5], Step [778/10336], Loss: 2.4839\n",
      "Epoch [1/5], Step [780/10336], Loss: 2.9437\n",
      "Epoch [1/5], Step [782/10336], Loss: 1.8907\n",
      "Epoch [1/5], Step [784/10336], Loss: 3.1223\n",
      "Epoch [1/5], Step [786/10336], Loss: 1.2076\n",
      "Epoch [1/5], Step [788/10336], Loss: 5.7973\n",
      "Epoch [1/5], Step [790/10336], Loss: 2.8630\n",
      "Epoch [1/5], Step [792/10336], Loss: 3.4587\n",
      "Epoch [1/5], Step [794/10336], Loss: 2.5158\n",
      "Epoch [1/5], Step [796/10336], Loss: 2.7728\n",
      "Epoch [1/5], Step [798/10336], Loss: 2.4616\n",
      "Epoch [1/5], Step [800/10336], Loss: 2.7306\n",
      "Epoch [1/5], Step [802/10336], Loss: 0.2365\n",
      "Epoch [1/5], Step [804/10336], Loss: 1.2008\n",
      "Epoch [1/5], Step [806/10336], Loss: 2.6082\n",
      "Epoch [1/5], Step [808/10336], Loss: 0.4267\n",
      "Epoch [1/5], Step [810/10336], Loss: 2.2956\n",
      "Epoch [1/5], Step [812/10336], Loss: 0.8682\n",
      "Epoch [1/5], Step [814/10336], Loss: 2.1555\n",
      "Epoch [1/5], Step [816/10336], Loss: 1.9296\n",
      "Epoch [1/5], Step [818/10336], Loss: 5.6566\n",
      "Epoch [1/5], Step [820/10336], Loss: 1.1223\n",
      "Epoch [1/5], Step [822/10336], Loss: 3.7210\n",
      "Epoch [1/5], Step [824/10336], Loss: 3.4810\n",
      "Epoch [1/5], Step [826/10336], Loss: 2.8076\n",
      "Epoch [1/5], Step [828/10336], Loss: 2.7936\n",
      "Epoch [1/5], Step [830/10336], Loss: 2.7197\n",
      "Epoch [1/5], Step [832/10336], Loss: 1.5292\n",
      "Epoch [1/5], Step [834/10336], Loss: 3.6147\n",
      "Epoch [1/5], Step [836/10336], Loss: 3.0949\n",
      "Epoch [1/5], Step [838/10336], Loss: 3.8935\n",
      "Epoch [1/5], Step [840/10336], Loss: 3.3066\n",
      "Epoch [1/5], Step [842/10336], Loss: 4.7734\n",
      "Epoch [1/5], Step [844/10336], Loss: 1.0243\n",
      "Epoch [1/5], Step [846/10336], Loss: 0.8977\n",
      "Epoch [1/5], Step [848/10336], Loss: 5.2156\n",
      "Epoch [1/5], Step [850/10336], Loss: 4.2760\n",
      "Epoch [1/5], Step [852/10336], Loss: 6.2009\n",
      "Epoch [1/5], Step [854/10336], Loss: 4.2157\n",
      "Epoch [1/5], Step [856/10336], Loss: 2.7983\n",
      "Epoch [1/5], Step [858/10336], Loss: 1.8991\n",
      "Epoch [1/5], Step [860/10336], Loss: 6.3398\n",
      "Epoch [1/5], Step [862/10336], Loss: 2.6200\n",
      "Epoch [1/5], Step [864/10336], Loss: 1.9085\n",
      "Epoch [1/5], Step [866/10336], Loss: 4.0888\n",
      "Epoch [1/5], Step [868/10336], Loss: 2.8544\n",
      "Epoch [1/5], Step [870/10336], Loss: 1.3712\n",
      "Epoch [1/5], Step [872/10336], Loss: 0.7725\n",
      "Epoch [1/5], Step [874/10336], Loss: 0.3216\n",
      "Epoch [1/5], Step [876/10336], Loss: 3.5327\n",
      "Epoch [1/5], Step [878/10336], Loss: 1.5880\n",
      "Epoch [1/5], Step [880/10336], Loss: 1.5564\n",
      "Epoch [1/5], Step [882/10336], Loss: 0.6713\n",
      "Epoch [1/5], Step [884/10336], Loss: 3.9507\n",
      "Epoch [1/5], Step [886/10336], Loss: 3.3223\n",
      "Epoch [1/5], Step [888/10336], Loss: 0.6819\n",
      "Epoch [1/5], Step [890/10336], Loss: 1.6210\n",
      "Epoch [1/5], Step [892/10336], Loss: 2.3516\n",
      "Epoch [1/5], Step [894/10336], Loss: 2.5355\n",
      "Epoch [1/5], Step [896/10336], Loss: 1.8316\n",
      "Epoch [1/5], Step [898/10336], Loss: 3.1212\n",
      "Epoch [1/5], Step [900/10336], Loss: 2.6799\n",
      "Epoch [1/5], Step [902/10336], Loss: 2.2137\n",
      "Epoch [1/5], Step [904/10336], Loss: 4.0875\n",
      "Epoch [1/5], Step [906/10336], Loss: 1.9261\n",
      "Epoch [1/5], Step [908/10336], Loss: 2.1626\n",
      "Epoch [1/5], Step [910/10336], Loss: 2.5668\n",
      "Epoch [1/5], Step [912/10336], Loss: 2.3605\n",
      "Epoch [1/5], Step [914/10336], Loss: 3.1371\n",
      "Epoch [1/5], Step [916/10336], Loss: 2.5882\n",
      "Epoch [1/5], Step [918/10336], Loss: 0.7086\n",
      "Epoch [1/5], Step [920/10336], Loss: 2.3765\n",
      "Epoch [1/5], Step [922/10336], Loss: 3.0474\n",
      "Epoch [1/5], Step [924/10336], Loss: 2.1116\n",
      "Epoch [1/5], Step [926/10336], Loss: 3.0749\n",
      "Epoch [1/5], Step [928/10336], Loss: 2.2656\n",
      "Epoch [1/5], Step [930/10336], Loss: 0.6599\n",
      "Epoch [1/5], Step [932/10336], Loss: 2.4818\n",
      "Epoch [1/5], Step [934/10336], Loss: 2.4832\n",
      "Epoch [1/5], Step [936/10336], Loss: 0.4960\n",
      "Epoch [1/5], Step [938/10336], Loss: 3.4084\n",
      "Epoch [1/5], Step [940/10336], Loss: 1.8938\n",
      "Epoch [1/5], Step [942/10336], Loss: 0.9069\n",
      "Epoch [1/5], Step [944/10336], Loss: 3.0793\n",
      "Epoch [1/5], Step [946/10336], Loss: 1.5323\n",
      "Epoch [1/5], Step [948/10336], Loss: 1.7365\n",
      "Epoch [1/5], Step [950/10336], Loss: 0.2449\n",
      "Epoch [1/5], Step [952/10336], Loss: 1.8232\n",
      "Epoch [1/5], Step [954/10336], Loss: 0.1402\n",
      "Epoch [1/5], Step [956/10336], Loss: 0.2394\n",
      "Epoch [1/5], Step [958/10336], Loss: 1.4057\n",
      "Epoch [1/5], Step [960/10336], Loss: 3.4554\n",
      "Epoch [1/5], Step [962/10336], Loss: 0.3973\n",
      "Epoch [1/5], Step [964/10336], Loss: 2.3744\n",
      "Epoch [1/5], Step [966/10336], Loss: 1.9156\n",
      "Epoch [1/5], Step [968/10336], Loss: 1.3392\n",
      "Epoch [1/5], Step [970/10336], Loss: 2.8537\n",
      "Epoch [1/5], Step [972/10336], Loss: 2.3858\n",
      "Epoch [1/5], Step [974/10336], Loss: 2.5795\n",
      "Epoch [1/5], Step [976/10336], Loss: 0.4928\n",
      "Epoch [1/5], Step [978/10336], Loss: 1.9871\n",
      "Epoch [1/5], Step [980/10336], Loss: 2.4522\n",
      "Epoch [1/5], Step [982/10336], Loss: 2.9333\n",
      "Epoch [1/5], Step [984/10336], Loss: 3.2775\n",
      "Epoch [1/5], Step [986/10336], Loss: 2.8420\n",
      "Epoch [1/5], Step [988/10336], Loss: 0.4635\n",
      "Epoch [1/5], Step [990/10336], Loss: 0.3497\n",
      "Epoch [1/5], Step [992/10336], Loss: 0.7033\n",
      "Epoch [1/5], Step [994/10336], Loss: 1.7488\n",
      "Epoch [1/5], Step [996/10336], Loss: 0.4896\n",
      "Epoch [1/5], Step [998/10336], Loss: 1.5796\n",
      "Epoch [1/5], Step [1000/10336], Loss: 3.3585\n",
      "Epoch [1/5], Step [1002/10336], Loss: 3.8564\n",
      "Epoch [1/5], Step [1004/10336], Loss: 2.4101\n",
      "Epoch [1/5], Step [1006/10336], Loss: 1.1426\n",
      "Epoch [1/5], Step [1008/10336], Loss: 1.6810\n",
      "Epoch [1/5], Step [1010/10336], Loss: 2.4836\n",
      "Epoch [1/5], Step [1012/10336], Loss: 0.4321\n",
      "Epoch [1/5], Step [1014/10336], Loss: 3.6712\n",
      "Epoch [1/5], Step [1016/10336], Loss: 1.4893\n",
      "Epoch [1/5], Step [1018/10336], Loss: 1.9871\n",
      "Epoch [1/5], Step [1020/10336], Loss: 3.4325\n",
      "Epoch [1/5], Step [1022/10336], Loss: 4.4938\n",
      "Epoch [1/5], Step [1024/10336], Loss: 3.6414\n",
      "Epoch [1/5], Step [1026/10336], Loss: 2.2278\n",
      "Epoch [1/5], Step [1028/10336], Loss: 2.9759\n",
      "Epoch [1/5], Step [1030/10336], Loss: 0.4101\n",
      "Epoch [1/5], Step [1032/10336], Loss: 4.1095\n",
      "Epoch [1/5], Step [1034/10336], Loss: 2.2653\n",
      "Epoch [1/5], Step [1036/10336], Loss: 3.4866\n",
      "Epoch [1/5], Step [1038/10336], Loss: 1.8890\n",
      "Epoch [1/5], Step [1040/10336], Loss: 1.4904\n",
      "Epoch [1/5], Step [1042/10336], Loss: 0.9253\n",
      "Epoch [1/5], Step [1044/10336], Loss: 4.0697\n",
      "Epoch [1/5], Step [1046/10336], Loss: 2.5755\n",
      "Epoch [1/5], Step [1048/10336], Loss: 1.4940\n",
      "Epoch [1/5], Step [1050/10336], Loss: 0.5665\n",
      "Epoch [1/5], Step [1052/10336], Loss: 1.3381\n",
      "Epoch [1/5], Step [1054/10336], Loss: 3.6558\n",
      "Epoch [1/5], Step [1056/10336], Loss: 3.3018\n",
      "Epoch [1/5], Step [1058/10336], Loss: 2.1313\n",
      "Epoch [1/5], Step [1060/10336], Loss: 1.8243\n",
      "Epoch [1/5], Step [1062/10336], Loss: 2.7964\n",
      "Epoch [1/5], Step [1064/10336], Loss: 3.2908\n",
      "Epoch [1/5], Step [1066/10336], Loss: 1.3409\n",
      "Epoch [1/5], Step [1068/10336], Loss: 2.6233\n",
      "Epoch [1/5], Step [1070/10336], Loss: 1.7099\n",
      "Epoch [1/5], Step [1072/10336], Loss: 1.3412\n",
      "Epoch [1/5], Step [1074/10336], Loss: 0.7121\n",
      "Epoch [1/5], Step [1076/10336], Loss: 3.6113\n",
      "Epoch [1/5], Step [1078/10336], Loss: 2.2535\n",
      "Epoch [1/5], Step [1080/10336], Loss: 1.8733\n",
      "Epoch [1/5], Step [1082/10336], Loss: 5.8415\n",
      "Epoch [1/5], Step [1084/10336], Loss: 2.9330\n",
      "Epoch [1/5], Step [1086/10336], Loss: 2.2347\n",
      "Epoch [1/5], Step [1088/10336], Loss: 2.6087\n",
      "Epoch [1/5], Step [1090/10336], Loss: 2.6312\n",
      "Epoch [1/5], Step [1092/10336], Loss: 1.5399\n",
      "Epoch [1/5], Step [1094/10336], Loss: 1.4673\n",
      "Epoch [1/5], Step [1096/10336], Loss: 2.2261\n",
      "Epoch [1/5], Step [1098/10336], Loss: 1.4084\n",
      "Epoch [1/5], Step [1100/10336], Loss: 1.2938\n",
      "Epoch [1/5], Step [1102/10336], Loss: 1.3871\n",
      "Epoch [1/5], Step [1104/10336], Loss: 2.5544\n",
      "Epoch [1/5], Step [1106/10336], Loss: 1.5402\n",
      "Epoch [1/5], Step [1108/10336], Loss: 3.4425\n",
      "Epoch [1/5], Step [1110/10336], Loss: 3.7444\n",
      "Epoch [1/5], Step [1112/10336], Loss: 3.1573\n",
      "Epoch [1/5], Step [1114/10336], Loss: 1.5409\n",
      "Epoch [1/5], Step [1116/10336], Loss: 0.6951\n",
      "Epoch [1/5], Step [1118/10336], Loss: 2.0904\n",
      "Epoch [1/5], Step [1120/10336], Loss: 1.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1122/10336], Loss: 2.0063\n",
      "Epoch [1/5], Step [1124/10336], Loss: 2.2194\n",
      "Epoch [1/5], Step [1126/10336], Loss: 6.9224\n",
      "Epoch [1/5], Step [1128/10336], Loss: 3.7532\n",
      "Epoch [1/5], Step [1130/10336], Loss: 3.0403\n",
      "Epoch [1/5], Step [1132/10336], Loss: 0.6285\n",
      "Epoch [1/5], Step [1134/10336], Loss: 2.6102\n",
      "Epoch [1/5], Step [1136/10336], Loss: 6.3338\n",
      "Epoch [1/5], Step [1138/10336], Loss: 2.3787\n",
      "Epoch [1/5], Step [1140/10336], Loss: 2.2145\n",
      "Epoch [1/5], Step [1142/10336], Loss: 1.4516\n",
      "Epoch [1/5], Step [1144/10336], Loss: 3.7452\n",
      "Epoch [1/5], Step [1146/10336], Loss: 0.3589\n",
      "Epoch [1/5], Step [1148/10336], Loss: 1.1305\n",
      "Epoch [1/5], Step [1150/10336], Loss: 1.4301\n",
      "Epoch [1/5], Step [1152/10336], Loss: 1.3189\n",
      "Epoch [1/5], Step [1154/10336], Loss: 0.9081\n",
      "Epoch [1/5], Step [1156/10336], Loss: 4.7610\n",
      "Epoch [1/5], Step [1158/10336], Loss: 1.3323\n",
      "Epoch [1/5], Step [1160/10336], Loss: 5.3369\n",
      "Epoch [1/5], Step [1162/10336], Loss: 0.1775\n",
      "Epoch [1/5], Step [1164/10336], Loss: 2.4945\n",
      "Epoch [1/5], Step [1166/10336], Loss: 2.1868\n",
      "Epoch [1/5], Step [1168/10336], Loss: 2.6802\n",
      "Epoch [1/5], Step [1170/10336], Loss: 4.5463\n",
      "Epoch [1/5], Step [1172/10336], Loss: 5.9407\n",
      "Epoch [1/5], Step [1174/10336], Loss: 2.9601\n",
      "Epoch [1/5], Step [1176/10336], Loss: 0.5860\n",
      "Epoch [1/5], Step [1178/10336], Loss: 2.3847\n",
      "Epoch [1/5], Step [1180/10336], Loss: 2.9648\n",
      "Epoch [1/5], Step [1182/10336], Loss: 6.1788\n",
      "Epoch [1/5], Step [1184/10336], Loss: 1.0387\n",
      "Epoch [1/5], Step [1186/10336], Loss: 3.6296\n",
      "Epoch [1/5], Step [1188/10336], Loss: 3.6526\n",
      "Epoch [1/5], Step [1190/10336], Loss: 2.1571\n",
      "Epoch [1/5], Step [1192/10336], Loss: 2.1047\n",
      "Epoch [1/5], Step [1194/10336], Loss: 1.1962\n",
      "Epoch [1/5], Step [1196/10336], Loss: 4.2833\n",
      "Epoch [1/5], Step [1198/10336], Loss: 1.7518\n",
      "Epoch [1/5], Step [1200/10336], Loss: 0.4013\n",
      "Epoch [1/5], Step [1202/10336], Loss: 1.4594\n",
      "Epoch [1/5], Step [1204/10336], Loss: 1.1765\n",
      "Epoch [1/5], Step [1206/10336], Loss: 1.8775\n",
      "Epoch [1/5], Step [1208/10336], Loss: 1.3466\n",
      "Epoch [1/5], Step [1210/10336], Loss: 1.9666\n",
      "Epoch [1/5], Step [1212/10336], Loss: 2.3257\n",
      "Epoch [1/5], Step [1214/10336], Loss: 1.2908\n",
      "Epoch [1/5], Step [1216/10336], Loss: 3.1793\n",
      "Epoch [1/5], Step [1218/10336], Loss: 0.8981\n",
      "Epoch [1/5], Step [1220/10336], Loss: 3.2061\n",
      "Epoch [1/5], Step [1222/10336], Loss: 1.4571\n",
      "Epoch [1/5], Step [1224/10336], Loss: 2.7736\n",
      "Epoch [1/5], Step [1226/10336], Loss: 0.3622\n",
      "Epoch [1/5], Step [1228/10336], Loss: 0.8708\n",
      "Epoch [1/5], Step [1230/10336], Loss: 6.9696\n",
      "Epoch [1/5], Step [1232/10336], Loss: 0.2731\n",
      "Epoch [1/5], Step [1234/10336], Loss: 6.4013\n",
      "Epoch [1/5], Step [1236/10336], Loss: 0.3256\n",
      "Epoch [1/5], Step [1238/10336], Loss: 0.9679\n",
      "Epoch [1/5], Step [1240/10336], Loss: 1.6971\n",
      "Epoch [1/5], Step [1242/10336], Loss: 0.4590\n",
      "Epoch [1/5], Step [1244/10336], Loss: 1.7717\n",
      "Epoch [1/5], Step [1246/10336], Loss: 2.4634\n",
      "Epoch [1/5], Step [1248/10336], Loss: 4.3334\n",
      "Epoch [1/5], Step [1250/10336], Loss: 3.7941\n",
      "Epoch [1/5], Step [1252/10336], Loss: 1.2892\n",
      "Epoch [1/5], Step [1254/10336], Loss: 3.3488\n",
      "Epoch [1/5], Step [1256/10336], Loss: 2.1877\n",
      "Epoch [1/5], Step [1258/10336], Loss: 0.6981\n",
      "Epoch [1/5], Step [1260/10336], Loss: 1.4239\n",
      "Epoch [1/5], Step [1262/10336], Loss: 1.8606\n",
      "Epoch [1/5], Step [1264/10336], Loss: 1.3091\n",
      "Epoch [1/5], Step [1266/10336], Loss: 0.1559\n",
      "Epoch [1/5], Step [1268/10336], Loss: 0.6046\n",
      "Epoch [1/5], Step [1270/10336], Loss: 0.4581\n",
      "Epoch [1/5], Step [1272/10336], Loss: 2.1761\n",
      "Epoch [1/5], Step [1274/10336], Loss: 2.0989\n",
      "Epoch [1/5], Step [1276/10336], Loss: 0.1063\n",
      "Epoch [1/5], Step [1278/10336], Loss: 5.3651\n",
      "Epoch [1/5], Step [1280/10336], Loss: 0.2869\n",
      "Epoch [1/5], Step [1282/10336], Loss: 1.5892\n",
      "Epoch [1/5], Step [1284/10336], Loss: 3.0383\n",
      "Epoch [1/5], Step [1286/10336], Loss: 0.1943\n",
      "Epoch [1/5], Step [1288/10336], Loss: 6.3143\n",
      "Epoch [1/5], Step [1290/10336], Loss: 2.9241\n",
      "Epoch [1/5], Step [1292/10336], Loss: 0.8932\n",
      "Epoch [1/5], Step [1294/10336], Loss: 5.6862\n",
      "Epoch [1/5], Step [1296/10336], Loss: 4.7290\n",
      "Epoch [1/5], Step [1298/10336], Loss: 0.9890\n",
      "Epoch [1/5], Step [1300/10336], Loss: 1.6990\n",
      "Epoch [1/5], Step [1302/10336], Loss: 1.8185\n",
      "Epoch [1/5], Step [1304/10336], Loss: 1.5636\n",
      "Epoch [1/5], Step [1306/10336], Loss: 4.0170\n",
      "Epoch [1/5], Step [1308/10336], Loss: 4.5318\n",
      "Epoch [1/5], Step [1310/10336], Loss: 2.6090\n",
      "Epoch [1/5], Step [1312/10336], Loss: 0.7441\n",
      "Epoch [1/5], Step [1314/10336], Loss: 3.4136\n",
      "Epoch [1/5], Step [1316/10336], Loss: 2.0443\n",
      "Epoch [1/5], Step [1318/10336], Loss: 2.5311\n",
      "Epoch [1/5], Step [1320/10336], Loss: 3.0107\n",
      "Epoch [1/5], Step [1322/10336], Loss: 2.2497\n",
      "Epoch [1/5], Step [1324/10336], Loss: 0.9153\n",
      "Epoch [1/5], Step [1326/10336], Loss: 3.7460\n",
      "Epoch [1/5], Step [1328/10336], Loss: 4.9971\n",
      "Epoch [1/5], Step [1330/10336], Loss: 1.9398\n",
      "Epoch [1/5], Step [1332/10336], Loss: 3.4523\n",
      "Epoch [1/5], Step [1334/10336], Loss: 3.7822\n",
      "Epoch [1/5], Step [1336/10336], Loss: 0.7995\n",
      "Epoch [1/5], Step [1338/10336], Loss: 3.4687\n",
      "Epoch [1/5], Step [1340/10336], Loss: 3.8617\n",
      "Epoch [1/5], Step [1342/10336], Loss: 0.4490\n",
      "Epoch [1/5], Step [1344/10336], Loss: 1.3701\n",
      "Epoch [1/5], Step [1346/10336], Loss: 2.9523\n",
      "Epoch [1/5], Step [1348/10336], Loss: 1.6142\n",
      "Epoch [1/5], Step [1350/10336], Loss: 3.8914\n",
      "Epoch [1/5], Step [1352/10336], Loss: 0.2317\n",
      "Epoch [1/5], Step [1354/10336], Loss: 0.9480\n",
      "Epoch [1/5], Step [1356/10336], Loss: 2.8365\n",
      "Epoch [1/5], Step [1358/10336], Loss: 1.2902\n",
      "Epoch [1/5], Step [1360/10336], Loss: 2.8841\n",
      "Epoch [1/5], Step [1362/10336], Loss: 3.2864\n",
      "Epoch [1/5], Step [1364/10336], Loss: 2.6629\n",
      "Epoch [1/5], Step [1366/10336], Loss: 3.0017\n",
      "Epoch [1/5], Step [1368/10336], Loss: 2.6624\n",
      "Epoch [1/5], Step [1370/10336], Loss: 3.3332\n",
      "Epoch [1/5], Step [1372/10336], Loss: 4.5896\n",
      "Epoch [1/5], Step [1374/10336], Loss: 1.9712\n",
      "Epoch [1/5], Step [1376/10336], Loss: 2.5856\n",
      "Epoch [1/5], Step [1378/10336], Loss: 2.5281\n",
      "Epoch [1/5], Step [1380/10336], Loss: 1.6271\n",
      "Epoch [1/5], Step [1382/10336], Loss: 0.7330\n",
      "Epoch [1/5], Step [1384/10336], Loss: 1.9496\n",
      "Epoch [1/5], Step [1386/10336], Loss: 0.2280\n",
      "Epoch [1/5], Step [1388/10336], Loss: 2.3074\n",
      "Epoch [1/5], Step [1390/10336], Loss: 0.5776\n",
      "Epoch [1/5], Step [1392/10336], Loss: 0.9263\n",
      "Epoch [1/5], Step [1394/10336], Loss: 4.1935\n",
      "Epoch [1/5], Step [1396/10336], Loss: 0.2278\n",
      "Epoch [1/5], Step [1398/10336], Loss: 2.6265\n",
      "Epoch [1/5], Step [1400/10336], Loss: 3.5693\n",
      "Epoch [1/5], Step [1402/10336], Loss: 1.4269\n",
      "Epoch [1/5], Step [1404/10336], Loss: 2.3477\n",
      "Epoch [1/5], Step [1406/10336], Loss: 0.3216\n",
      "Epoch [1/5], Step [1408/10336], Loss: 0.7051\n",
      "Epoch [1/5], Step [1410/10336], Loss: 5.9620\n",
      "Epoch [1/5], Step [1412/10336], Loss: 0.6074\n",
      "Epoch [1/5], Step [1414/10336], Loss: 1.6832\n",
      "Epoch [1/5], Step [1416/10336], Loss: 0.7489\n",
      "Epoch [1/5], Step [1418/10336], Loss: 0.9255\n",
      "Epoch [1/5], Step [1420/10336], Loss: 1.0947\n",
      "Epoch [1/5], Step [1422/10336], Loss: 4.2970\n",
      "Epoch [1/5], Step [1424/10336], Loss: 2.4471\n",
      "Epoch [1/5], Step [1426/10336], Loss: 0.8397\n",
      "Epoch [1/5], Step [1428/10336], Loss: 0.3667\n",
      "Epoch [1/5], Step [1430/10336], Loss: 4.1086\n",
      "Epoch [1/5], Step [1432/10336], Loss: 2.4197\n",
      "Epoch [1/5], Step [1434/10336], Loss: 4.8876\n",
      "Epoch [1/5], Step [1436/10336], Loss: 4.6407\n",
      "Epoch [1/5], Step [1438/10336], Loss: 0.3445\n",
      "Epoch [1/5], Step [1440/10336], Loss: 0.6160\n",
      "Epoch [1/5], Step [1442/10336], Loss: 2.5128\n",
      "Epoch [1/5], Step [1444/10336], Loss: 2.5787\n",
      "Epoch [1/5], Step [1446/10336], Loss: 3.1712\n",
      "Epoch [1/5], Step [1448/10336], Loss: 1.6098\n",
      "Epoch [1/5], Step [1450/10336], Loss: 0.5277\n",
      "Epoch [1/5], Step [1452/10336], Loss: 5.4383\n",
      "Epoch [1/5], Step [1454/10336], Loss: 3.2081\n",
      "Epoch [1/5], Step [1456/10336], Loss: 1.8170\n",
      "Epoch [1/5], Step [1458/10336], Loss: 4.1455\n",
      "Epoch [1/5], Step [1460/10336], Loss: 1.4028\n",
      "Epoch [1/5], Step [1462/10336], Loss: 1.8100\n",
      "Epoch [1/5], Step [1464/10336], Loss: 1.3382\n",
      "Epoch [1/5], Step [1466/10336], Loss: 1.8481\n",
      "Epoch [1/5], Step [1468/10336], Loss: 4.7300\n",
      "Epoch [1/5], Step [1470/10336], Loss: 4.4619\n",
      "Epoch [1/5], Step [1472/10336], Loss: 0.1230\n",
      "Epoch [1/5], Step [1474/10336], Loss: 1.8861\n",
      "Epoch [1/5], Step [1476/10336], Loss: 1.4984\n",
      "Epoch [1/5], Step [1478/10336], Loss: 1.2376\n",
      "Epoch [1/5], Step [1480/10336], Loss: 0.9675\n",
      "Epoch [1/5], Step [1482/10336], Loss: 4.1339\n",
      "Epoch [1/5], Step [1484/10336], Loss: 2.7953\n",
      "Epoch [1/5], Step [1486/10336], Loss: 1.7398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1488/10336], Loss: 3.9884\n",
      "Epoch [1/5], Step [1490/10336], Loss: 3.6718\n",
      "Epoch [1/5], Step [1492/10336], Loss: 2.1198\n",
      "Epoch [1/5], Step [1494/10336], Loss: 1.5712\n",
      "Epoch [1/5], Step [1496/10336], Loss: 0.7720\n",
      "Epoch [1/5], Step [1498/10336], Loss: 2.1193\n",
      "Epoch [1/5], Step [1500/10336], Loss: 0.0851\n",
      "Epoch [1/5], Step [1502/10336], Loss: 1.1124\n",
      "Epoch [1/5], Step [1504/10336], Loss: 2.9827\n",
      "Epoch [1/5], Step [1506/10336], Loss: 5.9569\n",
      "Epoch [1/5], Step [1508/10336], Loss: 0.7377\n",
      "Epoch [1/5], Step [1510/10336], Loss: 0.7324\n",
      "Epoch [1/5], Step [1512/10336], Loss: 0.4417\n",
      "Epoch [1/5], Step [1514/10336], Loss: 2.2304\n",
      "Epoch [1/5], Step [1516/10336], Loss: 1.1195\n",
      "Epoch [1/5], Step [1518/10336], Loss: 5.9763\n",
      "Epoch [1/5], Step [1520/10336], Loss: 0.1263\n",
      "Epoch [1/5], Step [1522/10336], Loss: 1.7335\n",
      "Epoch [1/5], Step [1524/10336], Loss: 2.7407\n",
      "Epoch [1/5], Step [1526/10336], Loss: 3.7678\n",
      "Epoch [1/5], Step [1528/10336], Loss: 0.2008\n",
      "Epoch [1/5], Step [1530/10336], Loss: 2.4045\n",
      "Epoch [1/5], Step [1532/10336], Loss: 1.9903\n",
      "Epoch [1/5], Step [1534/10336], Loss: 0.8166\n",
      "Epoch [1/5], Step [1536/10336], Loss: 1.0581\n",
      "Epoch [1/5], Step [1538/10336], Loss: 1.6109\n",
      "Epoch [1/5], Step [1540/10336], Loss: 3.8137\n",
      "Epoch [1/5], Step [1542/10336], Loss: 2.4345\n",
      "Epoch [1/5], Step [1544/10336], Loss: 3.2297\n",
      "Epoch [1/5], Step [1546/10336], Loss: 2.8514\n",
      "Epoch [1/5], Step [1548/10336], Loss: 2.0672\n",
      "Epoch [1/5], Step [1550/10336], Loss: 1.0721\n",
      "Epoch [1/5], Step [1552/10336], Loss: 2.7620\n",
      "Epoch [1/5], Step [1554/10336], Loss: 0.5212\n",
      "Epoch [1/5], Step [1556/10336], Loss: 1.4757\n",
      "Epoch [1/5], Step [1558/10336], Loss: 5.3662\n",
      "Epoch [1/5], Step [1560/10336], Loss: 1.1189\n",
      "Epoch [1/5], Step [1562/10336], Loss: 2.1048\n",
      "Epoch [1/5], Step [1564/10336], Loss: 2.2812\n",
      "Epoch [1/5], Step [1566/10336], Loss: 1.7769\n",
      "Epoch [1/5], Step [1568/10336], Loss: 2.0640\n",
      "Epoch [1/5], Step [1570/10336], Loss: 5.1559\n",
      "Epoch [1/5], Step [1572/10336], Loss: 2.7167\n",
      "Epoch [1/5], Step [1574/10336], Loss: 3.8821\n",
      "Epoch [1/5], Step [1576/10336], Loss: 3.5937\n",
      "Epoch [1/5], Step [1578/10336], Loss: 3.2598\n",
      "Epoch [1/5], Step [1580/10336], Loss: 6.5892\n",
      "Epoch [1/5], Step [1582/10336], Loss: 2.1587\n",
      "Epoch [1/5], Step [1584/10336], Loss: 1.9979\n",
      "Epoch [1/5], Step [1586/10336], Loss: 3.3752\n",
      "Epoch [1/5], Step [1588/10336], Loss: 1.4667\n",
      "Epoch [1/5], Step [1590/10336], Loss: 2.8817\n",
      "Epoch [1/5], Step [1592/10336], Loss: 4.7396\n",
      "Epoch [1/5], Step [1594/10336], Loss: 2.2638\n",
      "Epoch [1/5], Step [1596/10336], Loss: 2.5230\n",
      "Epoch [1/5], Step [1598/10336], Loss: 3.5406\n",
      "Epoch [1/5], Step [1600/10336], Loss: 3.3813\n",
      "Epoch [1/5], Step [1602/10336], Loss: 1.6622\n",
      "Epoch [1/5], Step [1604/10336], Loss: 2.3833\n",
      "Epoch [1/5], Step [1606/10336], Loss: 0.7434\n",
      "Epoch [1/5], Step [1608/10336], Loss: 0.6533\n",
      "Epoch [1/5], Step [1610/10336], Loss: 1.1063\n",
      "Epoch [1/5], Step [1612/10336], Loss: 4.7342\n",
      "Epoch [1/5], Step [1614/10336], Loss: 2.6964\n",
      "Epoch [1/5], Step [1616/10336], Loss: 2.0448\n",
      "Epoch [1/5], Step [1618/10336], Loss: 1.3539\n",
      "Epoch [1/5], Step [1620/10336], Loss: 0.5218\n",
      "Epoch [1/5], Step [1622/10336], Loss: 2.3416\n",
      "Epoch [1/5], Step [1624/10336], Loss: 1.2007\n",
      "Epoch [1/5], Step [1626/10336], Loss: 4.1105\n",
      "Epoch [1/5], Step [1628/10336], Loss: 2.5671\n",
      "Epoch [1/5], Step [1630/10336], Loss: 4.4643\n",
      "Epoch [1/5], Step [1632/10336], Loss: 1.8125\n",
      "Epoch [1/5], Step [1634/10336], Loss: 2.5056\n",
      "Epoch [1/5], Step [1636/10336], Loss: 1.2154\n",
      "Epoch [1/5], Step [1638/10336], Loss: 3.1702\n",
      "Epoch [1/5], Step [1640/10336], Loss: 2.0978\n",
      "Epoch [1/5], Step [1642/10336], Loss: 2.2299\n",
      "Epoch [1/5], Step [1644/10336], Loss: 0.7956\n",
      "Epoch [1/5], Step [1646/10336], Loss: 3.5344\n",
      "Epoch [1/5], Step [1648/10336], Loss: 0.5873\n",
      "Epoch [1/5], Step [1650/10336], Loss: 0.2070\n",
      "Epoch [1/5], Step [1652/10336], Loss: 4.7375\n",
      "Epoch [1/5], Step [1654/10336], Loss: 0.4658\n",
      "Epoch [1/5], Step [1656/10336], Loss: 4.6619\n",
      "Epoch [1/5], Step [1658/10336], Loss: 3.9596\n",
      "Epoch [1/5], Step [1660/10336], Loss: 3.6063\n",
      "Epoch [1/5], Step [1662/10336], Loss: 1.9280\n",
      "Epoch [1/5], Step [1664/10336], Loss: 1.3033\n",
      "Epoch [1/5], Step [1666/10336], Loss: 2.0356\n",
      "Epoch [1/5], Step [1668/10336], Loss: 2.0998\n",
      "Epoch [1/5], Step [1670/10336], Loss: 3.0410\n",
      "Epoch [1/5], Step [1672/10336], Loss: 1.8988\n",
      "Epoch [1/5], Step [1674/10336], Loss: 1.4914\n",
      "Epoch [1/5], Step [1676/10336], Loss: 0.8596\n",
      "Epoch [1/5], Step [1678/10336], Loss: 1.3501\n",
      "Epoch [1/5], Step [1680/10336], Loss: 3.9469\n",
      "Epoch [1/5], Step [1682/10336], Loss: 1.9445\n",
      "Epoch [1/5], Step [1684/10336], Loss: 3.8378\n",
      "Epoch [1/5], Step [1686/10336], Loss: 1.6854\n",
      "Epoch [1/5], Step [1688/10336], Loss: 1.7761\n",
      "Epoch [1/5], Step [1690/10336], Loss: 0.1513\n",
      "Epoch [1/5], Step [1692/10336], Loss: 1.2565\n",
      "Epoch [1/5], Step [1694/10336], Loss: 0.4886\n",
      "Epoch [1/5], Step [1696/10336], Loss: 3.5634\n",
      "Epoch [1/5], Step [1698/10336], Loss: 0.9428\n",
      "Epoch [1/5], Step [1700/10336], Loss: 1.4721\n",
      "Epoch [1/5], Step [1702/10336], Loss: 3.7873\n",
      "Epoch [1/5], Step [1704/10336], Loss: 0.5589\n",
      "Epoch [1/5], Step [1706/10336], Loss: 1.1472\n",
      "Epoch [1/5], Step [1708/10336], Loss: 4.1787\n",
      "Epoch [1/5], Step [1710/10336], Loss: 1.0718\n",
      "Epoch [1/5], Step [1712/10336], Loss: 3.2395\n",
      "Epoch [1/5], Step [1714/10336], Loss: 0.7246\n",
      "Epoch [1/5], Step [1716/10336], Loss: 1.3586\n",
      "Epoch [1/5], Step [1718/10336], Loss: 0.1817\n",
      "Epoch [1/5], Step [1720/10336], Loss: 2.1031\n",
      "Epoch [1/5], Step [1722/10336], Loss: 3.9978\n",
      "Epoch [1/5], Step [1724/10336], Loss: 0.6828\n",
      "Epoch [1/5], Step [1726/10336], Loss: 0.8504\n",
      "Epoch [1/5], Step [1728/10336], Loss: 2.7707\n",
      "Epoch [1/5], Step [1730/10336], Loss: 2.3374\n",
      "Epoch [1/5], Step [1732/10336], Loss: 4.8569\n",
      "Epoch [1/5], Step [1734/10336], Loss: 3.7469\n",
      "Epoch [1/5], Step [1736/10336], Loss: 1.4882\n",
      "Epoch [1/5], Step [1738/10336], Loss: 1.9250\n",
      "Epoch [1/5], Step [1740/10336], Loss: 1.9744\n",
      "Epoch [1/5], Step [1742/10336], Loss: 2.8257\n",
      "Epoch [1/5], Step [1744/10336], Loss: 0.9420\n",
      "Epoch [1/5], Step [1746/10336], Loss: 1.5407\n",
      "Epoch [1/5], Step [1748/10336], Loss: 0.8007\n",
      "Epoch [1/5], Step [1750/10336], Loss: 3.5452\n",
      "Epoch [1/5], Step [1752/10336], Loss: 1.9546\n",
      "Epoch [1/5], Step [1754/10336], Loss: 3.0879\n",
      "Epoch [1/5], Step [1756/10336], Loss: 2.6101\n",
      "Epoch [1/5], Step [1758/10336], Loss: 4.1280\n",
      "Epoch [1/5], Step [1760/10336], Loss: 1.1319\n",
      "Epoch [1/5], Step [1762/10336], Loss: 2.3270\n",
      "Epoch [1/5], Step [1764/10336], Loss: 3.7935\n",
      "Epoch [1/5], Step [1766/10336], Loss: 2.6388\n",
      "Epoch [1/5], Step [1768/10336], Loss: 3.0189\n",
      "Epoch [1/5], Step [1770/10336], Loss: 3.8009\n",
      "Epoch [1/5], Step [1772/10336], Loss: 3.6656\n",
      "Epoch [1/5], Step [1774/10336], Loss: 2.4170\n",
      "Epoch [1/5], Step [1776/10336], Loss: 1.7419\n",
      "Epoch [1/5], Step [1778/10336], Loss: 1.4308\n",
      "Epoch [1/5], Step [1780/10336], Loss: 1.4973\n",
      "Epoch [1/5], Step [1782/10336], Loss: 2.3709\n",
      "Epoch [1/5], Step [1784/10336], Loss: 1.4557\n",
      "Epoch [1/5], Step [1786/10336], Loss: 2.5158\n",
      "Epoch [1/5], Step [1788/10336], Loss: 1.5115\n",
      "Epoch [1/5], Step [1790/10336], Loss: 2.1770\n",
      "Epoch [1/5], Step [1792/10336], Loss: 1.3886\n",
      "Epoch [1/5], Step [1794/10336], Loss: 4.1653\n",
      "Epoch [1/5], Step [1796/10336], Loss: 2.6373\n",
      "Epoch [1/5], Step [1798/10336], Loss: 3.0592\n",
      "Epoch [1/5], Step [1800/10336], Loss: 0.5466\n",
      "Epoch [1/5], Step [1802/10336], Loss: 2.1823\n",
      "Epoch [1/5], Step [1804/10336], Loss: 2.6195\n",
      "Epoch [1/5], Step [1806/10336], Loss: 3.5370\n",
      "Epoch [1/5], Step [1808/10336], Loss: 0.3230\n",
      "Epoch [1/5], Step [1810/10336], Loss: 2.0281\n",
      "Epoch [1/5], Step [1812/10336], Loss: 3.8828\n",
      "Epoch [1/5], Step [1814/10336], Loss: 0.5410\n",
      "Epoch [1/5], Step [1816/10336], Loss: 2.9588\n",
      "Epoch [1/5], Step [1818/10336], Loss: 1.0985\n",
      "Epoch [1/5], Step [1820/10336], Loss: 3.3913\n",
      "Epoch [1/5], Step [1822/10336], Loss: 4.5292\n",
      "Epoch [1/5], Step [1824/10336], Loss: 4.9067\n",
      "Epoch [1/5], Step [1826/10336], Loss: 3.9339\n",
      "Epoch [1/5], Step [1828/10336], Loss: 0.1498\n",
      "Epoch [1/5], Step [1830/10336], Loss: 1.9373\n",
      "Epoch [1/5], Step [1832/10336], Loss: 0.0976\n",
      "Epoch [1/5], Step [1834/10336], Loss: 1.6958\n",
      "Epoch [1/5], Step [1836/10336], Loss: 3.5668\n",
      "Epoch [1/5], Step [1838/10336], Loss: 1.5345\n",
      "Epoch [1/5], Step [1840/10336], Loss: 0.6192\n",
      "Epoch [1/5], Step [1842/10336], Loss: 0.3147\n",
      "Epoch [1/5], Step [1844/10336], Loss: 2.1623\n",
      "Epoch [1/5], Step [1846/10336], Loss: 1.4102\n",
      "Epoch [1/5], Step [1848/10336], Loss: 2.2549\n",
      "Epoch [1/5], Step [1850/10336], Loss: 1.0338\n",
      "Epoch [1/5], Step [1852/10336], Loss: 4.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1854/10336], Loss: 1.5239\n",
      "Epoch [1/5], Step [1856/10336], Loss: 1.2783\n",
      "Epoch [1/5], Step [1858/10336], Loss: 0.4510\n",
      "Epoch [1/5], Step [1860/10336], Loss: 1.0552\n",
      "Epoch [1/5], Step [1862/10336], Loss: 4.1253\n",
      "Epoch [1/5], Step [1864/10336], Loss: 3.2251\n",
      "Epoch [1/5], Step [1866/10336], Loss: 0.3245\n",
      "Epoch [1/5], Step [1868/10336], Loss: 1.2546\n",
      "Epoch [1/5], Step [1870/10336], Loss: 0.3590\n",
      "Epoch [1/5], Step [1872/10336], Loss: 2.2288\n",
      "Epoch [1/5], Step [1874/10336], Loss: 0.6698\n",
      "Epoch [1/5], Step [1876/10336], Loss: 3.2049\n",
      "Epoch [1/5], Step [1878/10336], Loss: 1.6533\n",
      "Epoch [1/5], Step [1880/10336], Loss: 3.4237\n",
      "Epoch [1/5], Step [1882/10336], Loss: 0.7840\n",
      "Epoch [1/5], Step [1884/10336], Loss: 2.4597\n",
      "Epoch [1/5], Step [1886/10336], Loss: 3.2214\n",
      "Epoch [1/5], Step [1888/10336], Loss: 3.1847\n",
      "Epoch [1/5], Step [1890/10336], Loss: 0.5399\n",
      "Epoch [1/5], Step [1892/10336], Loss: 1.6717\n",
      "Epoch [1/5], Step [1894/10336], Loss: 1.9918\n",
      "Epoch [1/5], Step [1896/10336], Loss: 4.0657\n",
      "Epoch [1/5], Step [1898/10336], Loss: 2.3288\n",
      "Epoch [1/5], Step [1900/10336], Loss: 3.1198\n",
      "Epoch [1/5], Step [1902/10336], Loss: 1.8205\n",
      "Epoch [1/5], Step [1904/10336], Loss: 1.6300\n",
      "Epoch [1/5], Step [1906/10336], Loss: 0.7200\n",
      "Epoch [1/5], Step [1908/10336], Loss: 1.4572\n",
      "Epoch [1/5], Step [1910/10336], Loss: 1.4136\n",
      "Epoch [1/5], Step [1912/10336], Loss: 1.0155\n",
      "Epoch [1/5], Step [1914/10336], Loss: 1.6404\n",
      "Epoch [1/5], Step [1916/10336], Loss: 4.1866\n",
      "Epoch [1/5], Step [1918/10336], Loss: 2.7080\n",
      "Epoch [1/5], Step [1920/10336], Loss: 3.6510\n",
      "Epoch [1/5], Step [1922/10336], Loss: 1.7906\n",
      "Epoch [1/5], Step [1924/10336], Loss: 0.9884\n",
      "Epoch [1/5], Step [1926/10336], Loss: 2.1268\n",
      "Epoch [1/5], Step [1928/10336], Loss: 1.8942\n",
      "Epoch [1/5], Step [1930/10336], Loss: 1.8336\n",
      "Epoch [1/5], Step [1932/10336], Loss: 0.7130\n",
      "Epoch [1/5], Step [1934/10336], Loss: 4.1105\n",
      "Epoch [1/5], Step [1936/10336], Loss: 1.1064\n",
      "Epoch [1/5], Step [1938/10336], Loss: 3.9373\n",
      "Epoch [1/5], Step [1940/10336], Loss: 2.6226\n",
      "Epoch [1/5], Step [1942/10336], Loss: 1.0594\n",
      "Epoch [1/5], Step [1944/10336], Loss: 1.0988\n",
      "Epoch [1/5], Step [1946/10336], Loss: 3.2707\n",
      "Epoch [1/5], Step [1948/10336], Loss: 1.5998\n",
      "Epoch [1/5], Step [1950/10336], Loss: 0.6707\n",
      "Epoch [1/5], Step [1952/10336], Loss: 3.2417\n",
      "Epoch [1/5], Step [1954/10336], Loss: 1.1463\n",
      "Epoch [1/5], Step [1956/10336], Loss: 3.1489\n",
      "Epoch [1/5], Step [1958/10336], Loss: 1.8295\n",
      "Epoch [1/5], Step [1960/10336], Loss: 2.4911\n",
      "Epoch [1/5], Step [1962/10336], Loss: 0.4159\n",
      "Epoch [1/5], Step [1964/10336], Loss: 0.8041\n",
      "Epoch [1/5], Step [1966/10336], Loss: 2.5782\n",
      "Epoch [1/5], Step [1968/10336], Loss: 2.3262\n",
      "Epoch [1/5], Step [1970/10336], Loss: 1.6855\n",
      "Epoch [1/5], Step [1972/10336], Loss: 2.3655\n",
      "Epoch [1/5], Step [1974/10336], Loss: 2.5591\n",
      "Epoch [1/5], Step [1976/10336], Loss: 2.4889\n",
      "Epoch [1/5], Step [1978/10336], Loss: 1.8786\n",
      "Epoch [1/5], Step [1980/10336], Loss: 0.4680\n",
      "Epoch [1/5], Step [1982/10336], Loss: 2.3954\n",
      "Epoch [1/5], Step [1984/10336], Loss: 2.5399\n",
      "Epoch [1/5], Step [1986/10336], Loss: 0.3257\n",
      "Epoch [1/5], Step [1988/10336], Loss: 0.8624\n",
      "Epoch [1/5], Step [1990/10336], Loss: 1.4194\n",
      "Epoch [1/5], Step [1992/10336], Loss: 1.7064\n",
      "Epoch [1/5], Step [1994/10336], Loss: 0.6235\n",
      "Epoch [1/5], Step [1996/10336], Loss: 0.0760\n",
      "Epoch [1/5], Step [1998/10336], Loss: 6.2679\n",
      "Epoch [1/5], Step [2000/10336], Loss: 3.1175\n",
      "Epoch [1/5], Step [2002/10336], Loss: 7.0955\n",
      "Epoch [1/5], Step [2004/10336], Loss: 2.7654\n",
      "Epoch [1/5], Step [2006/10336], Loss: 1.4929\n",
      "Epoch [1/5], Step [2008/10336], Loss: 1.3830\n",
      "Epoch [1/5], Step [2010/10336], Loss: 0.6524\n",
      "Epoch [1/5], Step [2012/10336], Loss: 2.7695\n",
      "Epoch [1/5], Step [2014/10336], Loss: 2.7239\n",
      "Epoch [1/5], Step [2016/10336], Loss: 1.7507\n",
      "Epoch [1/5], Step [2018/10336], Loss: 2.4471\n",
      "Epoch [1/5], Step [2020/10336], Loss: 1.9852\n",
      "Epoch [1/5], Step [2022/10336], Loss: 4.4852\n",
      "Epoch [1/5], Step [2024/10336], Loss: 1.5861\n",
      "Epoch [1/5], Step [2026/10336], Loss: 3.1433\n",
      "Epoch [1/5], Step [2028/10336], Loss: 2.9476\n",
      "Epoch [1/5], Step [2030/10336], Loss: 3.3026\n",
      "Epoch [1/5], Step [2032/10336], Loss: 0.1058\n",
      "Epoch [1/5], Step [2034/10336], Loss: 3.9006\n",
      "Epoch [1/5], Step [2036/10336], Loss: 2.4361\n",
      "Epoch [1/5], Step [2038/10336], Loss: 0.3076\n",
      "Epoch [1/5], Step [2040/10336], Loss: 2.7973\n",
      "Epoch [1/5], Step [2042/10336], Loss: 0.8555\n",
      "Epoch [1/5], Step [2044/10336], Loss: 2.3691\n",
      "Epoch [1/5], Step [2046/10336], Loss: 1.7142\n",
      "Epoch [1/5], Step [2048/10336], Loss: 1.9554\n",
      "Epoch [1/5], Step [2050/10336], Loss: 1.0826\n",
      "Epoch [1/5], Step [2052/10336], Loss: 4.6411\n",
      "Epoch [1/5], Step [2054/10336], Loss: 2.7936\n",
      "Epoch [1/5], Step [2056/10336], Loss: 1.0016\n",
      "Epoch [1/5], Step [2058/10336], Loss: 0.0782\n",
      "Epoch [1/5], Step [2060/10336], Loss: 2.6358\n",
      "Epoch [1/5], Step [2062/10336], Loss: 1.0427\n",
      "Epoch [1/5], Step [2064/10336], Loss: 0.3731\n",
      "Epoch [1/5], Step [2066/10336], Loss: 2.6022\n",
      "Epoch [1/5], Step [2068/10336], Loss: 1.4763\n",
      "Epoch [1/5], Step [2070/10336], Loss: 0.6397\n",
      "Epoch [1/5], Step [2072/10336], Loss: 3.0386\n",
      "Epoch [1/5], Step [2074/10336], Loss: 1.7185\n",
      "Epoch [1/5], Step [2076/10336], Loss: 3.8472\n",
      "Epoch [1/5], Step [2078/10336], Loss: 2.3330\n",
      "Epoch [1/5], Step [2080/10336], Loss: 1.6050\n",
      "Epoch [1/5], Step [2082/10336], Loss: 3.9137\n",
      "Epoch [1/5], Step [2084/10336], Loss: 2.3873\n",
      "Epoch [1/5], Step [2086/10336], Loss: 3.2676\n",
      "Epoch [1/5], Step [2088/10336], Loss: 2.2391\n",
      "Epoch [1/5], Step [2090/10336], Loss: 2.0687\n",
      "Epoch [1/5], Step [2092/10336], Loss: 0.1250\n",
      "Epoch [1/5], Step [2094/10336], Loss: 1.8733\n",
      "Epoch [1/5], Step [2096/10336], Loss: 2.1404\n",
      "Epoch [1/5], Step [2098/10336], Loss: 1.2374\n",
      "Epoch [1/5], Step [2100/10336], Loss: 2.0528\n",
      "Epoch [1/5], Step [2102/10336], Loss: 1.1535\n",
      "Epoch [1/5], Step [2104/10336], Loss: 2.4191\n",
      "Epoch [1/5], Step [2106/10336], Loss: 1.4762\n",
      "Epoch [1/5], Step [2108/10336], Loss: 2.7257\n",
      "Epoch [1/5], Step [2110/10336], Loss: 3.2274\n",
      "Epoch [1/5], Step [2112/10336], Loss: 3.7266\n",
      "Epoch [1/5], Step [2114/10336], Loss: 2.2654\n",
      "Epoch [1/5], Step [2116/10336], Loss: 1.2939\n",
      "Epoch [1/5], Step [2118/10336], Loss: 2.9162\n",
      "Epoch [1/5], Step [2120/10336], Loss: 4.1839\n",
      "Epoch [1/5], Step [2122/10336], Loss: 2.4494\n",
      "Epoch [1/5], Step [2124/10336], Loss: 2.5856\n",
      "Epoch [1/5], Step [2126/10336], Loss: 0.7443\n",
      "Epoch [1/5], Step [2128/10336], Loss: 2.3166\n",
      "Epoch [1/5], Step [2130/10336], Loss: 1.4592\n",
      "Epoch [1/5], Step [2132/10336], Loss: 1.4351\n",
      "Epoch [1/5], Step [2134/10336], Loss: 0.9180\n",
      "Epoch [1/5], Step [2136/10336], Loss: 2.9825\n",
      "Epoch [1/5], Step [2138/10336], Loss: 2.8097\n",
      "Epoch [1/5], Step [2140/10336], Loss: 0.3488\n",
      "Epoch [1/5], Step [2142/10336], Loss: 0.7191\n",
      "Epoch [1/5], Step [2144/10336], Loss: 1.8901\n",
      "Epoch [1/5], Step [2146/10336], Loss: 3.6281\n",
      "Epoch [1/5], Step [2148/10336], Loss: 2.0535\n",
      "Epoch [1/5], Step [2150/10336], Loss: 0.9246\n",
      "Epoch [1/5], Step [2152/10336], Loss: 0.8686\n",
      "Epoch [1/5], Step [2154/10336], Loss: 4.1929\n",
      "Epoch [1/5], Step [2156/10336], Loss: 4.8255\n",
      "Epoch [1/5], Step [2158/10336], Loss: 0.9659\n",
      "Epoch [1/5], Step [2160/10336], Loss: 2.1334\n",
      "Epoch [1/5], Step [2162/10336], Loss: 0.6769\n",
      "Epoch [1/5], Step [2164/10336], Loss: 4.3064\n",
      "Epoch [1/5], Step [2166/10336], Loss: 8.1349\n",
      "Epoch [1/5], Step [2168/10336], Loss: 5.8783\n",
      "Epoch [1/5], Step [2170/10336], Loss: 4.3559\n",
      "Epoch [1/5], Step [2172/10336], Loss: 5.1429\n",
      "Epoch [1/5], Step [2174/10336], Loss: 3.3336\n",
      "Epoch [1/5], Step [2176/10336], Loss: 1.9254\n",
      "Epoch [1/5], Step [2178/10336], Loss: 4.5267\n",
      "Epoch [1/5], Step [2180/10336], Loss: 3.0489\n",
      "Epoch [1/5], Step [2182/10336], Loss: 3.6817\n",
      "Epoch [1/5], Step [2184/10336], Loss: 0.3506\n",
      "Epoch [1/5], Step [2186/10336], Loss: 3.6756\n",
      "Epoch [1/5], Step [2188/10336], Loss: 0.9848\n",
      "Epoch [1/5], Step [2190/10336], Loss: 3.9950\n",
      "Epoch [1/5], Step [2192/10336], Loss: 1.3405\n",
      "Epoch [1/5], Step [2194/10336], Loss: 5.7473\n",
      "Epoch [1/5], Step [2196/10336], Loss: 4.1828\n",
      "Epoch [1/5], Step [2198/10336], Loss: 1.5896\n",
      "Epoch [1/5], Step [2200/10336], Loss: 2.0654\n",
      "Epoch [1/5], Step [2202/10336], Loss: 1.5582\n",
      "Epoch [1/5], Step [2204/10336], Loss: 0.5415\n",
      "Epoch [1/5], Step [2206/10336], Loss: 3.6239\n",
      "Epoch [1/5], Step [2208/10336], Loss: 2.1432\n",
      "Epoch [1/5], Step [2210/10336], Loss: 3.1264\n",
      "Epoch [1/5], Step [2212/10336], Loss: 3.3588\n",
      "Epoch [1/5], Step [2214/10336], Loss: 2.0975\n",
      "Epoch [1/5], Step [2216/10336], Loss: 0.3704\n",
      "Epoch [1/5], Step [2218/10336], Loss: 0.8739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2220/10336], Loss: 2.2341\n",
      "Epoch [1/5], Step [2222/10336], Loss: 2.1043\n",
      "Epoch [1/5], Step [2224/10336], Loss: 3.0017\n",
      "Epoch [1/5], Step [2226/10336], Loss: 1.6325\n",
      "Epoch [1/5], Step [2228/10336], Loss: 1.0591\n",
      "Epoch [1/5], Step [2230/10336], Loss: 3.4174\n",
      "Epoch [1/5], Step [2232/10336], Loss: 1.3475\n",
      "Epoch [1/5], Step [2234/10336], Loss: 3.1686\n",
      "Epoch [1/5], Step [2236/10336], Loss: 1.6793\n",
      "Epoch [1/5], Step [2238/10336], Loss: 0.8925\n",
      "Epoch [1/5], Step [2240/10336], Loss: 3.6954\n",
      "Epoch [1/5], Step [2242/10336], Loss: 3.5106\n",
      "Epoch [1/5], Step [2244/10336], Loss: 2.8054\n",
      "Epoch [1/5], Step [2246/10336], Loss: 0.6353\n",
      "Epoch [1/5], Step [2248/10336], Loss: 1.3820\n",
      "Epoch [1/5], Step [2250/10336], Loss: 0.1093\n",
      "Epoch [1/5], Step [2252/10336], Loss: 3.1036\n",
      "Epoch [1/5], Step [2254/10336], Loss: 6.1257\n",
      "Epoch [1/5], Step [2256/10336], Loss: 2.1314\n",
      "Epoch [1/5], Step [2258/10336], Loss: 2.1272\n",
      "Epoch [1/5], Step [2260/10336], Loss: 1.5589\n",
      "Epoch [1/5], Step [2262/10336], Loss: 2.9296\n",
      "Epoch [1/5], Step [2264/10336], Loss: 1.5062\n",
      "Epoch [1/5], Step [2266/10336], Loss: 0.9238\n",
      "Epoch [1/5], Step [2268/10336], Loss: 3.0352\n",
      "Epoch [1/5], Step [2270/10336], Loss: 3.3950\n",
      "Epoch [1/5], Step [2272/10336], Loss: 1.1004\n",
      "Epoch [1/5], Step [2274/10336], Loss: 3.0853\n",
      "Epoch [1/5], Step [2276/10336], Loss: 0.6802\n",
      "Epoch [1/5], Step [2278/10336], Loss: 3.0540\n",
      "Epoch [1/5], Step [2280/10336], Loss: 1.5228\n",
      "Epoch [1/5], Step [2282/10336], Loss: 3.1480\n",
      "Epoch [1/5], Step [2284/10336], Loss: 4.4970\n",
      "Epoch [1/5], Step [2286/10336], Loss: 2.1803\n",
      "Epoch [1/5], Step [2288/10336], Loss: 3.5371\n",
      "Epoch [1/5], Step [2290/10336], Loss: 3.7237\n",
      "Epoch [1/5], Step [2292/10336], Loss: 2.6116\n",
      "Epoch [1/5], Step [2294/10336], Loss: 1.2323\n",
      "Epoch [1/5], Step [2296/10336], Loss: 0.4500\n",
      "Epoch [1/5], Step [2298/10336], Loss: 1.6003\n",
      "Epoch [1/5], Step [2300/10336], Loss: 1.8000\n",
      "Epoch [1/5], Step [2302/10336], Loss: 1.1961\n",
      "Epoch [1/5], Step [2304/10336], Loss: 2.6850\n",
      "Epoch [1/5], Step [2306/10336], Loss: 0.1109\n",
      "Epoch [1/5], Step [2308/10336], Loss: 4.0413\n",
      "Epoch [1/5], Step [2310/10336], Loss: 4.7130\n",
      "Epoch [1/5], Step [2312/10336], Loss: 4.7379\n",
      "Epoch [1/5], Step [2314/10336], Loss: 0.3499\n",
      "Epoch [1/5], Step [2316/10336], Loss: 4.8374\n",
      "Epoch [1/5], Step [2318/10336], Loss: 2.3137\n",
      "Epoch [1/5], Step [2320/10336], Loss: 2.2563\n",
      "Epoch [1/5], Step [2322/10336], Loss: 1.3807\n",
      "Epoch [1/5], Step [2324/10336], Loss: 2.9962\n",
      "Epoch [1/5], Step [2326/10336], Loss: 3.2779\n",
      "Epoch [1/5], Step [2328/10336], Loss: 2.3466\n",
      "Epoch [1/5], Step [2330/10336], Loss: 0.4134\n",
      "Epoch [1/5], Step [2332/10336], Loss: 3.3515\n",
      "Epoch [1/5], Step [2334/10336], Loss: 0.8851\n",
      "Epoch [1/5], Step [2336/10336], Loss: 5.4077\n",
      "Epoch [1/5], Step [2338/10336], Loss: 4.2572\n",
      "Epoch [1/5], Step [2340/10336], Loss: 1.6455\n",
      "Epoch [1/5], Step [2342/10336], Loss: 2.1749\n",
      "Epoch [1/5], Step [2344/10336], Loss: 2.3741\n",
      "Epoch [1/5], Step [2346/10336], Loss: 1.5007\n",
      "Epoch [1/5], Step [2348/10336], Loss: 2.6935\n",
      "Epoch [1/5], Step [2350/10336], Loss: 3.0992\n",
      "Epoch [1/5], Step [2352/10336], Loss: 3.0282\n",
      "Epoch [1/5], Step [2354/10336], Loss: 1.3195\n",
      "Epoch [1/5], Step [2356/10336], Loss: 2.6455\n",
      "Epoch [1/5], Step [2358/10336], Loss: 3.4598\n",
      "Epoch [1/5], Step [2360/10336], Loss: 2.2118\n",
      "Epoch [1/5], Step [2362/10336], Loss: 2.5442\n",
      "Epoch [1/5], Step [2364/10336], Loss: 2.2519\n",
      "Epoch [1/5], Step [2366/10336], Loss: 4.7081\n",
      "Epoch [1/5], Step [2368/10336], Loss: 1.9824\n",
      "Epoch [1/5], Step [2370/10336], Loss: 3.6901\n",
      "Epoch [1/5], Step [2372/10336], Loss: 3.0012\n",
      "Epoch [1/5], Step [2374/10336], Loss: 0.8347\n",
      "Epoch [1/5], Step [2376/10336], Loss: 0.5483\n",
      "Epoch [1/5], Step [2378/10336], Loss: 0.0919\n",
      "Epoch [1/5], Step [2380/10336], Loss: 3.0122\n",
      "Epoch [1/5], Step [2382/10336], Loss: 2.8919\n",
      "Epoch [1/5], Step [2384/10336], Loss: 3.7933\n",
      "Epoch [1/5], Step [2386/10336], Loss: 0.8690\n",
      "Epoch [1/5], Step [2388/10336], Loss: 2.1173\n",
      "Epoch [1/5], Step [2390/10336], Loss: 3.0665\n",
      "Epoch [1/5], Step [2392/10336], Loss: 2.2035\n",
      "Epoch [1/5], Step [2394/10336], Loss: 1.8627\n",
      "Epoch [1/5], Step [2396/10336], Loss: 4.7794\n",
      "Epoch [1/5], Step [2398/10336], Loss: 0.4920\n",
      "Epoch [1/5], Step [2400/10336], Loss: 1.8271\n",
      "Epoch [1/5], Step [2402/10336], Loss: 2.5623\n",
      "Epoch [1/5], Step [2404/10336], Loss: 1.0307\n",
      "Epoch [1/5], Step [2406/10336], Loss: 1.1868\n",
      "Epoch [1/5], Step [2408/10336], Loss: 0.3746\n",
      "Epoch [1/5], Step [2410/10336], Loss: 2.5637\n",
      "Epoch [1/5], Step [2412/10336], Loss: 2.8361\n",
      "Epoch [1/5], Step [2414/10336], Loss: 1.1568\n",
      "Epoch [1/5], Step [2416/10336], Loss: 2.4271\n",
      "Epoch [1/5], Step [2418/10336], Loss: 3.0211\n",
      "Epoch [1/5], Step [2420/10336], Loss: 0.0755\n",
      "Epoch [1/5], Step [2422/10336], Loss: 0.6224\n",
      "Epoch [1/5], Step [2424/10336], Loss: 2.9424\n",
      "Epoch [1/5], Step [2426/10336], Loss: 2.6184\n",
      "Epoch [1/5], Step [2428/10336], Loss: 3.0696\n",
      "Epoch [1/5], Step [2430/10336], Loss: 2.6551\n",
      "Epoch [1/5], Step [2432/10336], Loss: 0.9813\n",
      "Epoch [1/5], Step [2434/10336], Loss: 1.1044\n",
      "Epoch [1/5], Step [2436/10336], Loss: 1.0399\n",
      "Epoch [1/5], Step [2438/10336], Loss: 2.4071\n",
      "Epoch [1/5], Step [2440/10336], Loss: 0.9772\n",
      "Epoch [1/5], Step [2442/10336], Loss: 4.1119\n",
      "Epoch [1/5], Step [2444/10336], Loss: 5.1420\n",
      "Epoch [1/5], Step [2446/10336], Loss: 1.1643\n",
      "Epoch [1/5], Step [2448/10336], Loss: 0.2144\n",
      "Epoch [1/5], Step [2450/10336], Loss: 1.9317\n",
      "Epoch [1/5], Step [2452/10336], Loss: 2.2425\n",
      "Epoch [1/5], Step [2454/10336], Loss: 1.8656\n",
      "Epoch [1/5], Step [2456/10336], Loss: 0.0500\n",
      "Epoch [1/5], Step [2458/10336], Loss: 1.9700\n",
      "Epoch [1/5], Step [2460/10336], Loss: 0.2621\n",
      "Epoch [1/5], Step [2462/10336], Loss: 6.0882\n",
      "Epoch [1/5], Step [2464/10336], Loss: 1.2344\n",
      "Epoch [1/5], Step [2466/10336], Loss: 2.5499\n",
      "Epoch [1/5], Step [2468/10336], Loss: 2.1445\n",
      "Epoch [1/5], Step [2470/10336], Loss: 1.0601\n",
      "Epoch [1/5], Step [2472/10336], Loss: 4.2544\n",
      "Epoch [1/5], Step [2474/10336], Loss: 0.3386\n",
      "Epoch [1/5], Step [2476/10336], Loss: 3.8695\n",
      "Epoch [1/5], Step [2478/10336], Loss: 0.5755\n",
      "Epoch [1/5], Step [2480/10336], Loss: 1.3809\n",
      "Epoch [1/5], Step [2482/10336], Loss: 5.9013\n",
      "Epoch [1/5], Step [2484/10336], Loss: 2.1524\n",
      "Epoch [1/5], Step [2486/10336], Loss: 1.8803\n",
      "Epoch [1/5], Step [2488/10336], Loss: 0.7562\n",
      "Epoch [1/5], Step [2490/10336], Loss: 1.2596\n",
      "Epoch [1/5], Step [2492/10336], Loss: 4.7420\n",
      "Epoch [1/5], Step [2494/10336], Loss: 0.0137\n",
      "Epoch [1/5], Step [2496/10336], Loss: 4.8213\n",
      "Epoch [1/5], Step [2498/10336], Loss: 3.0509\n",
      "Epoch [1/5], Step [2500/10336], Loss: 3.4004\n",
      "Epoch [1/5], Step [2502/10336], Loss: 0.6843\n",
      "Epoch [1/5], Step [2504/10336], Loss: 0.4919\n",
      "Epoch [1/5], Step [2506/10336], Loss: 2.3590\n",
      "Epoch [1/5], Step [2508/10336], Loss: 1.8623\n",
      "Epoch [1/5], Step [2510/10336], Loss: 2.6174\n",
      "Epoch [1/5], Step [2512/10336], Loss: 2.0207\n",
      "Epoch [1/5], Step [2514/10336], Loss: 0.3628\n",
      "Epoch [1/5], Step [2516/10336], Loss: 2.6610\n",
      "Epoch [1/5], Step [2518/10336], Loss: 1.0858\n",
      "Epoch [1/5], Step [2520/10336], Loss: 2.4691\n",
      "Epoch [1/5], Step [2522/10336], Loss: 1.7495\n",
      "Epoch [1/5], Step [2524/10336], Loss: 1.5874\n",
      "Epoch [1/5], Step [2526/10336], Loss: 4.8901\n",
      "Epoch [1/5], Step [2528/10336], Loss: 1.4836\n",
      "Epoch [1/5], Step [2530/10336], Loss: 1.7708\n",
      "Epoch [1/5], Step [2532/10336], Loss: 0.2887\n",
      "Epoch [1/5], Step [2534/10336], Loss: 0.5025\n",
      "Epoch [1/5], Step [2536/10336], Loss: 3.1358\n",
      "Epoch [1/5], Step [2538/10336], Loss: 1.4904\n",
      "Epoch [1/5], Step [2540/10336], Loss: 1.9653\n",
      "Epoch [1/5], Step [2542/10336], Loss: 0.9077\n",
      "Epoch [1/5], Step [2544/10336], Loss: 1.9296\n",
      "Epoch [1/5], Step [2546/10336], Loss: 2.9954\n",
      "Epoch [1/5], Step [2548/10336], Loss: 0.9917\n",
      "Epoch [1/5], Step [2550/10336], Loss: 3.2993\n",
      "Epoch [1/5], Step [2552/10336], Loss: 5.2537\n",
      "Epoch [1/5], Step [2554/10336], Loss: 1.1748\n",
      "Epoch [1/5], Step [2556/10336], Loss: 3.1691\n",
      "Epoch [1/5], Step [2558/10336], Loss: 0.1341\n",
      "Epoch [1/5], Step [2560/10336], Loss: 0.3715\n",
      "Epoch [1/5], Step [2562/10336], Loss: 2.8419\n",
      "Epoch [1/5], Step [2564/10336], Loss: 6.2278\n",
      "Epoch [1/5], Step [2566/10336], Loss: 2.5907\n",
      "Epoch [1/5], Step [2568/10336], Loss: 1.1477\n",
      "Epoch [1/5], Step [2570/10336], Loss: 3.7616\n",
      "Epoch [1/5], Step [2572/10336], Loss: 1.1627\n",
      "Epoch [1/5], Step [2574/10336], Loss: 1.9344\n",
      "Epoch [1/5], Step [2576/10336], Loss: 2.8981\n",
      "Epoch [1/5], Step [2578/10336], Loss: 1.8127\n",
      "Epoch [1/5], Step [2580/10336], Loss: 0.4694\n",
      "Epoch [1/5], Step [2582/10336], Loss: 3.0760\n",
      "Epoch [1/5], Step [2584/10336], Loss: 1.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2586/10336], Loss: 2.5525\n",
      "Epoch [1/5], Step [2588/10336], Loss: 2.2055\n",
      "Epoch [1/5], Step [2590/10336], Loss: 1.3160\n",
      "Epoch [1/5], Step [2592/10336], Loss: 0.1987\n",
      "Epoch [1/5], Step [2594/10336], Loss: 0.9521\n",
      "Epoch [1/5], Step [2596/10336], Loss: 4.3784\n",
      "Epoch [1/5], Step [2598/10336], Loss: 1.6013\n",
      "Epoch [1/5], Step [2600/10336], Loss: 0.3167\n",
      "Epoch [1/5], Step [2602/10336], Loss: 2.4959\n",
      "Epoch [1/5], Step [2604/10336], Loss: 1.7241\n",
      "Epoch [1/5], Step [2606/10336], Loss: 2.1510\n",
      "Epoch [1/5], Step [2608/10336], Loss: 0.3092\n",
      "Epoch [1/5], Step [2610/10336], Loss: 0.8564\n",
      "Epoch [1/5], Step [2612/10336], Loss: 3.4814\n",
      "Epoch [1/5], Step [2614/10336], Loss: 0.2292\n",
      "Epoch [1/5], Step [2616/10336], Loss: 2.7915\n",
      "Epoch [1/5], Step [2618/10336], Loss: 1.5133\n",
      "Epoch [1/5], Step [2620/10336], Loss: 2.3190\n",
      "Epoch [1/5], Step [2622/10336], Loss: 4.9105\n",
      "Epoch [1/5], Step [2624/10336], Loss: 1.9943\n",
      "Epoch [1/5], Step [2626/10336], Loss: 0.9368\n",
      "Epoch [1/5], Step [2628/10336], Loss: 2.4417\n",
      "Epoch [1/5], Step [2630/10336], Loss: 1.8861\n",
      "Epoch [1/5], Step [2632/10336], Loss: 1.1327\n",
      "Epoch [1/5], Step [2634/10336], Loss: 1.8752\n",
      "Epoch [1/5], Step [2636/10336], Loss: 2.0408\n",
      "Epoch [1/5], Step [2638/10336], Loss: 0.8946\n",
      "Epoch [1/5], Step [2640/10336], Loss: 4.2234\n",
      "Epoch [1/5], Step [2642/10336], Loss: 1.3027\n",
      "Epoch [1/5], Step [2644/10336], Loss: 4.0140\n",
      "Epoch [1/5], Step [2646/10336], Loss: 0.1398\n",
      "Epoch [1/5], Step [2648/10336], Loss: 0.8673\n",
      "Epoch [1/5], Step [2650/10336], Loss: 1.8269\n",
      "Epoch [1/5], Step [2652/10336], Loss: 5.2629\n",
      "Epoch [1/5], Step [2654/10336], Loss: 3.9886\n",
      "Epoch [1/5], Step [2656/10336], Loss: 1.0654\n",
      "Epoch [1/5], Step [2658/10336], Loss: 0.4303\n",
      "Epoch [1/5], Step [2660/10336], Loss: 0.6214\n",
      "Epoch [1/5], Step [2662/10336], Loss: 2.1934\n",
      "Epoch [1/5], Step [2664/10336], Loss: 1.6902\n",
      "Epoch [1/5], Step [2666/10336], Loss: 2.6769\n",
      "Epoch [1/5], Step [2668/10336], Loss: 0.3108\n",
      "Epoch [1/5], Step [2670/10336], Loss: 0.8990\n",
      "Epoch [1/5], Step [2672/10336], Loss: 3.1330\n",
      "Epoch [1/5], Step [2674/10336], Loss: 2.2833\n",
      "Epoch [1/5], Step [2676/10336], Loss: 0.0786\n",
      "Epoch [1/5], Step [2678/10336], Loss: 3.5817\n",
      "Epoch [1/5], Step [2680/10336], Loss: 4.1501\n",
      "Epoch [1/5], Step [2682/10336], Loss: 1.2693\n",
      "Epoch [1/5], Step [2684/10336], Loss: 0.8751\n",
      "Epoch [1/5], Step [2686/10336], Loss: 0.6078\n",
      "Epoch [1/5], Step [2688/10336], Loss: 3.9269\n",
      "Epoch [1/5], Step [2690/10336], Loss: 1.3055\n",
      "Epoch [1/5], Step [2692/10336], Loss: 3.3509\n",
      "Epoch [1/5], Step [2694/10336], Loss: 1.0718\n",
      "Epoch [1/5], Step [2696/10336], Loss: 1.8083\n",
      "Epoch [1/5], Step [2698/10336], Loss: 1.3703\n",
      "Epoch [1/5], Step [2700/10336], Loss: 2.0222\n",
      "Epoch [1/5], Step [2702/10336], Loss: 0.8227\n",
      "Epoch [1/5], Step [2704/10336], Loss: 0.0777\n",
      "Epoch [1/5], Step [2706/10336], Loss: 2.9518\n",
      "Epoch [1/5], Step [2708/10336], Loss: 3.9399\n",
      "Epoch [1/5], Step [2710/10336], Loss: 3.1364\n",
      "Epoch [1/5], Step [2712/10336], Loss: 0.6157\n",
      "Epoch [1/5], Step [2714/10336], Loss: 0.6363\n",
      "Epoch [1/5], Step [2716/10336], Loss: 4.2527\n",
      "Epoch [1/5], Step [2718/10336], Loss: 3.5105\n",
      "Epoch [1/5], Step [2720/10336], Loss: 2.2689\n",
      "Epoch [1/5], Step [2722/10336], Loss: 1.6915\n",
      "Epoch [1/5], Step [2724/10336], Loss: 1.6952\n",
      "Epoch [1/5], Step [2726/10336], Loss: 1.6559\n",
      "Epoch [1/5], Step [2728/10336], Loss: 0.9081\n",
      "Epoch [1/5], Step [2730/10336], Loss: 0.6673\n",
      "Epoch [1/5], Step [2732/10336], Loss: 4.1681\n",
      "Epoch [1/5], Step [2734/10336], Loss: 1.2515\n",
      "Epoch [1/5], Step [2736/10336], Loss: 2.1094\n",
      "Epoch [1/5], Step [2738/10336], Loss: 1.6353\n",
      "Epoch [1/5], Step [2740/10336], Loss: 0.2923\n",
      "Epoch [1/5], Step [2742/10336], Loss: 0.5621\n",
      "Epoch [1/5], Step [2744/10336], Loss: 1.3608\n",
      "Epoch [1/5], Step [2746/10336], Loss: 1.6784\n",
      "Epoch [1/5], Step [2748/10336], Loss: 2.8430\n",
      "Epoch [1/5], Step [2750/10336], Loss: 0.3783\n",
      "Epoch [1/5], Step [2752/10336], Loss: 2.9178\n",
      "Epoch [1/5], Step [2754/10336], Loss: 1.4528\n",
      "Epoch [1/5], Step [2756/10336], Loss: 2.7497\n",
      "Epoch [1/5], Step [2758/10336], Loss: 2.9990\n",
      "Epoch [1/5], Step [2760/10336], Loss: 0.9010\n",
      "Epoch [1/5], Step [2762/10336], Loss: 3.2453\n",
      "Epoch [1/5], Step [2764/10336], Loss: 4.2159\n",
      "Epoch [1/5], Step [2766/10336], Loss: 3.3026\n",
      "Epoch [1/5], Step [2768/10336], Loss: 0.1680\n",
      "Epoch [1/5], Step [2770/10336], Loss: 0.7615\n",
      "Epoch [1/5], Step [2772/10336], Loss: 0.2983\n",
      "Epoch [1/5], Step [2774/10336], Loss: 1.6515\n",
      "Epoch [1/5], Step [2776/10336], Loss: 1.9291\n",
      "Epoch [1/5], Step [2778/10336], Loss: 1.0117\n",
      "Epoch [1/5], Step [2780/10336], Loss: 0.0712\n",
      "Epoch [1/5], Step [2782/10336], Loss: 0.0387\n",
      "Epoch [1/5], Step [2784/10336], Loss: 4.2063\n",
      "Epoch [1/5], Step [2786/10336], Loss: 0.0608\n",
      "Epoch [1/5], Step [2788/10336], Loss: 0.5460\n",
      "Epoch [1/5], Step [2790/10336], Loss: 0.6833\n",
      "Epoch [1/5], Step [2792/10336], Loss: 0.1776\n",
      "Epoch [1/5], Step [2794/10336], Loss: 1.4593\n",
      "Epoch [1/5], Step [2796/10336], Loss: 3.6662\n",
      "Epoch [1/5], Step [2798/10336], Loss: 3.2077\n",
      "Epoch [1/5], Step [2800/10336], Loss: 1.0657\n",
      "Epoch [1/5], Step [2802/10336], Loss: 0.4779\n",
      "Epoch [1/5], Step [2804/10336], Loss: 3.8034\n",
      "Epoch [1/5], Step [2806/10336], Loss: 1.6974\n",
      "Epoch [1/5], Step [2808/10336], Loss: 1.9701\n",
      "Epoch [1/5], Step [2810/10336], Loss: 1.5713\n",
      "Epoch [1/5], Step [2812/10336], Loss: 0.3856\n",
      "Epoch [1/5], Step [2814/10336], Loss: 1.7458\n",
      "Epoch [1/5], Step [2816/10336], Loss: 1.1849\n",
      "Epoch [1/5], Step [2818/10336], Loss: 0.0693\n",
      "Epoch [1/5], Step [2820/10336], Loss: 1.2627\n",
      "Epoch [1/5], Step [2822/10336], Loss: 0.9515\n",
      "Epoch [1/5], Step [2824/10336], Loss: 5.9446\n",
      "Epoch [1/5], Step [2826/10336], Loss: 3.1949\n",
      "Epoch [1/5], Step [2828/10336], Loss: 0.1599\n",
      "Epoch [1/5], Step [2830/10336], Loss: 1.7262\n",
      "Epoch [1/5], Step [2832/10336], Loss: 0.9753\n",
      "Epoch [1/5], Step [2834/10336], Loss: 0.4976\n",
      "Epoch [1/5], Step [2836/10336], Loss: 2.1327\n",
      "Epoch [1/5], Step [2838/10336], Loss: 3.5513\n",
      "Epoch [1/5], Step [2840/10336], Loss: 0.6798\n",
      "Epoch [1/5], Step [2842/10336], Loss: 3.1590\n",
      "Epoch [1/5], Step [2844/10336], Loss: 2.0794\n",
      "Epoch [1/5], Step [2846/10336], Loss: 2.3900\n",
      "Epoch [1/5], Step [2848/10336], Loss: 1.7314\n",
      "Epoch [1/5], Step [2850/10336], Loss: 0.9691\n",
      "Epoch [1/5], Step [2852/10336], Loss: 3.0894\n",
      "Epoch [1/5], Step [2854/10336], Loss: 1.4800\n",
      "Epoch [1/5], Step [2856/10336], Loss: 0.7350\n",
      "Epoch [1/5], Step [2858/10336], Loss: 0.9110\n",
      "Epoch [1/5], Step [2860/10336], Loss: 3.0922\n",
      "Epoch [1/5], Step [2862/10336], Loss: 2.4763\n",
      "Epoch [1/5], Step [2864/10336], Loss: 2.4278\n",
      "Epoch [1/5], Step [2866/10336], Loss: 2.1098\n",
      "Epoch [1/5], Step [2868/10336], Loss: 1.6297\n",
      "Epoch [1/5], Step [2870/10336], Loss: 3.0030\n",
      "Epoch [1/5], Step [2872/10336], Loss: 0.5595\n",
      "Epoch [1/5], Step [2874/10336], Loss: 4.0867\n",
      "Epoch [1/5], Step [2876/10336], Loss: 1.2184\n",
      "Epoch [1/5], Step [2878/10336], Loss: 2.9110\n",
      "Epoch [1/5], Step [2880/10336], Loss: 2.7850\n",
      "Epoch [1/5], Step [2882/10336], Loss: 1.4840\n",
      "Epoch [1/5], Step [2884/10336], Loss: 2.2010\n",
      "Epoch [1/5], Step [2886/10336], Loss: 2.2026\n",
      "Epoch [1/5], Step [2888/10336], Loss: 1.7048\n",
      "Epoch [1/5], Step [2890/10336], Loss: 0.7937\n",
      "Epoch [1/5], Step [2892/10336], Loss: 2.3565\n",
      "Epoch [1/5], Step [2894/10336], Loss: 1.7597\n",
      "Epoch [1/5], Step [2896/10336], Loss: 1.1836\n",
      "Epoch [1/5], Step [2898/10336], Loss: 0.8358\n",
      "Epoch [1/5], Step [2900/10336], Loss: 1.3760\n",
      "Epoch [1/5], Step [2902/10336], Loss: 1.6301\n",
      "Epoch [1/5], Step [2904/10336], Loss: 0.8809\n",
      "Epoch [1/5], Step [2906/10336], Loss: 3.0140\n",
      "Epoch [1/5], Step [2908/10336], Loss: 1.1138\n",
      "Epoch [1/5], Step [2910/10336], Loss: 0.3666\n",
      "Epoch [1/5], Step [2912/10336], Loss: 2.1036\n",
      "Epoch [1/5], Step [2914/10336], Loss: 1.9312\n",
      "Epoch [1/5], Step [2916/10336], Loss: 1.7548\n",
      "Epoch [1/5], Step [2918/10336], Loss: 1.5502\n",
      "Epoch [1/5], Step [2920/10336], Loss: 0.4079\n",
      "Epoch [1/5], Step [2922/10336], Loss: 2.6118\n",
      "Epoch [1/5], Step [2924/10336], Loss: 0.4323\n",
      "Epoch [1/5], Step [2926/10336], Loss: 1.9054\n",
      "Epoch [1/5], Step [2928/10336], Loss: 3.9983\n",
      "Epoch [1/5], Step [2930/10336], Loss: 0.8851\n",
      "Epoch [1/5], Step [2932/10336], Loss: 1.9639\n",
      "Epoch [1/5], Step [2934/10336], Loss: 0.8911\n",
      "Epoch [1/5], Step [2936/10336], Loss: 2.2348\n",
      "Epoch [1/5], Step [2938/10336], Loss: 1.3931\n",
      "Epoch [1/5], Step [2940/10336], Loss: 2.2982\n",
      "Epoch [1/5], Step [2942/10336], Loss: 2.9806\n",
      "Epoch [1/5], Step [2944/10336], Loss: 2.1748\n",
      "Epoch [1/5], Step [2946/10336], Loss: 1.7987\n",
      "Epoch [1/5], Step [2948/10336], Loss: 3.8343\n",
      "Epoch [1/5], Step [2950/10336], Loss: 0.6065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2952/10336], Loss: 1.4867\n",
      "Epoch [1/5], Step [2954/10336], Loss: 4.7482\n",
      "Epoch [1/5], Step [2956/10336], Loss: 1.2304\n",
      "Epoch [1/5], Step [2958/10336], Loss: 0.8887\n",
      "Epoch [1/5], Step [2960/10336], Loss: 2.7847\n",
      "Epoch [1/5], Step [2962/10336], Loss: 0.6927\n",
      "Epoch [1/5], Step [2964/10336], Loss: 2.5848\n",
      "Epoch [1/5], Step [2966/10336], Loss: 1.0322\n",
      "Epoch [1/5], Step [2968/10336], Loss: 3.7295\n",
      "Epoch [1/5], Step [2970/10336], Loss: 0.2351\n",
      "Epoch [1/5], Step [2972/10336], Loss: 1.1534\n",
      "Epoch [1/5], Step [2974/10336], Loss: 3.5203\n",
      "Epoch [1/5], Step [2976/10336], Loss: 0.5021\n",
      "Epoch [1/5], Step [2978/10336], Loss: 0.3655\n",
      "Epoch [1/5], Step [2980/10336], Loss: 3.7944\n",
      "Epoch [1/5], Step [2982/10336], Loss: 1.8792\n",
      "Epoch [1/5], Step [2984/10336], Loss: 2.3440\n",
      "Epoch [1/5], Step [2986/10336], Loss: 1.4932\n",
      "Epoch [1/5], Step [2988/10336], Loss: 1.3569\n",
      "Epoch [1/5], Step [2990/10336], Loss: 2.4441\n",
      "Epoch [1/5], Step [2992/10336], Loss: 3.4563\n",
      "Epoch [1/5], Step [2994/10336], Loss: 1.2959\n",
      "Epoch [1/5], Step [2996/10336], Loss: 0.4114\n",
      "Epoch [1/5], Step [2998/10336], Loss: 2.3140\n",
      "Epoch [1/5], Step [3000/10336], Loss: 1.9238\n",
      "Epoch [1/5], Step [3002/10336], Loss: 0.2933\n",
      "Epoch [1/5], Step [3004/10336], Loss: 3.2837\n",
      "Epoch [1/5], Step [3006/10336], Loss: 3.5582\n",
      "Epoch [1/5], Step [3008/10336], Loss: 0.6945\n",
      "Epoch [1/5], Step [3010/10336], Loss: 0.3356\n",
      "Epoch [1/5], Step [3012/10336], Loss: 2.1226\n",
      "Epoch [1/5], Step [3014/10336], Loss: 0.1325\n",
      "Epoch [1/5], Step [3016/10336], Loss: 1.9533\n",
      "Epoch [1/5], Step [3018/10336], Loss: 1.0150\n",
      "Epoch [1/5], Step [3020/10336], Loss: 2.5469\n",
      "Epoch [1/5], Step [3022/10336], Loss: 1.2878\n",
      "Epoch [1/5], Step [3024/10336], Loss: 3.7992\n",
      "Epoch [1/5], Step [3026/10336], Loss: 0.8348\n",
      "Epoch [1/5], Step [3028/10336], Loss: 2.0908\n",
      "Epoch [1/5], Step [3030/10336], Loss: 1.4916\n",
      "Epoch [1/5], Step [3032/10336], Loss: 1.6930\n",
      "Epoch [1/5], Step [3034/10336], Loss: 3.9849\n",
      "Epoch [1/5], Step [3036/10336], Loss: 2.2225\n",
      "Epoch [1/5], Step [3038/10336], Loss: 2.5979\n",
      "Epoch [1/5], Step [3040/10336], Loss: 2.4992\n",
      "Epoch [1/5], Step [3042/10336], Loss: 7.4992\n",
      "Epoch [1/5], Step [3044/10336], Loss: 1.6626\n",
      "Epoch [1/5], Step [3046/10336], Loss: 1.8054\n",
      "Epoch [1/5], Step [3048/10336], Loss: 3.0029\n",
      "Epoch [1/5], Step [3050/10336], Loss: 1.5596\n",
      "Epoch [1/5], Step [3052/10336], Loss: 0.8920\n",
      "Epoch [1/5], Step [3054/10336], Loss: 1.7300\n",
      "Epoch [1/5], Step [3056/10336], Loss: 2.4705\n",
      "Epoch [1/5], Step [3058/10336], Loss: 3.4251\n",
      "Epoch [1/5], Step [3060/10336], Loss: 3.6793\n",
      "Epoch [1/5], Step [3062/10336], Loss: 1.8194\n",
      "Epoch [1/5], Step [3064/10336], Loss: 2.8408\n",
      "Epoch [1/5], Step [3066/10336], Loss: 2.3477\n",
      "Epoch [1/5], Step [3068/10336], Loss: 0.0850\n",
      "Epoch [1/5], Step [3070/10336], Loss: 0.5536\n",
      "Epoch [1/5], Step [3072/10336], Loss: 0.9292\n",
      "Epoch [1/5], Step [3074/10336], Loss: 3.1214\n",
      "Epoch [1/5], Step [3076/10336], Loss: 1.5594\n",
      "Epoch [1/5], Step [3078/10336], Loss: 2.2858\n",
      "Epoch [1/5], Step [3080/10336], Loss: 5.4193\n",
      "Epoch [1/5], Step [3082/10336], Loss: 4.7433\n",
      "Epoch [1/5], Step [3084/10336], Loss: 0.3696\n",
      "Epoch [1/5], Step [3086/10336], Loss: 3.3039\n",
      "Epoch [1/5], Step [3088/10336], Loss: 1.6701\n",
      "Epoch [1/5], Step [3090/10336], Loss: 5.7769\n",
      "Epoch [1/5], Step [3092/10336], Loss: 6.4421\n",
      "Epoch [1/5], Step [3094/10336], Loss: 5.6269\n",
      "Epoch [1/5], Step [3096/10336], Loss: 0.6464\n",
      "Epoch [1/5], Step [3098/10336], Loss: 1.5028\n",
      "Epoch [1/5], Step [3100/10336], Loss: 0.5586\n",
      "Epoch [1/5], Step [3102/10336], Loss: 3.7324\n",
      "Epoch [1/5], Step [3104/10336], Loss: 0.0317\n",
      "Epoch [1/5], Step [3106/10336], Loss: 2.8604\n",
      "Epoch [1/5], Step [3108/10336], Loss: 3.8385\n",
      "Epoch [1/5], Step [3110/10336], Loss: 0.1808\n",
      "Epoch [1/5], Step [3112/10336], Loss: 0.4804\n",
      "Epoch [1/5], Step [3114/10336], Loss: 1.2600\n",
      "Epoch [1/5], Step [3116/10336], Loss: 1.3679\n",
      "Epoch [1/5], Step [3118/10336], Loss: 2.8169\n",
      "Epoch [1/5], Step [3120/10336], Loss: 1.4235\n",
      "Epoch [1/5], Step [3122/10336], Loss: 2.2694\n",
      "Epoch [1/5], Step [3124/10336], Loss: 0.2780\n",
      "Epoch [1/5], Step [3126/10336], Loss: 4.2700\n",
      "Epoch [1/5], Step [3128/10336], Loss: 4.7222\n",
      "Epoch [1/5], Step [3130/10336], Loss: 1.9931\n",
      "Epoch [1/5], Step [3132/10336], Loss: 0.8972\n",
      "Epoch [1/5], Step [3134/10336], Loss: 1.0008\n",
      "Epoch [1/5], Step [3136/10336], Loss: 2.4408\n",
      "Epoch [1/5], Step [3138/10336], Loss: 2.7066\n",
      "Epoch [1/5], Step [3140/10336], Loss: 2.4189\n",
      "Epoch [1/5], Step [3142/10336], Loss: 6.7329\n",
      "Epoch [1/5], Step [3144/10336], Loss: 0.2466\n",
      "Epoch [1/5], Step [3146/10336], Loss: 0.5079\n",
      "Epoch [1/5], Step [3148/10336], Loss: 0.2170\n",
      "Epoch [1/5], Step [3150/10336], Loss: 1.4210\n",
      "Epoch [1/5], Step [3152/10336], Loss: 3.9900\n",
      "Epoch [1/5], Step [3154/10336], Loss: 3.0398\n",
      "Epoch [1/5], Step [3156/10336], Loss: 1.2556\n",
      "Epoch [1/5], Step [3158/10336], Loss: 2.8684\n",
      "Epoch [1/5], Step [3160/10336], Loss: 1.9762\n",
      "Epoch [1/5], Step [3162/10336], Loss: 1.7973\n",
      "Epoch [1/5], Step [3164/10336], Loss: 2.1190\n",
      "Epoch [1/5], Step [3166/10336], Loss: 4.7000\n",
      "Epoch [1/5], Step [3168/10336], Loss: 0.7266\n",
      "Epoch [1/5], Step [3170/10336], Loss: 0.9422\n",
      "Epoch [1/5], Step [3172/10336], Loss: 0.2734\n",
      "Epoch [1/5], Step [3174/10336], Loss: 3.7233\n",
      "Epoch [1/5], Step [3176/10336], Loss: 7.1993\n",
      "Epoch [1/5], Step [3178/10336], Loss: 3.8443\n",
      "Epoch [1/5], Step [3180/10336], Loss: 0.4926\n",
      "Epoch [1/5], Step [3182/10336], Loss: 0.9172\n",
      "Epoch [1/5], Step [3184/10336], Loss: 6.2184\n",
      "Epoch [1/5], Step [3186/10336], Loss: 1.6676\n",
      "Epoch [1/5], Step [3188/10336], Loss: 1.0160\n",
      "Epoch [1/5], Step [3190/10336], Loss: 5.3975\n",
      "Epoch [1/5], Step [3192/10336], Loss: 1.2487\n",
      "Epoch [1/5], Step [3194/10336], Loss: 3.1294\n",
      "Epoch [1/5], Step [3196/10336], Loss: 2.7911\n",
      "Epoch [1/5], Step [3198/10336], Loss: 1.6871\n",
      "Epoch [1/5], Step [3200/10336], Loss: 2.1963\n",
      "Epoch [1/5], Step [3202/10336], Loss: 0.5707\n",
      "Epoch [1/5], Step [3204/10336], Loss: 4.1248\n",
      "Epoch [1/5], Step [3206/10336], Loss: 3.0271\n",
      "Epoch [1/5], Step [3208/10336], Loss: 0.7003\n",
      "Epoch [1/5], Step [3210/10336], Loss: 0.3056\n",
      "Epoch [1/5], Step [3212/10336], Loss: 1.7774\n",
      "Epoch [1/5], Step [3214/10336], Loss: 0.9705\n",
      "Epoch [1/5], Step [3216/10336], Loss: 0.6308\n",
      "Epoch [1/5], Step [3218/10336], Loss: 1.9348\n",
      "Epoch [1/5], Step [3220/10336], Loss: 0.9093\n",
      "Epoch [1/5], Step [3222/10336], Loss: 2.2868\n",
      "Epoch [1/5], Step [3224/10336], Loss: 1.7778\n",
      "Epoch [1/5], Step [3226/10336], Loss: 2.3251\n",
      "Epoch [1/5], Step [3228/10336], Loss: 3.0521\n",
      "Epoch [1/5], Step [3230/10336], Loss: 3.5163\n",
      "Epoch [1/5], Step [3232/10336], Loss: 0.0984\n",
      "Epoch [1/5], Step [3234/10336], Loss: 2.0371\n",
      "Epoch [1/5], Step [3236/10336], Loss: 0.7229\n",
      "Epoch [1/5], Step [3238/10336], Loss: 1.0911\n",
      "Epoch [1/5], Step [3240/10336], Loss: 1.8872\n",
      "Epoch [1/5], Step [3242/10336], Loss: 1.4189\n",
      "Epoch [1/5], Step [3244/10336], Loss: 4.5777\n",
      "Epoch [1/5], Step [3246/10336], Loss: 2.5942\n",
      "Epoch [1/5], Step [3248/10336], Loss: 0.5362\n",
      "Epoch [1/5], Step [3250/10336], Loss: 2.7366\n",
      "Epoch [1/5], Step [3252/10336], Loss: 0.6581\n",
      "Epoch [1/5], Step [3254/10336], Loss: 1.5605\n",
      "Epoch [1/5], Step [3256/10336], Loss: 2.4168\n",
      "Epoch [1/5], Step [3258/10336], Loss: 4.1207\n",
      "Epoch [1/5], Step [3260/10336], Loss: 2.4747\n",
      "Epoch [1/5], Step [3262/10336], Loss: 4.2990\n",
      "Epoch [1/5], Step [3264/10336], Loss: 2.2270\n",
      "Epoch [1/5], Step [3266/10336], Loss: 2.2573\n",
      "Epoch [1/5], Step [3268/10336], Loss: 2.1087\n",
      "Epoch [1/5], Step [3270/10336], Loss: 3.1116\n",
      "Epoch [1/5], Step [3272/10336], Loss: 3.8754\n",
      "Epoch [1/5], Step [3274/10336], Loss: 2.5112\n",
      "Epoch [1/5], Step [3276/10336], Loss: 0.9645\n",
      "Epoch [1/5], Step [3278/10336], Loss: 1.2976\n",
      "Epoch [1/5], Step [3280/10336], Loss: 1.2690\n",
      "Epoch [1/5], Step [3282/10336], Loss: 1.4588\n",
      "Epoch [1/5], Step [3284/10336], Loss: 1.6918\n",
      "Epoch [1/5], Step [3286/10336], Loss: 2.0928\n",
      "Epoch [1/5], Step [3288/10336], Loss: 1.0888\n",
      "Epoch [1/5], Step [3290/10336], Loss: 0.8385\n",
      "Epoch [1/5], Step [3292/10336], Loss: 0.1629\n",
      "Epoch [1/5], Step [3294/10336], Loss: 1.4204\n",
      "Epoch [1/5], Step [3296/10336], Loss: 2.2613\n",
      "Epoch [1/5], Step [3298/10336], Loss: 4.5775\n",
      "Epoch [1/5], Step [3300/10336], Loss: 3.7104\n",
      "Epoch [1/5], Step [3302/10336], Loss: 0.9645\n",
      "Epoch [1/5], Step [3304/10336], Loss: 0.8075\n",
      "Epoch [1/5], Step [3306/10336], Loss: 2.8671\n",
      "Epoch [1/5], Step [3308/10336], Loss: 1.4902\n",
      "Epoch [1/5], Step [3310/10336], Loss: 4.2868\n",
      "Epoch [1/5], Step [3312/10336], Loss: 2.0461\n",
      "Epoch [1/5], Step [3314/10336], Loss: 0.8161\n",
      "Epoch [1/5], Step [3316/10336], Loss: 1.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [3318/10336], Loss: 0.8535\n",
      "Epoch [1/5], Step [3320/10336], Loss: 3.8826\n",
      "Epoch [1/5], Step [3322/10336], Loss: 0.6437\n",
      "Epoch [1/5], Step [3324/10336], Loss: 1.4520\n",
      "Epoch [1/5], Step [3326/10336], Loss: 3.3939\n",
      "Epoch [1/5], Step [3328/10336], Loss: 0.4063\n",
      "Epoch [1/5], Step [3330/10336], Loss: 0.4223\n",
      "Epoch [1/5], Step [3332/10336], Loss: 2.4365\n",
      "Epoch [1/5], Step [3334/10336], Loss: 6.4639\n",
      "Epoch [1/5], Step [3336/10336], Loss: 1.6450\n",
      "Epoch [1/5], Step [3338/10336], Loss: 0.4076\n",
      "Epoch [1/5], Step [3340/10336], Loss: 2.1326\n",
      "Epoch [1/5], Step [3342/10336], Loss: 0.6504\n",
      "Epoch [1/5], Step [3344/10336], Loss: 1.4700\n",
      "Epoch [1/5], Step [3346/10336], Loss: 1.8374\n",
      "Epoch [1/5], Step [3348/10336], Loss: 0.7315\n",
      "Epoch [1/5], Step [3350/10336], Loss: 0.5170\n",
      "Epoch [1/5], Step [3352/10336], Loss: 1.6257\n",
      "Epoch [1/5], Step [3354/10336], Loss: 2.1153\n",
      "Epoch [1/5], Step [3356/10336], Loss: 2.3656\n",
      "Epoch [1/5], Step [3358/10336], Loss: 1.8682\n",
      "Epoch [1/5], Step [3360/10336], Loss: 0.9103\n",
      "Epoch [1/5], Step [3362/10336], Loss: 1.5654\n",
      "Epoch [1/5], Step [3364/10336], Loss: 4.3956\n",
      "Epoch [1/5], Step [3366/10336], Loss: 0.5741\n",
      "Epoch [1/5], Step [3368/10336], Loss: 1.7352\n",
      "Epoch [1/5], Step [3370/10336], Loss: 1.9185\n",
      "Epoch [1/5], Step [3372/10336], Loss: 0.4046\n",
      "Epoch [1/5], Step [3374/10336], Loss: 0.2808\n",
      "Epoch [1/5], Step [3376/10336], Loss: 1.5965\n",
      "Epoch [1/5], Step [3378/10336], Loss: 1.7891\n",
      "Epoch [1/5], Step [3380/10336], Loss: 1.3753\n",
      "Epoch [1/5], Step [3382/10336], Loss: 2.8059\n",
      "Epoch [1/5], Step [3384/10336], Loss: 0.0889\n",
      "Epoch [1/5], Step [3386/10336], Loss: 0.2798\n",
      "Epoch [1/5], Step [3388/10336], Loss: 1.5940\n",
      "Epoch [1/5], Step [3390/10336], Loss: 0.7651\n",
      "Epoch [1/5], Step [3392/10336], Loss: 0.4762\n",
      "Epoch [1/5], Step [3394/10336], Loss: 0.4684\n",
      "Epoch [1/5], Step [3396/10336], Loss: 0.0489\n",
      "Epoch [1/5], Step [3398/10336], Loss: 0.8419\n",
      "Epoch [1/5], Step [3400/10336], Loss: 2.1875\n",
      "Epoch [1/5], Step [3402/10336], Loss: 0.7692\n",
      "Epoch [1/5], Step [3404/10336], Loss: 4.6958\n",
      "Epoch [1/5], Step [3406/10336], Loss: 2.1035\n",
      "Epoch [1/5], Step [3408/10336], Loss: 2.5031\n",
      "Epoch [1/5], Step [3410/10336], Loss: 1.3871\n",
      "Epoch [1/5], Step [3412/10336], Loss: 1.4867\n",
      "Epoch [1/5], Step [3414/10336], Loss: 0.6803\n",
      "Epoch [1/5], Step [3416/10336], Loss: 2.2800\n",
      "Epoch [1/5], Step [3418/10336], Loss: 1.9367\n",
      "Epoch [1/5], Step [3420/10336], Loss: 1.2064\n",
      "Epoch [1/5], Step [3422/10336], Loss: 0.3684\n",
      "Epoch [1/5], Step [3424/10336], Loss: 1.5309\n",
      "Epoch [1/5], Step [3426/10336], Loss: 2.6326\n",
      "Epoch [1/5], Step [3428/10336], Loss: 1.6441\n",
      "Epoch [1/5], Step [3430/10336], Loss: 1.1027\n",
      "Epoch [1/5], Step [3432/10336], Loss: 4.7874\n",
      "Epoch [1/5], Step [3434/10336], Loss: 2.3317\n",
      "Epoch [1/5], Step [3436/10336], Loss: 2.8619\n",
      "Epoch [1/5], Step [3438/10336], Loss: 2.4377\n",
      "Epoch [1/5], Step [3440/10336], Loss: 2.1161\n",
      "Epoch [1/5], Step [3442/10336], Loss: 0.6504\n",
      "Epoch [1/5], Step [3444/10336], Loss: 3.6968\n",
      "Epoch [1/5], Step [3446/10336], Loss: 1.4480\n",
      "Epoch [1/5], Step [3448/10336], Loss: 1.0158\n",
      "Epoch [1/5], Step [3450/10336], Loss: 2.8017\n",
      "Epoch [1/5], Step [3452/10336], Loss: 2.1642\n",
      "Epoch [1/5], Step [3454/10336], Loss: 4.3746\n",
      "Epoch [1/5], Step [3456/10336], Loss: 3.9581\n",
      "Epoch [1/5], Step [3458/10336], Loss: 0.2504\n",
      "Epoch [1/5], Step [3460/10336], Loss: 3.3592\n",
      "Epoch [1/5], Step [3462/10336], Loss: 2.0304\n",
      "Epoch [1/5], Step [3464/10336], Loss: 2.4736\n",
      "Epoch [1/5], Step [3466/10336], Loss: 5.2048\n",
      "Epoch [1/5], Step [3468/10336], Loss: 0.3338\n",
      "Epoch [1/5], Step [3470/10336], Loss: 0.3548\n",
      "Epoch [1/5], Step [3472/10336], Loss: 1.4109\n",
      "Epoch [1/5], Step [3474/10336], Loss: 0.4077\n",
      "Epoch [1/5], Step [3476/10336], Loss: 2.0937\n",
      "Epoch [1/5], Step [3478/10336], Loss: 4.7333\n",
      "Epoch [1/5], Step [3480/10336], Loss: 1.7778\n",
      "Epoch [1/5], Step [3482/10336], Loss: 3.4140\n",
      "Epoch [1/5], Step [3484/10336], Loss: 0.0140\n",
      "Epoch [1/5], Step [3486/10336], Loss: 2.6697\n",
      "Epoch [1/5], Step [3488/10336], Loss: 1.5819\n",
      "Epoch [1/5], Step [3490/10336], Loss: 0.4802\n",
      "Epoch [1/5], Step [3492/10336], Loss: 2.4494\n",
      "Epoch [1/5], Step [3494/10336], Loss: 3.6091\n",
      "Epoch [1/5], Step [3496/10336], Loss: 0.7486\n",
      "Epoch [1/5], Step [3498/10336], Loss: 1.3416\n",
      "Epoch [1/5], Step [3500/10336], Loss: 1.4330\n",
      "Epoch [1/5], Step [3502/10336], Loss: 0.2533\n",
      "Epoch [1/5], Step [3504/10336], Loss: 0.8675\n",
      "Epoch [1/5], Step [3506/10336], Loss: 2.4117\n",
      "Epoch [1/5], Step [3508/10336], Loss: 0.4540\n",
      "Epoch [1/5], Step [3510/10336], Loss: 2.4510\n",
      "Epoch [1/5], Step [3512/10336], Loss: 2.5870\n",
      "Epoch [1/5], Step [3514/10336], Loss: 1.2865\n",
      "Epoch [1/5], Step [3516/10336], Loss: 2.2167\n",
      "Epoch [1/5], Step [3518/10336], Loss: 0.5810\n",
      "Epoch [1/5], Step [3520/10336], Loss: 2.6461\n",
      "Epoch [1/5], Step [3522/10336], Loss: 3.8646\n",
      "Epoch [1/5], Step [3524/10336], Loss: 0.3369\n",
      "Epoch [1/5], Step [3526/10336], Loss: 1.0186\n",
      "Epoch [1/5], Step [3528/10336], Loss: 0.2767\n",
      "Epoch [1/5], Step [3530/10336], Loss: 2.5488\n",
      "Epoch [1/5], Step [3532/10336], Loss: 0.1797\n",
      "Epoch [1/5], Step [3534/10336], Loss: 1.7954\n",
      "Epoch [1/5], Step [3536/10336], Loss: 3.3705\n",
      "Epoch [1/5], Step [3538/10336], Loss: 2.7527\n",
      "Epoch [1/5], Step [3540/10336], Loss: 4.6468\n",
      "Epoch [1/5], Step [3542/10336], Loss: 2.1608\n",
      "Epoch [1/5], Step [3544/10336], Loss: 0.9755\n",
      "Epoch [1/5], Step [3546/10336], Loss: 1.7069\n",
      "Epoch [1/5], Step [3548/10336], Loss: 1.9771\n",
      "Epoch [1/5], Step [3550/10336], Loss: 0.2507\n",
      "Epoch [1/5], Step [3552/10336], Loss: 1.6730\n",
      "Epoch [1/5], Step [3554/10336], Loss: 1.4319\n",
      "Epoch [1/5], Step [3556/10336], Loss: 1.7108\n",
      "Epoch [1/5], Step [3558/10336], Loss: 3.1601\n",
      "Epoch [1/5], Step [3560/10336], Loss: 2.2104\n",
      "Epoch [1/5], Step [3562/10336], Loss: 3.8670\n",
      "Epoch [1/5], Step [3564/10336], Loss: 0.4275\n",
      "Epoch [1/5], Step [3566/10336], Loss: 3.3065\n",
      "Epoch [1/5], Step [3568/10336], Loss: 1.9984\n",
      "Epoch [1/5], Step [3570/10336], Loss: 0.4219\n",
      "Epoch [1/5], Step [3572/10336], Loss: 2.2979\n",
      "Epoch [1/5], Step [3574/10336], Loss: 1.0830\n",
      "Epoch [1/5], Step [3576/10336], Loss: 1.3508\n",
      "Epoch [1/5], Step [3578/10336], Loss: 3.4359\n",
      "Epoch [1/5], Step [3580/10336], Loss: 1.9463\n",
      "Epoch [1/5], Step [3582/10336], Loss: 1.7969\n",
      "Epoch [1/5], Step [3584/10336], Loss: 2.9133\n",
      "Epoch [1/5], Step [3586/10336], Loss: 3.1253\n",
      "Epoch [1/5], Step [3588/10336], Loss: 3.1435\n",
      "Epoch [1/5], Step [3590/10336], Loss: 0.9071\n",
      "Epoch [1/5], Step [3592/10336], Loss: 1.8822\n",
      "Epoch [1/5], Step [3594/10336], Loss: 0.1563\n",
      "Epoch [1/5], Step [3596/10336], Loss: 0.7434\n",
      "Epoch [1/5], Step [3598/10336], Loss: 1.3154\n",
      "Epoch [1/5], Step [3600/10336], Loss: 1.1625\n",
      "Epoch [1/5], Step [3602/10336], Loss: 1.1938\n",
      "Epoch [1/5], Step [3604/10336], Loss: 0.4669\n",
      "Epoch [1/5], Step [3606/10336], Loss: 1.5346\n",
      "Epoch [1/5], Step [3608/10336], Loss: 0.0429\n",
      "Epoch [1/5], Step [3610/10336], Loss: 3.3231\n",
      "Epoch [1/5], Step [3612/10336], Loss: 0.2899\n",
      "Epoch [1/5], Step [3614/10336], Loss: 3.0304\n",
      "Epoch [1/5], Step [3616/10336], Loss: 0.3642\n",
      "Epoch [1/5], Step [3618/10336], Loss: 1.6845\n",
      "Epoch [1/5], Step [3620/10336], Loss: 2.4105\n",
      "Epoch [1/5], Step [3622/10336], Loss: 1.0625\n",
      "Epoch [1/5], Step [3624/10336], Loss: 2.7417\n",
      "Epoch [1/5], Step [3626/10336], Loss: 0.9046\n",
      "Epoch [1/5], Step [3628/10336], Loss: 1.7390\n",
      "Epoch [1/5], Step [3630/10336], Loss: 1.7493\n",
      "Epoch [1/5], Step [3632/10336], Loss: 3.5980\n",
      "Epoch [1/5], Step [3634/10336], Loss: 0.5376\n",
      "Epoch [1/5], Step [3636/10336], Loss: 2.6031\n",
      "Epoch [1/5], Step [3638/10336], Loss: 2.6612\n",
      "Epoch [1/5], Step [3640/10336], Loss: 2.0633\n",
      "Epoch [1/5], Step [3642/10336], Loss: 1.5403\n",
      "Epoch [1/5], Step [3644/10336], Loss: 1.5417\n",
      "Epoch [1/5], Step [3646/10336], Loss: 0.1368\n",
      "Epoch [1/5], Step [3648/10336], Loss: 1.9694\n",
      "Epoch [1/5], Step [3650/10336], Loss: 2.8209\n",
      "Epoch [1/5], Step [3652/10336], Loss: 0.2139\n",
      "Epoch [1/5], Step [3654/10336], Loss: 4.9922\n",
      "Epoch [1/5], Step [3656/10336], Loss: 0.6769\n",
      "Epoch [1/5], Step [3658/10336], Loss: 0.6452\n",
      "Epoch [1/5], Step [3660/10336], Loss: 2.4095\n",
      "Epoch [1/5], Step [3662/10336], Loss: 2.3396\n",
      "Epoch [1/5], Step [3664/10336], Loss: 1.3660\n",
      "Epoch [1/5], Step [3666/10336], Loss: 1.9936\n",
      "Epoch [1/5], Step [3668/10336], Loss: 0.4685\n",
      "Epoch [1/5], Step [3670/10336], Loss: 1.9551\n",
      "Epoch [1/5], Step [3672/10336], Loss: 1.4815\n",
      "Epoch [1/5], Step [3674/10336], Loss: 0.8320\n",
      "Epoch [1/5], Step [3676/10336], Loss: 2.9265\n",
      "Epoch [1/5], Step [3678/10336], Loss: 1.8573\n",
      "Epoch [1/5], Step [3680/10336], Loss: 2.6348\n",
      "Epoch [1/5], Step [3682/10336], Loss: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [3684/10336], Loss: 3.1734\n",
      "Epoch [1/5], Step [3686/10336], Loss: 1.5576\n",
      "Epoch [1/5], Step [3688/10336], Loss: 1.7151\n",
      "Epoch [1/5], Step [3690/10336], Loss: 2.2463\n",
      "Epoch [1/5], Step [3692/10336], Loss: 3.7830\n",
      "Epoch [1/5], Step [3694/10336], Loss: 2.1940\n",
      "Epoch [1/5], Step [3696/10336], Loss: 1.8296\n",
      "Epoch [1/5], Step [3698/10336], Loss: 2.7311\n",
      "Epoch [1/5], Step [3700/10336], Loss: 1.3752\n",
      "Epoch [1/5], Step [3702/10336], Loss: 3.0272\n",
      "Epoch [1/5], Step [3704/10336], Loss: 1.7613\n",
      "Epoch [1/5], Step [3706/10336], Loss: 0.5125\n",
      "Epoch [1/5], Step [3708/10336], Loss: 0.9084\n",
      "Epoch [1/5], Step [3710/10336], Loss: 1.9691\n",
      "Epoch [1/5], Step [3712/10336], Loss: 1.1990\n",
      "Epoch [1/5], Step [3714/10336], Loss: 0.3424\n",
      "Epoch [1/5], Step [3716/10336], Loss: 1.1254\n",
      "Epoch [1/5], Step [3718/10336], Loss: 0.2961\n",
      "Epoch [1/5], Step [3720/10336], Loss: 4.9947\n",
      "Epoch [1/5], Step [3722/10336], Loss: 3.6740\n",
      "Epoch [1/5], Step [3724/10336], Loss: 0.9192\n",
      "Epoch [1/5], Step [3726/10336], Loss: 1.6490\n",
      "Epoch [1/5], Step [3728/10336], Loss: 0.6494\n",
      "Epoch [1/5], Step [3730/10336], Loss: 0.2159\n",
      "Epoch [1/5], Step [3732/10336], Loss: 0.9102\n",
      "Epoch [1/5], Step [3734/10336], Loss: 1.3836\n",
      "Epoch [1/5], Step [3736/10336], Loss: 0.7754\n",
      "Epoch [1/5], Step [3738/10336], Loss: 1.0692\n",
      "Epoch [1/5], Step [3740/10336], Loss: 2.5416\n",
      "Epoch [1/5], Step [3742/10336], Loss: 2.7970\n",
      "Epoch [1/5], Step [3744/10336], Loss: 3.5375\n",
      "Epoch [1/5], Step [3746/10336], Loss: 1.9113\n",
      "Epoch [1/5], Step [3748/10336], Loss: 1.7996\n",
      "Epoch [1/5], Step [3750/10336], Loss: 1.6320\n",
      "Epoch [1/5], Step [3752/10336], Loss: 1.3907\n",
      "Epoch [1/5], Step [3754/10336], Loss: 1.1612\n",
      "Epoch [1/5], Step [3756/10336], Loss: 1.0046\n",
      "Epoch [1/5], Step [3758/10336], Loss: 1.9238\n",
      "Epoch [1/5], Step [3760/10336], Loss: 2.3994\n",
      "Epoch [1/5], Step [3762/10336], Loss: 1.4501\n",
      "Epoch [1/5], Step [3764/10336], Loss: 2.5852\n",
      "Epoch [1/5], Step [3766/10336], Loss: 3.1644\n",
      "Epoch [1/5], Step [3768/10336], Loss: 2.4703\n",
      "Epoch [1/5], Step [3770/10336], Loss: 1.4999\n",
      "Epoch [1/5], Step [3772/10336], Loss: 2.8093\n",
      "Epoch [1/5], Step [3774/10336], Loss: 0.8513\n",
      "Epoch [1/5], Step [3776/10336], Loss: 1.4399\n",
      "Epoch [1/5], Step [3778/10336], Loss: 0.2225\n",
      "Epoch [1/5], Step [3780/10336], Loss: 0.0981\n",
      "Epoch [1/5], Step [3782/10336], Loss: 2.0204\n",
      "Epoch [1/5], Step [3784/10336], Loss: 0.2372\n",
      "Epoch [1/5], Step [3786/10336], Loss: 0.0214\n",
      "Epoch [1/5], Step [3788/10336], Loss: 0.9112\n",
      "Epoch [1/5], Step [3790/10336], Loss: 0.0282\n",
      "Epoch [1/5], Step [3792/10336], Loss: 7.1504\n",
      "Epoch [1/5], Step [3794/10336], Loss: 4.8003\n",
      "Epoch [1/5], Step [3796/10336], Loss: 0.2993\n",
      "Epoch [1/5], Step [3798/10336], Loss: 2.5785\n",
      "Epoch [1/5], Step [3800/10336], Loss: 1.3989\n",
      "Epoch [1/5], Step [3802/10336], Loss: 0.9110\n",
      "Epoch [1/5], Step [3804/10336], Loss: 2.6316\n",
      "Epoch [1/5], Step [3806/10336], Loss: 1.8289\n",
      "Epoch [1/5], Step [3808/10336], Loss: 6.9732\n",
      "Epoch [1/5], Step [3810/10336], Loss: 3.5280\n",
      "Epoch [1/5], Step [3812/10336], Loss: 0.3657\n",
      "Epoch [1/5], Step [3814/10336], Loss: 2.0616\n",
      "Epoch [1/5], Step [3816/10336], Loss: 1.0965\n",
      "Epoch [1/5], Step [3818/10336], Loss: 3.6027\n",
      "Epoch [1/5], Step [3820/10336], Loss: 2.7975\n",
      "Epoch [1/5], Step [3822/10336], Loss: 0.3585\n",
      "Epoch [1/5], Step [3824/10336], Loss: 1.4254\n",
      "Epoch [1/5], Step [3826/10336], Loss: 0.9342\n",
      "Epoch [1/5], Step [3828/10336], Loss: 0.1879\n",
      "Epoch [1/5], Step [3830/10336], Loss: 1.3725\n",
      "Epoch [1/5], Step [3832/10336], Loss: 1.8181\n",
      "Epoch [1/5], Step [3834/10336], Loss: 3.1219\n",
      "Epoch [1/5], Step [3836/10336], Loss: 0.3520\n",
      "Epoch [1/5], Step [3838/10336], Loss: 0.8429\n",
      "Epoch [1/5], Step [3840/10336], Loss: 0.8470\n",
      "Epoch [1/5], Step [3842/10336], Loss: 1.0851\n",
      "Epoch [1/5], Step [3844/10336], Loss: 0.7422\n",
      "Epoch [1/5], Step [3846/10336], Loss: 4.2728\n",
      "Epoch [1/5], Step [3848/10336], Loss: 0.7009\n",
      "Epoch [1/5], Step [3850/10336], Loss: 3.8396\n",
      "Epoch [1/5], Step [3852/10336], Loss: 1.9351\n",
      "Epoch [1/5], Step [3854/10336], Loss: 1.0450\n",
      "Epoch [1/5], Step [3856/10336], Loss: 1.3801\n",
      "Epoch [1/5], Step [3858/10336], Loss: 3.1912\n",
      "Epoch [1/5], Step [3860/10336], Loss: 1.3785\n",
      "Epoch [1/5], Step [3862/10336], Loss: 0.1428\n",
      "Epoch [1/5], Step [3864/10336], Loss: 1.6914\n",
      "Epoch [1/5], Step [3866/10336], Loss: 0.8865\n",
      "Epoch [1/5], Step [3868/10336], Loss: 1.3956\n",
      "Epoch [1/5], Step [3870/10336], Loss: 2.7912\n",
      "Epoch [1/5], Step [3872/10336], Loss: 1.7084\n",
      "Epoch [1/5], Step [3874/10336], Loss: 0.7236\n",
      "Epoch [1/5], Step [3876/10336], Loss: 0.4630\n",
      "Epoch [1/5], Step [3878/10336], Loss: 0.4598\n",
      "Epoch [1/5], Step [3880/10336], Loss: 2.8666\n",
      "Epoch [1/5], Step [3882/10336], Loss: 0.2158\n",
      "Epoch [1/5], Step [3884/10336], Loss: 2.3226\n",
      "Epoch [1/5], Step [3886/10336], Loss: 1.2460\n",
      "Epoch [1/5], Step [3888/10336], Loss: 2.0136\n",
      "Epoch [1/5], Step [3890/10336], Loss: 1.7419\n",
      "Epoch [1/5], Step [3892/10336], Loss: 2.5534\n",
      "Epoch [1/5], Step [3894/10336], Loss: 0.6072\n",
      "Epoch [1/5], Step [3896/10336], Loss: 1.5647\n",
      "Epoch [1/5], Step [3898/10336], Loss: 1.7216\n",
      "Epoch [1/5], Step [3900/10336], Loss: 3.7568\n",
      "Epoch [1/5], Step [3902/10336], Loss: 0.5953\n",
      "Epoch [1/5], Step [3904/10336], Loss: 1.3677\n",
      "Epoch [1/5], Step [3906/10336], Loss: 1.1902\n",
      "Epoch [1/5], Step [3908/10336], Loss: 0.7991\n",
      "Epoch [1/5], Step [3910/10336], Loss: 1.2669\n",
      "Epoch [1/5], Step [3912/10336], Loss: 0.4169\n",
      "Epoch [1/5], Step [3914/10336], Loss: 1.9780\n",
      "Epoch [1/5], Step [3916/10336], Loss: 2.1481\n",
      "Epoch [1/5], Step [3918/10336], Loss: 0.9086\n",
      "Epoch [1/5], Step [3920/10336], Loss: 0.1925\n",
      "Epoch [1/5], Step [3922/10336], Loss: 0.5735\n",
      "Epoch [1/5], Step [3924/10336], Loss: 0.0975\n",
      "Epoch [1/5], Step [3926/10336], Loss: 0.9989\n",
      "Epoch [1/5], Step [3928/10336], Loss: 2.2322\n",
      "Epoch [1/5], Step [3930/10336], Loss: 2.8629\n",
      "Epoch [1/5], Step [3932/10336], Loss: 4.2608\n",
      "Epoch [1/5], Step [3934/10336], Loss: 3.1935\n",
      "Epoch [1/5], Step [3936/10336], Loss: 0.1184\n",
      "Epoch [1/5], Step [3938/10336], Loss: 2.0297\n",
      "Epoch [1/5], Step [3940/10336], Loss: 4.8573\n",
      "Epoch [1/5], Step [3942/10336], Loss: 0.4595\n",
      "Epoch [1/5], Step [3944/10336], Loss: 0.8470\n",
      "Epoch [1/5], Step [3946/10336], Loss: 3.4533\n",
      "Epoch [1/5], Step [3948/10336], Loss: 1.6720\n",
      "Epoch [1/5], Step [3950/10336], Loss: 0.4118\n",
      "Epoch [1/5], Step [3952/10336], Loss: 3.0941\n",
      "Epoch [1/5], Step [3954/10336], Loss: 1.0704\n",
      "Epoch [1/5], Step [3956/10336], Loss: 0.0502\n",
      "Epoch [1/5], Step [3958/10336], Loss: 1.1567\n",
      "Epoch [1/5], Step [3960/10336], Loss: 3.7831\n",
      "Epoch [1/5], Step [3962/10336], Loss: 3.4655\n",
      "Epoch [1/5], Step [3964/10336], Loss: 0.8267\n",
      "Epoch [1/5], Step [3966/10336], Loss: 1.1349\n",
      "Epoch [1/5], Step [3968/10336], Loss: 0.9384\n",
      "Epoch [1/5], Step [3970/10336], Loss: 0.3059\n",
      "Epoch [1/5], Step [3972/10336], Loss: 2.8908\n",
      "Epoch [1/5], Step [3974/10336], Loss: 1.8106\n",
      "Epoch [1/5], Step [3976/10336], Loss: 3.0220\n",
      "Epoch [1/5], Step [3978/10336], Loss: 1.2795\n",
      "Epoch [1/5], Step [3980/10336], Loss: 4.0144\n",
      "Epoch [1/5], Step [3982/10336], Loss: 2.4746\n",
      "Epoch [1/5], Step [3984/10336], Loss: 3.0253\n",
      "Epoch [1/5], Step [3986/10336], Loss: 2.3862\n",
      "Epoch [1/5], Step [3988/10336], Loss: 2.1554\n",
      "Epoch [1/5], Step [3990/10336], Loss: 1.1736\n",
      "Epoch [1/5], Step [3992/10336], Loss: 1.2841\n",
      "Epoch [1/5], Step [3994/10336], Loss: 1.1189\n",
      "Epoch [1/5], Step [3996/10336], Loss: 0.8317\n",
      "Epoch [1/5], Step [3998/10336], Loss: 1.9141\n",
      "Epoch [1/5], Step [4000/10336], Loss: 2.4047\n",
      "Epoch [1/5], Step [4002/10336], Loss: 1.5557\n",
      "Epoch [1/5], Step [4004/10336], Loss: 0.3722\n",
      "Epoch [1/5], Step [4006/10336], Loss: 0.4747\n",
      "Epoch [1/5], Step [4008/10336], Loss: 1.1085\n",
      "Epoch [1/5], Step [4010/10336], Loss: 1.3474\n",
      "Epoch [1/5], Step [4012/10336], Loss: 0.1393\n",
      "Epoch [1/5], Step [4014/10336], Loss: 1.8526\n",
      "Epoch [1/5], Step [4016/10336], Loss: 0.4026\n",
      "Epoch [1/5], Step [4018/10336], Loss: 3.0454\n",
      "Epoch [1/5], Step [4020/10336], Loss: 0.7224\n",
      "Epoch [1/5], Step [4022/10336], Loss: 1.8624\n",
      "Epoch [1/5], Step [4024/10336], Loss: 0.8298\n",
      "Epoch [1/5], Step [4026/10336], Loss: 2.1106\n",
      "Epoch [1/5], Step [4028/10336], Loss: 0.5855\n",
      "Epoch [1/5], Step [4030/10336], Loss: 0.4219\n",
      "Epoch [1/5], Step [4032/10336], Loss: 3.7486\n",
      "Epoch [1/5], Step [4034/10336], Loss: 2.4023\n",
      "Epoch [1/5], Step [4036/10336], Loss: 0.3263\n",
      "Epoch [1/5], Step [4038/10336], Loss: 4.0727\n",
      "Epoch [1/5], Step [4040/10336], Loss: 2.2556\n",
      "Epoch [1/5], Step [4042/10336], Loss: 0.0925\n",
      "Epoch [1/5], Step [4044/10336], Loss: 0.5273\n",
      "Epoch [1/5], Step [4046/10336], Loss: 1.3266\n",
      "Epoch [1/5], Step [4048/10336], Loss: 2.2774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [4050/10336], Loss: 1.3782\n",
      "Epoch [1/5], Step [4052/10336], Loss: 0.9502\n",
      "Epoch [1/5], Step [4054/10336], Loss: 1.3135\n",
      "Epoch [1/5], Step [4056/10336], Loss: 1.1169\n",
      "Epoch [1/5], Step [4058/10336], Loss: 0.8978\n",
      "Epoch [1/5], Step [4060/10336], Loss: 1.9317\n",
      "Epoch [1/5], Step [4062/10336], Loss: 0.0682\n",
      "Epoch [1/5], Step [4064/10336], Loss: 0.6641\n",
      "Epoch [1/5], Step [4066/10336], Loss: 0.2973\n",
      "Epoch [1/5], Step [4068/10336], Loss: 0.5948\n",
      "Epoch [1/5], Step [4070/10336], Loss: 0.2732\n",
      "Epoch [1/5], Step [4072/10336], Loss: 1.9982\n",
      "Epoch [1/5], Step [4074/10336], Loss: 2.4418\n",
      "Epoch [1/5], Step [4076/10336], Loss: 3.1141\n",
      "Epoch [1/5], Step [4078/10336], Loss: 1.2858\n",
      "Epoch [1/5], Step [4080/10336], Loss: 0.3725\n",
      "Epoch [1/5], Step [4082/10336], Loss: 0.6011\n",
      "Epoch [1/5], Step [4084/10336], Loss: 4.2858\n",
      "Epoch [1/5], Step [4086/10336], Loss: 4.7459\n",
      "Epoch [1/5], Step [4088/10336], Loss: 0.0750\n",
      "Epoch [1/5], Step [4090/10336], Loss: 2.1931\n",
      "Epoch [1/5], Step [4092/10336], Loss: 1.0740\n",
      "Epoch [1/5], Step [4094/10336], Loss: 2.3833\n",
      "Epoch [1/5], Step [4096/10336], Loss: 1.4616\n",
      "Epoch [1/5], Step [4098/10336], Loss: 3.1906\n",
      "Epoch [1/5], Step [4100/10336], Loss: 0.3384\n",
      "Epoch [1/5], Step [4102/10336], Loss: 3.4437\n",
      "Epoch [1/5], Step [4104/10336], Loss: 2.7846\n",
      "Epoch [1/5], Step [4106/10336], Loss: 1.3507\n",
      "Epoch [1/5], Step [4108/10336], Loss: 1.5918\n",
      "Epoch [1/5], Step [4110/10336], Loss: 0.8893\n",
      "Epoch [1/5], Step [4112/10336], Loss: 1.0755\n",
      "Epoch [1/5], Step [4114/10336], Loss: 3.2063\n",
      "Epoch [1/5], Step [4116/10336], Loss: 2.8358\n",
      "Epoch [1/5], Step [4118/10336], Loss: 1.1128\n",
      "Epoch [1/5], Step [4120/10336], Loss: 0.8218\n",
      "Epoch [1/5], Step [4122/10336], Loss: 3.4830\n",
      "Epoch [1/5], Step [4124/10336], Loss: 4.4856\n",
      "Epoch [1/5], Step [4126/10336], Loss: 2.6456\n",
      "Epoch [1/5], Step [4128/10336], Loss: 1.9598\n",
      "Epoch [1/5], Step [4130/10336], Loss: 2.5921\n",
      "Epoch [1/5], Step [4132/10336], Loss: 2.5298\n",
      "Epoch [1/5], Step [4134/10336], Loss: 0.8093\n",
      "Epoch [1/5], Step [4136/10336], Loss: 0.3244\n",
      "Epoch [1/5], Step [4138/10336], Loss: 0.4666\n",
      "Epoch [1/5], Step [4140/10336], Loss: 1.7091\n",
      "Epoch [1/5], Step [4142/10336], Loss: 0.7389\n",
      "Epoch [1/5], Step [4144/10336], Loss: 1.1089\n",
      "Epoch [1/5], Step [4146/10336], Loss: 1.0873\n",
      "Epoch [1/5], Step [4148/10336], Loss: 2.4343\n",
      "Epoch [1/5], Step [4150/10336], Loss: 1.2636\n",
      "Epoch [1/5], Step [4152/10336], Loss: 0.1138\n",
      "Epoch [1/5], Step [4154/10336], Loss: 0.9320\n",
      "Epoch [1/5], Step [4156/10336], Loss: 1.0497\n",
      "Epoch [1/5], Step [4158/10336], Loss: 0.5871\n",
      "Epoch [1/5], Step [4160/10336], Loss: 2.0536\n",
      "Epoch [1/5], Step [4162/10336], Loss: 2.1640\n",
      "Epoch [1/5], Step [4164/10336], Loss: 1.0077\n",
      "Epoch [1/5], Step [4166/10336], Loss: 0.4658\n",
      "Epoch [1/5], Step [4168/10336], Loss: 3.0219\n",
      "Epoch [1/5], Step [4170/10336], Loss: 2.4205\n",
      "Epoch [1/5], Step [4172/10336], Loss: 0.2201\n",
      "Epoch [1/5], Step [4174/10336], Loss: 3.9801\n",
      "Epoch [1/5], Step [4176/10336], Loss: 5.9151\n",
      "Epoch [1/5], Step [4178/10336], Loss: 1.4321\n",
      "Epoch [1/5], Step [4180/10336], Loss: 0.3878\n",
      "Epoch [1/5], Step [4182/10336], Loss: 1.2127\n",
      "Epoch [1/5], Step [4184/10336], Loss: 0.6420\n",
      "Epoch [1/5], Step [4186/10336], Loss: 2.6434\n",
      "Epoch [1/5], Step [4188/10336], Loss: 1.4277\n",
      "Epoch [1/5], Step [4190/10336], Loss: 0.4193\n",
      "Epoch [1/5], Step [4192/10336], Loss: 2.1026\n",
      "Epoch [1/5], Step [4194/10336], Loss: 2.9425\n",
      "Epoch [1/5], Step [4196/10336], Loss: 0.7998\n",
      "Epoch [1/5], Step [4198/10336], Loss: 0.8430\n",
      "Epoch [1/5], Step [4200/10336], Loss: 1.6573\n",
      "Epoch [1/5], Step [4202/10336], Loss: 2.7870\n"
     ]
    }
   ],
   "source": [
    "%time arya_train()\n",
    "torch.save(resnet18.state_dict(), 'resnet18.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Accuracy Calculation\n",
    "Jorah then asks a question, how is this a detection task?<br/>\n",
    "As everybody wonders, Theon Greyjoy suggests a slding window method to test the above trained trained network on the detection task:<br/>\n",
    "\"We take some windows of varying size and aspect ratios\", he mumbled, \"and slide it through the test image (considering some stride of pixels) from left to right, and top to bottom, detect the class scores for each of the window, and keep only those which are above a certain threshold value!\". \"He is right\", says Samwell, \"I read a similar approach in the paper -Faster RCNN by Ross Girshick in the library, where he uses three diferent scales/sizes and three different aspect ratios, making a total of nine windows per pixel to slide\". You need to write the code and use it in testing code to find the predicted boxes and their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def theon_sliding_window(image,aspect_ratio,size,slide_amount):\n",
    "    # Begin\n",
    "    windows = []\n",
    "    for x in xrange(0,image.size(0),slide_amount):\n",
    "        for y in xrange(0,image.size(1),slide_amount):\n",
    "            box = [x,y,x+size*aspect_ratio,y+size]\n",
    "            crop_img = image.crop(box).convert('RGB')\n",
    "            output = resnet18(composed_transform(crop_img))\n",
    "#             if(output.data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wait\", says <b>Jon Snow</b>, \"The predicted boxes may be too many and we can't deal with all of them. So, I myself will go and apply non_maximum_supression to reduce the number of boxes\". You are free to choose the threshold value for non maximum supression, but choose wisely [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aegon_targaryen_non_maximum_supression(boxes,threshold = 0.3):\n",
    "    # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daenerys, the queen, then orders her army to test out the trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daenerys_test(resnet18):\n",
    "    # Write loops for testing the model on the test set\n",
    "    # Also print out the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time daenerys_test(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Showdown\n",
    "After covering all the steps and passing the accuracy value to the talking crystal, they all pass through to the land of the living, with a wounded Jon Snow armed with the Dragon-axe. After a fierce battle, Jon Snow manages to go face to face with the Night king. Surrounded by battling men and falling bodies, they engage in a ferocious battle, a battle of spear and axe. After a raging fight, Jon manages to sink the axe into the Night king's heart, but not before he gets wounded by the spear. As dead men fall to bones, Daenerys and others rush to his aid, but it is too late. Everyone is in tears as they look towards the man of honour, Jon Snow, lying in Daenerys's arms when he says his last words: \"The night has ended. Winter is finally over!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The night has ended. Winter is finally over!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
