{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Datasets and Finetuning Pre-trained Networks\n",
    "In this notebook you have to create custom datasets for PyTorch and use this dataset to finetune certain pre-trained neural networks and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "#\n",
    "# Several of the imports you will need have been added but you will need to provide the\n",
    "# rest yourself; you should be able to figure out most of the imports as you go through\n",
    "# the notebook since without proper imports your code will fail to run\n",
    "#\n",
    "# All import statements go in this block\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All hyper parameters go in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_epochs = 5\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom Datasets\n",
    "Your first task is to create a pipeline for the custom dataset so that you can load it using a dataloader. Download the dataset provided in the assignment webpage and complete the following block of code so that you can load it as if it was a standard dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.dataset = []\n",
    "        tdir = \"train\"\n",
    "        if train==False:\n",
    "            tdir = \"test\"\n",
    "        for filepath in glob.glob(root_dir+\"/\"+tdir+\"/*/*.png\"):\n",
    "            label = ord(filepath.split(\"/\")[-2]) - ord('A')\n",
    "            with Image.open(filepath) as img:\n",
    "                image = img.convert('RGB')\n",
    "            self.dataset.append((image,label))\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # idx - the index of the sample requested\n",
    "        #\n",
    "        # Open the image correspoding to idx, apply transforms on it and return a tuple (image, label)\n",
    "        # where label is an integer from 0-9 (since notMNIST has 10 classes)\n",
    "        img, lab = self.dataset[idx]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, lab\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now load the dataset. You just need to supply the `root_dir` in the block below and if you implemented the above block correctly, it should work without any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: 16854\n",
      "Size of test dataset: 1870\n",
      "Train images\n",
      "Test images\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABmCAYAAADFw1rEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcYYY4xbjv8fs61P7QE2Eu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f961e2810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((224,224)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='notMNIST_small', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='notMNIST_small', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# Let's check the size of the datasets, if implemented correctly they should be 16854 and 1870 respectively\n",
    "print('Size of train dataset: %d' % len(train_dataset))\n",
    "print('Size of test dataset: %d' % len(test_dataset))\n",
    "\n",
    "# Create loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Let's look at one batch of train and test images\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "train_dataiter = iter(train_loader)\n",
    "train_images, train_labels = train_dataiter.next()\n",
    "print(\"Train images\")\n",
    "imshow(torchvision.utils.make_grid(train_images))\n",
    "\n",
    "test_dataiter = iter(test_loader)\n",
    "test_images, test_labels = test_dataiter.next()\n",
    "print(\"Test images\")\n",
    "imshow(torchvision.utils.make_grid(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16 and Resnet-18\n",
    "Now that you have created the dataset we can use it for training and testing neural networks. VGG-16 and Resnet-18 are both well-known deep-net architectures. VGG-16 is named as such since it has 16 layers in total (13 convolution and 3 fully-connected). Resnet-18 on the other hand is a Resnet architecture that uses skip-connections. PyTorch provides pre-trained models of both these architectures and we shall be using them directly. If you are interested in knowing how they have been defined do take a look at the source, [VGG](https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py), [Resnet](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Code to change the last layers so that they only have 10 classes as output\n",
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 7 * 7, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 10),\n",
    ")\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "\n",
    "# Add code for using CUDA here if it is available\n",
    "if(torch.cuda.is_available()):\n",
    "    vgg16.cuda()\n",
    "    resnet18.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_vgg16 = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)\n",
    "optimizer_resnet18 = torch.optim.Adam(resnet18.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning\n",
    "Finetuning is nothing but training models after their weights have been loaded. This allows us to start at a better position than training from scratch. Since the models created already have weights loaded, you simply need to write a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_vgg16():\n",
    "    # Write loops so as to train the model for N epochs, use num_epochs hyper parameter\n",
    "    # Train/finetune the VGG-16 network\n",
    "    # Store the losses for every epoch and generate a graph using matplotlib\n",
    "    llist = []\n",
    "    count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Convert torch tensor to Variable\n",
    "#             print (\"loading images and labels\")\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "#             print (\"cuda ops\")\n",
    "            if(use_gpu):\n",
    "                images=images.cuda()\n",
    "                labels=labels.cuda()\n",
    "#             print (\"optimizer\")\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer_vgg16.zero_grad()  # zero the gradient buffer\n",
    "#             print (\"pass\")\n",
    "            outputs = vgg16(images)\n",
    "#             print (\"loss\")\n",
    "            loss = criterion(outputs, labels)\n",
    "#             print (\"backprop\")\n",
    "            loss.backward()\n",
    "#             print (\"optimizer update\")\n",
    "            optimizer_vgg16.step()\n",
    "            count = count+1\n",
    "            llist.append(loss.data[0])\n",
    "            if (i+1) % batch_size == 0:\n",
    "                print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "    plt.plot(np.array(range(count)),np.array(llist))\n",
    "    plt.show()\n",
    "    \n",
    "def train_resnet18():\n",
    "    # Same as above except now using the Resnet-18 network\n",
    "    llist = []\n",
    "    count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # Convert torch tensor to Variable\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            if(use_gpu):\n",
    "                images=images.cuda()\n",
    "                labels=labels.cuda()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer_resnet18.zero_grad()  # zero the gradient buffer\n",
    "            outputs = resnet18(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_resnet18.step()\n",
    "            count = count+1\n",
    "            llist.append(loss.data[0])\n",
    "            if (i+1) % batch_size == 0:\n",
    "                print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "    plt.plot(np.array(range(count)),np.array(llist))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us start the training/finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [5/3370], Loss: 1.9345\n",
      "Epoch [1/5], Step [10/3370], Loss: 2.7151\n",
      "Epoch [1/5], Step [15/3370], Loss: 2.3381\n",
      "Epoch [1/5], Step [20/3370], Loss: 2.3469\n",
      "Epoch [1/5], Step [25/3370], Loss: 1.6572\n",
      "Epoch [1/5], Step [30/3370], Loss: 2.6695\n",
      "Epoch [1/5], Step [35/3370], Loss: 1.6433\n",
      "Epoch [1/5], Step [40/3370], Loss: 1.3165\n",
      "Epoch [1/5], Step [45/3370], Loss: 1.4440\n",
      "Epoch [1/5], Step [50/3370], Loss: 0.2796\n",
      "Epoch [1/5], Step [55/3370], Loss: 0.7808\n",
      "Epoch [1/5], Step [60/3370], Loss: 0.4132\n",
      "Epoch [1/5], Step [65/3370], Loss: 0.5069\n",
      "Epoch [1/5], Step [70/3370], Loss: 0.5331\n",
      "Epoch [1/5], Step [75/3370], Loss: 0.2583\n",
      "Epoch [1/5], Step [80/3370], Loss: 0.7435\n",
      "Epoch [1/5], Step [85/3370], Loss: 0.2786\n",
      "Epoch [1/5], Step [90/3370], Loss: 0.5787\n",
      "Epoch [1/5], Step [95/3370], Loss: 0.3969\n",
      "Epoch [1/5], Step [100/3370], Loss: 0.2179\n",
      "Epoch [1/5], Step [105/3370], Loss: 1.2394\n",
      "Epoch [1/5], Step [110/3370], Loss: 0.0099\n",
      "Epoch [1/5], Step [115/3370], Loss: 1.3363\n",
      "Epoch [1/5], Step [120/3370], Loss: 1.0400\n",
      "Epoch [1/5], Step [125/3370], Loss: 0.2152\n",
      "Epoch [1/5], Step [130/3370], Loss: 0.1491\n",
      "Epoch [1/5], Step [135/3370], Loss: 0.7806\n",
      "Epoch [1/5], Step [140/3370], Loss: 0.1367\n",
      "Epoch [1/5], Step [145/3370], Loss: 0.0241\n",
      "Epoch [1/5], Step [150/3370], Loss: 0.2625\n",
      "Epoch [1/5], Step [155/3370], Loss: 0.6001\n",
      "Epoch [1/5], Step [160/3370], Loss: 0.2826\n",
      "Epoch [1/5], Step [165/3370], Loss: 1.2276\n",
      "Epoch [1/5], Step [170/3370], Loss: 0.1046\n",
      "Epoch [1/5], Step [175/3370], Loss: 0.5787\n",
      "Epoch [1/5], Step [180/3370], Loss: 0.4961\n",
      "Epoch [1/5], Step [185/3370], Loss: 0.1906\n",
      "Epoch [1/5], Step [190/3370], Loss: 0.5673\n",
      "Epoch [1/5], Step [195/3370], Loss: 0.5460\n",
      "Epoch [1/5], Step [200/3370], Loss: 0.0042\n",
      "Epoch [1/5], Step [205/3370], Loss: 0.4007\n",
      "Epoch [1/5], Step [210/3370], Loss: 0.9817\n",
      "Epoch [1/5], Step [215/3370], Loss: 0.8274\n",
      "Epoch [1/5], Step [220/3370], Loss: 0.1411\n",
      "Epoch [1/5], Step [225/3370], Loss: 0.6133\n",
      "Epoch [1/5], Step [230/3370], Loss: 0.0066\n",
      "Epoch [1/5], Step [235/3370], Loss: 0.0056\n",
      "Epoch [1/5], Step [240/3370], Loss: 0.0654\n",
      "Epoch [1/5], Step [245/3370], Loss: 0.1775\n",
      "Epoch [1/5], Step [250/3370], Loss: 1.1955\n",
      "Epoch [1/5], Step [255/3370], Loss: 0.0778\n",
      "Epoch [1/5], Step [260/3370], Loss: 0.0092\n",
      "Epoch [1/5], Step [265/3370], Loss: 0.1758\n",
      "Epoch [1/5], Step [270/3370], Loss: 0.0620\n",
      "Epoch [1/5], Step [275/3370], Loss: 0.0145\n",
      "Epoch [1/5], Step [280/3370], Loss: 0.5123\n",
      "Epoch [1/5], Step [285/3370], Loss: 0.1541\n",
      "Epoch [1/5], Step [290/3370], Loss: 0.5228\n",
      "Epoch [1/5], Step [295/3370], Loss: 0.3884\n",
      "Epoch [1/5], Step [300/3370], Loss: 0.4296\n",
      "Epoch [1/5], Step [305/3370], Loss: 0.6566\n",
      "Epoch [1/5], Step [310/3370], Loss: 0.2642\n",
      "Epoch [1/5], Step [315/3370], Loss: 0.6412\n",
      "Epoch [1/5], Step [320/3370], Loss: 0.0022\n",
      "Epoch [1/5], Step [325/3370], Loss: 0.0000\n",
      "Epoch [1/5], Step [330/3370], Loss: 0.0211\n",
      "Epoch [1/5], Step [335/3370], Loss: 0.0006\n",
      "Epoch [1/5], Step [340/3370], Loss: 0.7186\n",
      "Epoch [1/5], Step [345/3370], Loss: 0.0146\n",
      "Epoch [1/5], Step [350/3370], Loss: 0.0523\n",
      "Epoch [1/5], Step [355/3370], Loss: 0.3894\n",
      "Epoch [1/5], Step [360/3370], Loss: 0.1675\n",
      "Epoch [1/5], Step [365/3370], Loss: 0.1486\n",
      "Epoch [1/5], Step [370/3370], Loss: 0.6791\n",
      "Epoch [1/5], Step [375/3370], Loss: 0.4849\n",
      "Epoch [1/5], Step [380/3370], Loss: 0.6222\n",
      "Epoch [1/5], Step [385/3370], Loss: 0.7100\n",
      "Epoch [1/5], Step [390/3370], Loss: 0.0070\n",
      "Epoch [1/5], Step [395/3370], Loss: 0.1716\n",
      "Epoch [1/5], Step [400/3370], Loss: 0.8097\n",
      "Epoch [1/5], Step [405/3370], Loss: 0.8549\n",
      "Epoch [1/5], Step [410/3370], Loss: 1.6823\n",
      "Epoch [1/5], Step [415/3370], Loss: 0.1087\n",
      "Epoch [1/5], Step [420/3370], Loss: 0.1408\n",
      "Epoch [1/5], Step [425/3370], Loss: 0.3069\n",
      "Epoch [1/5], Step [430/3370], Loss: 0.0032\n",
      "Epoch [1/5], Step [435/3370], Loss: 0.1273\n",
      "Epoch [1/5], Step [440/3370], Loss: 0.0011\n",
      "Epoch [1/5], Step [445/3370], Loss: 1.1767\n",
      "Epoch [1/5], Step [450/3370], Loss: 0.0300\n",
      "Epoch [1/5], Step [455/3370], Loss: 0.0201\n",
      "Epoch [1/5], Step [460/3370], Loss: 0.0012\n",
      "Epoch [1/5], Step [465/3370], Loss: 0.2722\n",
      "Epoch [1/5], Step [470/3370], Loss: 0.5499\n",
      "Epoch [1/5], Step [475/3370], Loss: 0.0427\n",
      "Epoch [1/5], Step [480/3370], Loss: 0.0397\n",
      "Epoch [1/5], Step [485/3370], Loss: 0.2782\n",
      "Epoch [1/5], Step [490/3370], Loss: 0.3212\n",
      "Epoch [1/5], Step [495/3370], Loss: 0.3376\n",
      "Epoch [1/5], Step [500/3370], Loss: 0.2170\n",
      "Epoch [1/5], Step [505/3370], Loss: 0.3638\n",
      "Epoch [1/5], Step [510/3370], Loss: 0.0344\n",
      "Epoch [1/5], Step [515/3370], Loss: 0.0090\n",
      "Epoch [1/5], Step [520/3370], Loss: 0.4077\n",
      "Epoch [1/5], Step [525/3370], Loss: 0.0012\n",
      "Epoch [1/5], Step [530/3370], Loss: 0.0445\n",
      "Epoch [1/5], Step [535/3370], Loss: 1.1817\n",
      "Epoch [1/5], Step [540/3370], Loss: 0.0667\n",
      "Epoch [1/5], Step [545/3370], Loss: 1.8578\n",
      "Epoch [1/5], Step [550/3370], Loss: 0.0184\n",
      "Epoch [1/5], Step [555/3370], Loss: 0.0834\n",
      "Epoch [1/5], Step [560/3370], Loss: 0.0834\n",
      "Epoch [1/5], Step [565/3370], Loss: 0.1765\n",
      "Epoch [1/5], Step [570/3370], Loss: 0.0027\n",
      "Epoch [1/5], Step [575/3370], Loss: 0.0033\n",
      "Epoch [1/5], Step [580/3370], Loss: 0.0399\n",
      "Epoch [1/5], Step [585/3370], Loss: 0.0421\n",
      "Epoch [1/5], Step [590/3370], Loss: 0.1069\n",
      "Epoch [1/5], Step [595/3370], Loss: 0.0027\n",
      "Epoch [1/5], Step [600/3370], Loss: 0.1229\n",
      "Epoch [1/5], Step [605/3370], Loss: 0.0453\n",
      "Epoch [1/5], Step [610/3370], Loss: 0.9804\n",
      "Epoch [1/5], Step [615/3370], Loss: 0.0143\n",
      "Epoch [1/5], Step [620/3370], Loss: 1.2396\n",
      "Epoch [1/5], Step [625/3370], Loss: 0.0148\n",
      "Epoch [1/5], Step [630/3370], Loss: 0.7136\n",
      "Epoch [1/5], Step [635/3370], Loss: 0.0003\n",
      "Epoch [1/5], Step [640/3370], Loss: 0.0035\n",
      "Epoch [1/5], Step [645/3370], Loss: 0.4322\n",
      "Epoch [1/5], Step [650/3370], Loss: 0.0112\n",
      "Epoch [1/5], Step [655/3370], Loss: 0.0253\n",
      "Epoch [1/5], Step [660/3370], Loss: 0.5647\n",
      "Epoch [1/5], Step [665/3370], Loss: 0.2395\n",
      "Epoch [1/5], Step [670/3370], Loss: 0.1633\n",
      "Epoch [1/5], Step [675/3370], Loss: 0.0053\n",
      "Epoch [1/5], Step [680/3370], Loss: 1.1191\n",
      "Epoch [1/5], Step [685/3370], Loss: 0.0249\n",
      "Epoch [1/5], Step [690/3370], Loss: 0.2926\n",
      "Epoch [1/5], Step [695/3370], Loss: 0.0685\n",
      "Epoch [1/5], Step [700/3370], Loss: 0.1707\n",
      "Epoch [1/5], Step [705/3370], Loss: 0.3280\n",
      "Epoch [1/5], Step [710/3370], Loss: 0.0522\n",
      "Epoch [1/5], Step [715/3370], Loss: 1.4201\n",
      "Epoch [1/5], Step [720/3370], Loss: 0.0206\n",
      "Epoch [1/5], Step [725/3370], Loss: 0.1322\n",
      "Epoch [1/5], Step [730/3370], Loss: 0.2393\n",
      "Epoch [1/5], Step [735/3370], Loss: 0.6882\n",
      "Epoch [1/5], Step [740/3370], Loss: 0.0022\n",
      "Epoch [1/5], Step [745/3370], Loss: 0.0003\n",
      "Epoch [1/5], Step [750/3370], Loss: 0.4476\n",
      "Epoch [1/5], Step [755/3370], Loss: 0.0004\n",
      "Epoch [1/5], Step [760/3370], Loss: 0.1943\n",
      "Epoch [1/5], Step [765/3370], Loss: 3.3208\n",
      "Epoch [1/5], Step [770/3370], Loss: 0.0690\n",
      "Epoch [1/5], Step [775/3370], Loss: 0.0589\n",
      "Epoch [1/5], Step [780/3370], Loss: 0.1607\n",
      "Epoch [1/5], Step [785/3370], Loss: 0.5508\n",
      "Epoch [1/5], Step [790/3370], Loss: 0.1053\n",
      "Epoch [1/5], Step [795/3370], Loss: 0.0449\n",
      "Epoch [1/5], Step [800/3370], Loss: 0.0109\n",
      "Epoch [1/5], Step [805/3370], Loss: 0.0021\n",
      "Epoch [1/5], Step [810/3370], Loss: 0.3100\n",
      "Epoch [1/5], Step [815/3370], Loss: 0.0191\n",
      "Epoch [1/5], Step [820/3370], Loss: 0.1575\n",
      "Epoch [1/5], Step [825/3370], Loss: 2.1237\n",
      "Epoch [1/5], Step [830/3370], Loss: 0.0046\n",
      "Epoch [1/5], Step [835/3370], Loss: 0.3470\n",
      "Epoch [1/5], Step [840/3370], Loss: 0.0261\n",
      "Epoch [1/5], Step [845/3370], Loss: 1.0635\n",
      "Epoch [1/5], Step [850/3370], Loss: 0.1598\n",
      "Epoch [1/5], Step [855/3370], Loss: 0.0429\n",
      "Epoch [1/5], Step [860/3370], Loss: 0.1598\n",
      "Epoch [1/5], Step [865/3370], Loss: 0.0157\n",
      "Epoch [1/5], Step [870/3370], Loss: 0.0008\n",
      "Epoch [1/5], Step [875/3370], Loss: 0.2415\n",
      "Epoch [1/5], Step [880/3370], Loss: 0.0000\n",
      "Epoch [1/5], Step [885/3370], Loss: 0.9687\n",
      "Epoch [1/5], Step [890/3370], Loss: 1.0650\n",
      "Epoch [1/5], Step [895/3370], Loss: 0.2574\n",
      "Epoch [1/5], Step [900/3370], Loss: 0.3383\n",
      "Epoch [1/5], Step [905/3370], Loss: 0.2746\n",
      "Epoch [1/5], Step [910/3370], Loss: 0.3555\n",
      "Epoch [1/5], Step [915/3370], Loss: 0.4764\n"
     ]
    }
   ],
   "source": [
    "%time train_vgg16()\n",
    "%time train_resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "Once finetuning is done we need to test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    # Write loops for testing the model on the test set\n",
    "    # You should also print out the accuracy of the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images)\n",
    "        \n",
    "        if(use_gpu):\n",
    "            images = images.cuda()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "    print('Accuracy of the network on test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time test(vgg16)\n",
    "%time test(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add more code to save the models if you want but otherwise this notebook is complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
